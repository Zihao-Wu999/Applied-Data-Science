{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DfkHfHmZ5uOE"
   },
   "source": [
    "# Homework Session 11 Neural networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xfx_1JqY5uOG"
   },
   "source": [
    "### part 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lsqgCcNY5uOG"
   },
   "source": [
    "The purpose of the below is to classify days over years 2017-2018 by their corresponding mobility patterns between 10 zones in Taipei (quantified by an aggregated temporal network of subway ridership flows across the city)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZKLYMDbY5uOG"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Input, Dense\n",
    "from keras.utils import np_utils\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Flatten\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.utils import np_utils\n",
    "from keras import backend as K\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "import numpy as np\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import LSTM\n",
    "from keras.layers.core import Dense, Activation\n",
    "from keras.optimizers import RMSprop\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import heapq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FdwTOn5P5uOH"
   },
   "outputs": [],
   "source": [
    "#read the data\n",
    "TNet=pd.read_csv('taipeiD_TNet2.csv',header=None);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 300
    },
    "id": "kMdb7Dfj5uOI",
    "outputId": "21b7dbb1-3b1c-4fe9-9e76-f85491b052af"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-ccff442a-606b-4e16-9996-2d816ec9463d\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>90</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.017943</td>\n",
       "      <td>0.005415</td>\n",
       "      <td>0.003590</td>\n",
       "      <td>0.008316</td>\n",
       "      <td>0.007859</td>\n",
       "      <td>0.012942</td>\n",
       "      <td>0.012196</td>\n",
       "      <td>0.019543</td>\n",
       "      <td>0.001196</td>\n",
       "      <td>0.003327</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002529</td>\n",
       "      <td>0.001533</td>\n",
       "      <td>0.001860</td>\n",
       "      <td>0.002375</td>\n",
       "      <td>0.005408</td>\n",
       "      <td>0.008922</td>\n",
       "      <td>0.003945</td>\n",
       "      <td>0.011075</td>\n",
       "      <td>0.005073</td>\n",
       "      <td>0.012708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.021283</td>\n",
       "      <td>0.005215</td>\n",
       "      <td>0.003530</td>\n",
       "      <td>0.009359</td>\n",
       "      <td>0.007803</td>\n",
       "      <td>0.014288</td>\n",
       "      <td>0.011185</td>\n",
       "      <td>0.019044</td>\n",
       "      <td>0.001383</td>\n",
       "      <td>0.003499</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002803</td>\n",
       "      <td>0.001757</td>\n",
       "      <td>0.001783</td>\n",
       "      <td>0.002549</td>\n",
       "      <td>0.005515</td>\n",
       "      <td>0.009650</td>\n",
       "      <td>0.003596</td>\n",
       "      <td>0.009618</td>\n",
       "      <td>0.005946</td>\n",
       "      <td>0.013709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.028988</td>\n",
       "      <td>0.006511</td>\n",
       "      <td>0.005591</td>\n",
       "      <td>0.012970</td>\n",
       "      <td>0.007816</td>\n",
       "      <td>0.015878</td>\n",
       "      <td>0.010973</td>\n",
       "      <td>0.015768</td>\n",
       "      <td>0.002252</td>\n",
       "      <td>0.005388</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004649</td>\n",
       "      <td>0.002555</td>\n",
       "      <td>0.002672</td>\n",
       "      <td>0.004291</td>\n",
       "      <td>0.007385</td>\n",
       "      <td>0.009558</td>\n",
       "      <td>0.004293</td>\n",
       "      <td>0.008791</td>\n",
       "      <td>0.010040</td>\n",
       "      <td>0.016301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.029534</td>\n",
       "      <td>0.006471</td>\n",
       "      <td>0.005615</td>\n",
       "      <td>0.013017</td>\n",
       "      <td>0.007717</td>\n",
       "      <td>0.016098</td>\n",
       "      <td>0.011182</td>\n",
       "      <td>0.015815</td>\n",
       "      <td>0.002325</td>\n",
       "      <td>0.005443</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004611</td>\n",
       "      <td>0.002473</td>\n",
       "      <td>0.002635</td>\n",
       "      <td>0.004195</td>\n",
       "      <td>0.007255</td>\n",
       "      <td>0.009487</td>\n",
       "      <td>0.004316</td>\n",
       "      <td>0.008729</td>\n",
       "      <td>0.010296</td>\n",
       "      <td>0.016437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.029333</td>\n",
       "      <td>0.006525</td>\n",
       "      <td>0.005727</td>\n",
       "      <td>0.013098</td>\n",
       "      <td>0.007692</td>\n",
       "      <td>0.016358</td>\n",
       "      <td>0.011000</td>\n",
       "      <td>0.015677</td>\n",
       "      <td>0.002344</td>\n",
       "      <td>0.005527</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004694</td>\n",
       "      <td>0.002515</td>\n",
       "      <td>0.002677</td>\n",
       "      <td>0.004222</td>\n",
       "      <td>0.007269</td>\n",
       "      <td>0.009921</td>\n",
       "      <td>0.004387</td>\n",
       "      <td>0.008923</td>\n",
       "      <td>0.010381</td>\n",
       "      <td>0.016914</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 100 columns</p>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ccff442a-606b-4e16-9996-2d816ec9463d')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-ccff442a-606b-4e16-9996-2d816ec9463d button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-ccff442a-606b-4e16-9996-2d816ec9463d');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "         0         1         2         3         4         5         6   \\\n",
       "0  0.017943  0.005415  0.003590  0.008316  0.007859  0.012942  0.012196   \n",
       "1  0.021283  0.005215  0.003530  0.009359  0.007803  0.014288  0.011185   \n",
       "2  0.028988  0.006511  0.005591  0.012970  0.007816  0.015878  0.010973   \n",
       "3  0.029534  0.006471  0.005615  0.013017  0.007717  0.016098  0.011182   \n",
       "4  0.029333  0.006525  0.005727  0.013098  0.007692  0.016358  0.011000   \n",
       "\n",
       "         7         8         9   ...        90        91        92        93  \\\n",
       "0  0.019543  0.001196  0.003327  ...  0.002529  0.001533  0.001860  0.002375   \n",
       "1  0.019044  0.001383  0.003499  ...  0.002803  0.001757  0.001783  0.002549   \n",
       "2  0.015768  0.002252  0.005388  ...  0.004649  0.002555  0.002672  0.004291   \n",
       "3  0.015815  0.002325  0.005443  ...  0.004611  0.002473  0.002635  0.004195   \n",
       "4  0.015677  0.002344  0.005527  ...  0.004694  0.002515  0.002677  0.004222   \n",
       "\n",
       "         94        95        96        97        98        99  \n",
       "0  0.005408  0.008922  0.003945  0.011075  0.005073  0.012708  \n",
       "1  0.005515  0.009650  0.003596  0.009618  0.005946  0.013709  \n",
       "2  0.007385  0.009558  0.004293  0.008791  0.010040  0.016301  \n",
       "3  0.007255  0.009487  0.004316  0.008729  0.010296  0.016437  \n",
       "4  0.007269  0.009921  0.004387  0.008923  0.010381  0.016914  \n",
       "\n",
       "[5 rows x 100 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TNet.head() \n",
    "#each row represents a 10x10 adjacency matrix of the normalized Taipei subway mobility network between 10 zones flattened into a 100x1 row corresponding to a single day\n",
    "#days start at jan-1-2017"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0CTT43Z45uOI"
   },
   "outputs": [],
   "source": [
    "#convert to an array and scale the data\n",
    "X=np.array(TNet);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xLoeIJgO5uOJ"
   },
   "outputs": [],
   "source": [
    "X=MinMaxScaler(feature_range=(0, 1), copy=True).fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "B9t9a0P-5uOJ",
    "outputId": "9c985500-cbbd-4e33-bdab-17e8f01c2078"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(669, 100)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0zpXMWnn5uOJ",
    "outputId": "eb1f569b-8fd8-440b-ebe8-30e324173e1d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4, 5, 6, 0, 1, 2])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#define day of the week corresponding to each day of observation; 0-Sunday, 1-Monday,...,6-Saturday\n",
    "y=np.array(range(669))%7; y[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yelPviYR5uOJ",
    "outputId": "2734ebe9-e5cb-48e7-e567-b22fd60597e1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yc=np_utils.to_categorical(y) #get categorical binary variables isSunday, isMonday,...\n",
    "yc[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e8N9IrJp5uOK"
   },
   "outputs": [],
   "source": [
    "X_test=X[400:,:]; X_train=X[:400,:]; #split the data into training and test\n",
    "y_test=yc[400:,:]; y_train=yc[:400,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "csI5RVtH5-Hz",
    "outputId": "d011fe1f-7790-4038-a975-c2183704ea1b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.90159786, 0.72082394, 0.68945875, ..., 0.31791065, 0.7516474 ,\n",
       "        0.6480811 ],\n",
       "       [0.80536476, 0.72076218, 0.67706797, ..., 0.40164665, 0.74135895,\n",
       "        0.64908372],\n",
       "       [0.81765599, 0.66149903, 0.67597867, ..., 0.35410987, 0.72873928,\n",
       "        0.63215062],\n",
       "       ...,\n",
       "       [0.90658665, 0.81779439, 0.57798706, ..., 0.25836145, 0.87024431,\n",
       "        0.72583969],\n",
       "       [0.88836671, 0.81415027, 0.6014524 , ..., 0.24613308, 0.88847445,\n",
       "        0.79435192],\n",
       "       [0.8981997 , 0.7926253 , 0.5901963 , ..., 0.27293832, 0.86042211,\n",
       "        0.74722888]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oddXo8sv5uOK"
   },
   "source": [
    "## Task 1. Classify weekdays/weekends\n",
    "Label the rows with ones for weekends, zeros for weekdays.\n",
    "Train a neural network with 4 layers of 30,10,3 and 1 (output) neurons over the training sample against this label, evaluating its performance over the test sample. Report the acheived accuracy (categorical) over the test sample\n",
    "\n",
    "First three layers use relu activation function, last one - sigmoid.\n",
    "Use loss='binary_crossentropy', optimizer='adam', 100 epochs, batch_size=20. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_Z7-jA_L5uOK"
   },
   "outputs": [],
   "source": [
    "y_label = np.array([(i % 7 > 4) for i in range(X.shape[0])]).astype(int)\n",
    "y_train_label = y_label[:400]\n",
    "y_test_label = y_label[400:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dYz0rTw25uOK",
    "outputId": "917ec41f-991e-4f93-db0f-2496e0dfc7d4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "20/20 - 1s - loss: 0.5648 - accuracy: 0.7150 - val_loss: 0.5264 - val_accuracy: 0.7175 - 1s/epoch - 53ms/step\n",
      "Epoch 2/100\n",
      "20/20 - 0s - loss: 0.5119 - accuracy: 0.7150 - val_loss: 0.4907 - val_accuracy: 0.7175 - 52ms/epoch - 3ms/step\n",
      "Epoch 3/100\n",
      "20/20 - 0s - loss: 0.4798 - accuracy: 0.7150 - val_loss: 0.4605 - val_accuracy: 0.7175 - 54ms/epoch - 3ms/step\n",
      "Epoch 4/100\n",
      "20/20 - 0s - loss: 0.4483 - accuracy: 0.7150 - val_loss: 0.4329 - val_accuracy: 0.7212 - 59ms/epoch - 3ms/step\n",
      "Epoch 5/100\n",
      "20/20 - 0s - loss: 0.4238 - accuracy: 0.7375 - val_loss: 0.4036 - val_accuracy: 0.7323 - 54ms/epoch - 3ms/step\n",
      "Epoch 6/100\n",
      "20/20 - 0s - loss: 0.3939 - accuracy: 0.7675 - val_loss: 0.3808 - val_accuracy: 0.7472 - 71ms/epoch - 4ms/step\n",
      "Epoch 7/100\n",
      "20/20 - 0s - loss: 0.3689 - accuracy: 0.8000 - val_loss: 0.3655 - val_accuracy: 0.7398 - 54ms/epoch - 3ms/step\n",
      "Epoch 8/100\n",
      "20/20 - 0s - loss: 0.3487 - accuracy: 0.8375 - val_loss: 0.3605 - val_accuracy: 0.7398 - 57ms/epoch - 3ms/step\n",
      "Epoch 9/100\n",
      "20/20 - 0s - loss: 0.3332 - accuracy: 0.8450 - val_loss: 0.3375 - val_accuracy: 0.7472 - 57ms/epoch - 3ms/step\n",
      "Epoch 10/100\n",
      "20/20 - 0s - loss: 0.3152 - accuracy: 0.8525 - val_loss: 0.3167 - val_accuracy: 0.8439 - 59ms/epoch - 3ms/step\n",
      "Epoch 11/100\n",
      "20/20 - 0s - loss: 0.3021 - accuracy: 0.8900 - val_loss: 0.3103 - val_accuracy: 0.8178 - 71ms/epoch - 4ms/step\n",
      "Epoch 12/100\n",
      "20/20 - 0s - loss: 0.2865 - accuracy: 0.8875 - val_loss: 0.3022 - val_accuracy: 0.8364 - 67ms/epoch - 3ms/step\n",
      "Epoch 13/100\n",
      "20/20 - 0s - loss: 0.2746 - accuracy: 0.9000 - val_loss: 0.2859 - val_accuracy: 0.8848 - 62ms/epoch - 3ms/step\n",
      "Epoch 14/100\n",
      "20/20 - 0s - loss: 0.2748 - accuracy: 0.9175 - val_loss: 0.2763 - val_accuracy: 0.8736 - 54ms/epoch - 3ms/step\n",
      "Epoch 15/100\n",
      "20/20 - 0s - loss: 0.2652 - accuracy: 0.9275 - val_loss: 0.2734 - val_accuracy: 0.8699 - 66ms/epoch - 3ms/step\n",
      "Epoch 16/100\n",
      "20/20 - 0s - loss: 0.2486 - accuracy: 0.9325 - val_loss: 0.2694 - val_accuracy: 0.8662 - 60ms/epoch - 3ms/step\n",
      "Epoch 17/100\n",
      "20/20 - 0s - loss: 0.2421 - accuracy: 0.9300 - val_loss: 0.2541 - val_accuracy: 0.9033 - 62ms/epoch - 3ms/step\n",
      "Epoch 18/100\n",
      "20/20 - 0s - loss: 0.2385 - accuracy: 0.9425 - val_loss: 0.2686 - val_accuracy: 0.8625 - 56ms/epoch - 3ms/step\n",
      "Epoch 19/100\n",
      "20/20 - 0s - loss: 0.2329 - accuracy: 0.9475 - val_loss: 0.2635 - val_accuracy: 0.8699 - 51ms/epoch - 3ms/step\n",
      "Epoch 20/100\n",
      "20/20 - 0s - loss: 0.2247 - accuracy: 0.9425 - val_loss: 0.2394 - val_accuracy: 0.9145 - 112ms/epoch - 6ms/step\n",
      "Epoch 21/100\n",
      "20/20 - 0s - loss: 0.2157 - accuracy: 0.9625 - val_loss: 0.2512 - val_accuracy: 0.8959 - 88ms/epoch - 4ms/step\n",
      "Epoch 22/100\n",
      "20/20 - 0s - loss: 0.2167 - accuracy: 0.9525 - val_loss: 0.2258 - val_accuracy: 0.9591 - 82ms/epoch - 4ms/step\n",
      "Epoch 23/100\n",
      "20/20 - 0s - loss: 0.2094 - accuracy: 0.9650 - val_loss: 0.2314 - val_accuracy: 0.9182 - 77ms/epoch - 4ms/step\n",
      "Epoch 24/100\n",
      "20/20 - 0s - loss: 0.2027 - accuracy: 0.9700 - val_loss: 0.2207 - val_accuracy: 0.9554 - 87ms/epoch - 4ms/step\n",
      "Epoch 25/100\n",
      "20/20 - 0s - loss: 0.2020 - accuracy: 0.9675 - val_loss: 0.2188 - val_accuracy: 0.9442 - 73ms/epoch - 4ms/step\n",
      "Epoch 26/100\n",
      "20/20 - 0s - loss: 0.1967 - accuracy: 0.9675 - val_loss: 0.2240 - val_accuracy: 0.9257 - 77ms/epoch - 4ms/step\n",
      "Epoch 27/100\n",
      "20/20 - 0s - loss: 0.1939 - accuracy: 0.9700 - val_loss: 0.2273 - val_accuracy: 0.9219 - 67ms/epoch - 3ms/step\n",
      "Epoch 28/100\n",
      "20/20 - 0s - loss: 0.1864 - accuracy: 0.9725 - val_loss: 0.2190 - val_accuracy: 0.9294 - 73ms/epoch - 4ms/step\n",
      "Epoch 29/100\n",
      "20/20 - 0s - loss: 0.1855 - accuracy: 0.9700 - val_loss: 0.2212 - val_accuracy: 0.9405 - 77ms/epoch - 4ms/step\n",
      "Epoch 30/100\n",
      "20/20 - 0s - loss: 0.1854 - accuracy: 0.9650 - val_loss: 0.2243 - val_accuracy: 0.9219 - 66ms/epoch - 3ms/step\n",
      "Epoch 31/100\n",
      "20/20 - 0s - loss: 0.1833 - accuracy: 0.9675 - val_loss: 0.2147 - val_accuracy: 0.9405 - 79ms/epoch - 4ms/step\n",
      "Epoch 32/100\n",
      "20/20 - 0s - loss: 0.1779 - accuracy: 0.9725 - val_loss: 0.2216 - val_accuracy: 0.9182 - 76ms/epoch - 4ms/step\n",
      "Epoch 33/100\n",
      "20/20 - 0s - loss: 0.1776 - accuracy: 0.9775 - val_loss: 0.2204 - val_accuracy: 0.9219 - 76ms/epoch - 4ms/step\n",
      "Epoch 34/100\n",
      "20/20 - 0s - loss: 0.1692 - accuracy: 0.9775 - val_loss: 0.2069 - val_accuracy: 0.9442 - 72ms/epoch - 4ms/step\n",
      "Epoch 35/100\n",
      "20/20 - 0s - loss: 0.1682 - accuracy: 0.9825 - val_loss: 0.1964 - val_accuracy: 0.9591 - 73ms/epoch - 4ms/step\n",
      "Epoch 36/100\n",
      "20/20 - 0s - loss: 0.1607 - accuracy: 0.9750 - val_loss: 0.1993 - val_accuracy: 0.9628 - 73ms/epoch - 4ms/step\n",
      "Epoch 37/100\n",
      "20/20 - 0s - loss: 0.1629 - accuracy: 0.9775 - val_loss: 0.1964 - val_accuracy: 0.9554 - 76ms/epoch - 4ms/step\n",
      "Epoch 38/100\n",
      "20/20 - 0s - loss: 0.1660 - accuracy: 0.9700 - val_loss: 0.2224 - val_accuracy: 0.9145 - 89ms/epoch - 4ms/step\n",
      "Epoch 39/100\n",
      "20/20 - 0s - loss: 0.1650 - accuracy: 0.9750 - val_loss: 0.2258 - val_accuracy: 0.9145 - 73ms/epoch - 4ms/step\n",
      "Epoch 40/100\n",
      "20/20 - 0s - loss: 0.1556 - accuracy: 0.9800 - val_loss: 0.2293 - val_accuracy: 0.9108 - 80ms/epoch - 4ms/step\n",
      "Epoch 41/100\n",
      "20/20 - 0s - loss: 0.1516 - accuracy: 0.9775 - val_loss: 0.1944 - val_accuracy: 0.9554 - 76ms/epoch - 4ms/step\n",
      "Epoch 42/100\n",
      "20/20 - 0s - loss: 0.1471 - accuracy: 0.9800 - val_loss: 0.1854 - val_accuracy: 0.9628 - 76ms/epoch - 4ms/step\n",
      "Epoch 43/100\n",
      "20/20 - 0s - loss: 0.1442 - accuracy: 0.9800 - val_loss: 0.1884 - val_accuracy: 0.9591 - 61ms/epoch - 3ms/step\n",
      "Epoch 44/100\n",
      "20/20 - 0s - loss: 0.1413 - accuracy: 0.9900 - val_loss: 0.2134 - val_accuracy: 0.9331 - 54ms/epoch - 3ms/step\n",
      "Epoch 45/100\n",
      "20/20 - 0s - loss: 0.1443 - accuracy: 0.9825 - val_loss: 0.2004 - val_accuracy: 0.9442 - 61ms/epoch - 3ms/step\n",
      "Epoch 46/100\n",
      "20/20 - 0s - loss: 0.1449 - accuracy: 0.9825 - val_loss: 0.1896 - val_accuracy: 0.9591 - 54ms/epoch - 3ms/step\n",
      "Epoch 47/100\n",
      "20/20 - 0s - loss: 0.1346 - accuracy: 0.9875 - val_loss: 0.1855 - val_accuracy: 0.9591 - 60ms/epoch - 3ms/step\n",
      "Epoch 48/100\n",
      "20/20 - 0s - loss: 0.1336 - accuracy: 0.9875 - val_loss: 0.1860 - val_accuracy: 0.9591 - 56ms/epoch - 3ms/step\n",
      "Epoch 49/100\n",
      "20/20 - 0s - loss: 0.1349 - accuracy: 0.9900 - val_loss: 0.2046 - val_accuracy: 0.9368 - 60ms/epoch - 3ms/step\n",
      "Epoch 50/100\n",
      "20/20 - 0s - loss: 0.1297 - accuracy: 0.9900 - val_loss: 0.1863 - val_accuracy: 0.9554 - 61ms/epoch - 3ms/step\n",
      "Epoch 51/100\n",
      "20/20 - 0s - loss: 0.1293 - accuracy: 0.9900 - val_loss: 0.1893 - val_accuracy: 0.9517 - 53ms/epoch - 3ms/step\n",
      "Epoch 52/100\n",
      "20/20 - 0s - loss: 0.1260 - accuracy: 0.9875 - val_loss: 0.1781 - val_accuracy: 0.9628 - 55ms/epoch - 3ms/step\n",
      "Epoch 53/100\n",
      "20/20 - 0s - loss: 0.1241 - accuracy: 0.9850 - val_loss: 0.1885 - val_accuracy: 0.9591 - 60ms/epoch - 3ms/step\n",
      "Epoch 54/100\n",
      "20/20 - 0s - loss: 0.1212 - accuracy: 0.9925 - val_loss: 0.1918 - val_accuracy: 0.9591 - 51ms/epoch - 3ms/step\n",
      "Epoch 55/100\n",
      "20/20 - 0s - loss: 0.1204 - accuracy: 0.9900 - val_loss: 0.1801 - val_accuracy: 0.9628 - 51ms/epoch - 3ms/step\n",
      "Epoch 56/100\n",
      "20/20 - 0s - loss: 0.1197 - accuracy: 0.9900 - val_loss: 0.1827 - val_accuracy: 0.9480 - 50ms/epoch - 2ms/step\n",
      "Epoch 57/100\n",
      "20/20 - 0s - loss: 0.1176 - accuracy: 0.9900 - val_loss: 0.1898 - val_accuracy: 0.9554 - 60ms/epoch - 3ms/step\n",
      "Epoch 58/100\n",
      "20/20 - 0s - loss: 0.1165 - accuracy: 0.9900 - val_loss: 0.1929 - val_accuracy: 0.9442 - 55ms/epoch - 3ms/step\n",
      "Epoch 59/100\n",
      "20/20 - 0s - loss: 0.1168 - accuracy: 0.9875 - val_loss: 0.1881 - val_accuracy: 0.9517 - 52ms/epoch - 3ms/step\n",
      "Epoch 60/100\n",
      "20/20 - 0s - loss: 0.1177 - accuracy: 0.9875 - val_loss: 0.1703 - val_accuracy: 0.9628 - 54ms/epoch - 3ms/step\n",
      "Epoch 61/100\n",
      "20/20 - 0s - loss: 0.1141 - accuracy: 0.9850 - val_loss: 0.1694 - val_accuracy: 0.9628 - 59ms/epoch - 3ms/step\n",
      "Epoch 62/100\n",
      "20/20 - 0s - loss: 0.1159 - accuracy: 0.9875 - val_loss: 0.1717 - val_accuracy: 0.9554 - 50ms/epoch - 3ms/step\n",
      "Epoch 63/100\n",
      "20/20 - 0s - loss: 0.1088 - accuracy: 0.9925 - val_loss: 0.1778 - val_accuracy: 0.9591 - 51ms/epoch - 3ms/step\n",
      "Epoch 64/100\n",
      "20/20 - 0s - loss: 0.1068 - accuracy: 0.9925 - val_loss: 0.1818 - val_accuracy: 0.9554 - 57ms/epoch - 3ms/step\n",
      "Epoch 65/100\n",
      "20/20 - 0s - loss: 0.1091 - accuracy: 0.9875 - val_loss: 0.1756 - val_accuracy: 0.9591 - 54ms/epoch - 3ms/step\n",
      "Epoch 66/100\n",
      "20/20 - 0s - loss: 0.1047 - accuracy: 0.9925 - val_loss: 0.1640 - val_accuracy: 0.9628 - 52ms/epoch - 3ms/step\n",
      "Epoch 67/100\n",
      "20/20 - 0s - loss: 0.1075 - accuracy: 0.9900 - val_loss: 0.1719 - val_accuracy: 0.9591 - 53ms/epoch - 3ms/step\n",
      "Epoch 68/100\n",
      "20/20 - 0s - loss: 0.1118 - accuracy: 0.9850 - val_loss: 0.1719 - val_accuracy: 0.9628 - 60ms/epoch - 3ms/step\n",
      "Epoch 69/100\n",
      "20/20 - 0s - loss: 0.1083 - accuracy: 0.9900 - val_loss: 0.1661 - val_accuracy: 0.9628 - 64ms/epoch - 3ms/step\n",
      "Epoch 70/100\n",
      "20/20 - 0s - loss: 0.1064 - accuracy: 0.9925 - val_loss: 0.1717 - val_accuracy: 0.9628 - 52ms/epoch - 3ms/step\n",
      "Epoch 71/100\n",
      "20/20 - 0s - loss: 0.1024 - accuracy: 0.9900 - val_loss: 0.1808 - val_accuracy: 0.9554 - 60ms/epoch - 3ms/step\n",
      "Epoch 72/100\n",
      "20/20 - 0s - loss: 0.0972 - accuracy: 0.9925 - val_loss: 0.1880 - val_accuracy: 0.9480 - 59ms/epoch - 3ms/step\n",
      "Epoch 73/100\n",
      "20/20 - 0s - loss: 0.0973 - accuracy: 0.9900 - val_loss: 0.1582 - val_accuracy: 0.9665 - 53ms/epoch - 3ms/step\n",
      "Epoch 74/100\n",
      "20/20 - 0s - loss: 0.0969 - accuracy: 0.9900 - val_loss: 0.1682 - val_accuracy: 0.9628 - 56ms/epoch - 3ms/step\n",
      "Epoch 75/100\n",
      "20/20 - 0s - loss: 0.0945 - accuracy: 0.9925 - val_loss: 0.1645 - val_accuracy: 0.9591 - 59ms/epoch - 3ms/step\n",
      "Epoch 76/100\n",
      "20/20 - 0s - loss: 0.0927 - accuracy: 0.9925 - val_loss: 0.1595 - val_accuracy: 0.9665 - 66ms/epoch - 3ms/step\n",
      "Epoch 77/100\n",
      "20/20 - 0s - loss: 0.0917 - accuracy: 0.9925 - val_loss: 0.1970 - val_accuracy: 0.9331 - 67ms/epoch - 3ms/step\n",
      "Epoch 78/100\n",
      "20/20 - 0s - loss: 0.0931 - accuracy: 0.9900 - val_loss: 0.1745 - val_accuracy: 0.9591 - 52ms/epoch - 3ms/step\n",
      "Epoch 79/100\n",
      "20/20 - 0s - loss: 0.0917 - accuracy: 0.9900 - val_loss: 0.1639 - val_accuracy: 0.9591 - 52ms/epoch - 3ms/step\n",
      "Epoch 80/100\n",
      "20/20 - 0s - loss: 0.0900 - accuracy: 0.9925 - val_loss: 0.1725 - val_accuracy: 0.9554 - 48ms/epoch - 2ms/step\n",
      "Epoch 81/100\n",
      "20/20 - 0s - loss: 0.0883 - accuracy: 0.9925 - val_loss: 0.1662 - val_accuracy: 0.9591 - 59ms/epoch - 3ms/step\n",
      "Epoch 82/100\n",
      "20/20 - 0s - loss: 0.0874 - accuracy: 0.9925 - val_loss: 0.1593 - val_accuracy: 0.9628 - 54ms/epoch - 3ms/step\n",
      "Epoch 83/100\n",
      "20/20 - 0s - loss: 0.0873 - accuracy: 0.9925 - val_loss: 0.1499 - val_accuracy: 0.9665 - 54ms/epoch - 3ms/step\n",
      "Epoch 84/100\n",
      "20/20 - 0s - loss: 0.0867 - accuracy: 0.9925 - val_loss: 0.1737 - val_accuracy: 0.9591 - 58ms/epoch - 3ms/step\n",
      "Epoch 85/100\n",
      "20/20 - 0s - loss: 0.0857 - accuracy: 0.9925 - val_loss: 0.1642 - val_accuracy: 0.9517 - 51ms/epoch - 3ms/step\n",
      "Epoch 86/100\n",
      "20/20 - 0s - loss: 0.0936 - accuracy: 0.9825 - val_loss: 0.1710 - val_accuracy: 0.9628 - 59ms/epoch - 3ms/step\n",
      "Epoch 87/100\n",
      "20/20 - 0s - loss: 0.0895 - accuracy: 0.9900 - val_loss: 0.1870 - val_accuracy: 0.9442 - 52ms/epoch - 3ms/step\n",
      "Epoch 88/100\n",
      "20/20 - 0s - loss: 0.0855 - accuracy: 0.9925 - val_loss: 0.2229 - val_accuracy: 0.9257 - 69ms/epoch - 3ms/step\n",
      "Epoch 89/100\n",
      "20/20 - 0s - loss: 0.0864 - accuracy: 0.9900 - val_loss: 0.1574 - val_accuracy: 0.9591 - 54ms/epoch - 3ms/step\n",
      "Epoch 90/100\n",
      "20/20 - 0s - loss: 0.0816 - accuracy: 0.9925 - val_loss: 0.1570 - val_accuracy: 0.9591 - 56ms/epoch - 3ms/step\n",
      "Epoch 91/100\n",
      "20/20 - 0s - loss: 0.0805 - accuracy: 0.9925 - val_loss: 0.1412 - val_accuracy: 0.9703 - 51ms/epoch - 3ms/step\n",
      "Epoch 92/100\n",
      "20/20 - 0s - loss: 0.0802 - accuracy: 0.9925 - val_loss: 0.1701 - val_accuracy: 0.9517 - 54ms/epoch - 3ms/step\n",
      "Epoch 93/100\n",
      "20/20 - 0s - loss: 0.0786 - accuracy: 0.9925 - val_loss: 0.1579 - val_accuracy: 0.9591 - 71ms/epoch - 4ms/step\n",
      "Epoch 94/100\n",
      "20/20 - 0s - loss: 0.0786 - accuracy: 0.9925 - val_loss: 0.1668 - val_accuracy: 0.9517 - 62ms/epoch - 3ms/step\n",
      "Epoch 95/100\n",
      "20/20 - 0s - loss: 0.0774 - accuracy: 0.9925 - val_loss: 0.1723 - val_accuracy: 0.9517 - 53ms/epoch - 3ms/step\n",
      "Epoch 96/100\n",
      "20/20 - 0s - loss: 0.0787 - accuracy: 0.9925 - val_loss: 0.1599 - val_accuracy: 0.9628 - 55ms/epoch - 3ms/step\n",
      "Epoch 97/100\n",
      "20/20 - 0s - loss: 0.0771 - accuracy: 0.9925 - val_loss: 0.1539 - val_accuracy: 0.9665 - 53ms/epoch - 3ms/step\n",
      "Epoch 98/100\n",
      "20/20 - 0s - loss: 0.0814 - accuracy: 0.9900 - val_loss: 0.1459 - val_accuracy: 0.9665 - 60ms/epoch - 3ms/step\n",
      "Epoch 99/100\n",
      "20/20 - 0s - loss: 0.0883 - accuracy: 0.9825 - val_loss: 0.1449 - val_accuracy: 0.9554 - 67ms/epoch - 3ms/step\n",
      "Epoch 100/100\n",
      "20/20 - 0s - loss: 0.0924 - accuracy: 0.9825 - val_loss: 0.1385 - val_accuracy: 0.9628 - 60ms/epoch - 3ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "dim = X_train.shape[1]\n",
    "np.random.seed(2023)\n",
    "model = Sequential()\n",
    "model.add(Dense(30, activation='relu', input_dim=dim))\n",
    "model.add(Dense(10, activation='relu', input_dim=dim))\n",
    "model.add(Dense(3, activation='relu', input_dim=dim))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.fit(X_train, y_train_label, validation_data=(X_test, y_test_label), epochs=100, batch_size=20, verbose=2)\n",
    "predict_test = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Nc4AUGsx5uOK",
    "outputId": "5264c5d5-ef3f-48f6-9c0d-6f39b30a0b6d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9628252788104089"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Report accuracy \n",
    "test=pd.DataFrame()\n",
    "test['predict_test']=y_test_label\n",
    "test['predict_label'] = predict_test.flatten()\n",
    "test['predict_label_']=1.0*(test['predict_label']>0.5)\n",
    " #Test accuracy\n",
    "1.0*sum((test['predict_test']==1)==(test['predict_label']>0.5))/len(test['predict_label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HTMRMjGj5uOL"
   },
   "source": [
    "## Task 2. Classify all days of the week\n",
    "Train a neural network against the origial categorical label. Use 5 layers of 40,15,5 and 7 (outputs, representing probabilities for a current input to correspond to each of the weekdays) neurons over the training sample, evaluating its performance over the test sample (use 'categorical_accurary'). Report the acheived accuracy (categorical) over the test sample.\n",
    "\n",
    "First three layers use relu activation function, last one - sigmoid.\n",
    "Use loss='binary_crossentropy', optimizer='adam', 200 epochs, batch_size=20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kUwLjCgFXPCx",
    "outputId": "8d1a62cf-d852-449d-8408-681c460fd98b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "20/20 - 1s - loss: 0.6904 - categorical_accuracy: 0.1550 - val_loss: 0.6677 - val_categorical_accuracy: 0.1450 - 804ms/epoch - 40ms/step\n",
      "Epoch 2/200\n",
      "20/20 - 0s - loss: 0.6552 - categorical_accuracy: 0.1425 - val_loss: 0.6362 - val_categorical_accuracy: 0.1450 - 72ms/epoch - 4ms/step\n",
      "Epoch 3/200\n",
      "20/20 - 0s - loss: 0.6189 - categorical_accuracy: 0.1425 - val_loss: 0.5946 - val_categorical_accuracy: 0.1487 - 110ms/epoch - 5ms/step\n",
      "Epoch 4/200\n",
      "20/20 - 0s - loss: 0.5727 - categorical_accuracy: 0.1425 - val_loss: 0.5440 - val_categorical_accuracy: 0.1487 - 57ms/epoch - 3ms/step\n",
      "Epoch 5/200\n",
      "20/20 - 0s - loss: 0.5132 - categorical_accuracy: 0.1975 - val_loss: 0.4770 - val_categorical_accuracy: 0.1970 - 78ms/epoch - 4ms/step\n",
      "Epoch 6/200\n",
      "20/20 - 0s - loss: 0.4557 - categorical_accuracy: 0.2575 - val_loss: 0.4311 - val_categorical_accuracy: 0.2788 - 64ms/epoch - 3ms/step\n",
      "Epoch 7/200\n",
      "20/20 - 0s - loss: 0.4212 - categorical_accuracy: 0.2750 - val_loss: 0.4077 - val_categorical_accuracy: 0.2825 - 66ms/epoch - 3ms/step\n",
      "Epoch 8/200\n",
      "20/20 - 0s - loss: 0.4029 - categorical_accuracy: 0.2750 - val_loss: 0.3944 - val_categorical_accuracy: 0.2788 - 69ms/epoch - 3ms/step\n",
      "Epoch 9/200\n",
      "20/20 - 0s - loss: 0.3909 - categorical_accuracy: 0.2775 - val_loss: 0.3861 - val_categorical_accuracy: 0.2788 - 62ms/epoch - 3ms/step\n",
      "Epoch 10/200\n",
      "20/20 - 0s - loss: 0.3844 - categorical_accuracy: 0.2775 - val_loss: 0.3803 - val_categorical_accuracy: 0.2788 - 59ms/epoch - 3ms/step\n",
      "Epoch 11/200\n",
      "20/20 - 0s - loss: 0.3784 - categorical_accuracy: 0.2725 - val_loss: 0.3766 - val_categorical_accuracy: 0.2788 - 61ms/epoch - 3ms/step\n",
      "Epoch 12/200\n",
      "20/20 - 0s - loss: 0.3752 - categorical_accuracy: 0.2775 - val_loss: 0.3744 - val_categorical_accuracy: 0.2639 - 63ms/epoch - 3ms/step\n",
      "Epoch 13/200\n",
      "20/20 - 0s - loss: 0.3718 - categorical_accuracy: 0.2800 - val_loss: 0.3706 - val_categorical_accuracy: 0.2714 - 58ms/epoch - 3ms/step\n",
      "Epoch 14/200\n",
      "20/20 - 0s - loss: 0.3688 - categorical_accuracy: 0.2750 - val_loss: 0.3678 - val_categorical_accuracy: 0.2788 - 61ms/epoch - 3ms/step\n",
      "Epoch 15/200\n",
      "20/20 - 0s - loss: 0.3673 - categorical_accuracy: 0.2775 - val_loss: 0.3658 - val_categorical_accuracy: 0.2825 - 71ms/epoch - 4ms/step\n",
      "Epoch 16/200\n",
      "20/20 - 0s - loss: 0.3642 - categorical_accuracy: 0.2825 - val_loss: 0.3643 - val_categorical_accuracy: 0.2788 - 67ms/epoch - 3ms/step\n",
      "Epoch 17/200\n",
      "20/20 - 0s - loss: 0.3631 - categorical_accuracy: 0.2750 - val_loss: 0.3619 - val_categorical_accuracy: 0.2825 - 66ms/epoch - 3ms/step\n",
      "Epoch 18/200\n",
      "20/20 - 0s - loss: 0.3608 - categorical_accuracy: 0.3125 - val_loss: 0.3599 - val_categorical_accuracy: 0.2788 - 61ms/epoch - 3ms/step\n",
      "Epoch 19/200\n",
      "20/20 - 0s - loss: 0.3588 - categorical_accuracy: 0.2850 - val_loss: 0.3588 - val_categorical_accuracy: 0.3048 - 59ms/epoch - 3ms/step\n",
      "Epoch 20/200\n",
      "20/20 - 0s - loss: 0.3568 - categorical_accuracy: 0.3000 - val_loss: 0.3559 - val_categorical_accuracy: 0.2788 - 64ms/epoch - 3ms/step\n",
      "Epoch 21/200\n",
      "20/20 - 0s - loss: 0.3544 - categorical_accuracy: 0.2925 - val_loss: 0.3545 - val_categorical_accuracy: 0.2937 - 70ms/epoch - 4ms/step\n",
      "Epoch 22/200\n",
      "20/20 - 0s - loss: 0.3527 - categorical_accuracy: 0.3150 - val_loss: 0.3527 - val_categorical_accuracy: 0.2937 - 57ms/epoch - 3ms/step\n",
      "Epoch 23/200\n",
      "20/20 - 0s - loss: 0.3522 - categorical_accuracy: 0.3025 - val_loss: 0.3512 - val_categorical_accuracy: 0.2974 - 67ms/epoch - 3ms/step\n",
      "Epoch 24/200\n",
      "20/20 - 0s - loss: 0.3496 - categorical_accuracy: 0.3175 - val_loss: 0.3500 - val_categorical_accuracy: 0.3532 - 80ms/epoch - 4ms/step\n",
      "Epoch 25/200\n",
      "20/20 - 0s - loss: 0.3479 - categorical_accuracy: 0.3350 - val_loss: 0.3491 - val_categorical_accuracy: 0.3234 - 65ms/epoch - 3ms/step\n",
      "Epoch 26/200\n",
      "20/20 - 0s - loss: 0.3475 - categorical_accuracy: 0.3425 - val_loss: 0.3484 - val_categorical_accuracy: 0.2825 - 65ms/epoch - 3ms/step\n",
      "Epoch 27/200\n",
      "20/20 - 0s - loss: 0.3457 - categorical_accuracy: 0.3000 - val_loss: 0.3471 - val_categorical_accuracy: 0.3011 - 54ms/epoch - 3ms/step\n",
      "Epoch 28/200\n",
      "20/20 - 0s - loss: 0.3449 - categorical_accuracy: 0.3150 - val_loss: 0.3456 - val_categorical_accuracy: 0.3717 - 63ms/epoch - 3ms/step\n",
      "Epoch 29/200\n",
      "20/20 - 0s - loss: 0.3429 - categorical_accuracy: 0.3450 - val_loss: 0.3441 - val_categorical_accuracy: 0.3569 - 71ms/epoch - 4ms/step\n",
      "Epoch 30/200\n",
      "20/20 - 0s - loss: 0.3421 - categorical_accuracy: 0.3425 - val_loss: 0.3439 - val_categorical_accuracy: 0.3606 - 58ms/epoch - 3ms/step\n",
      "Epoch 31/200\n",
      "20/20 - 0s - loss: 0.3402 - categorical_accuracy: 0.3450 - val_loss: 0.3429 - val_categorical_accuracy: 0.3011 - 64ms/epoch - 3ms/step\n",
      "Epoch 32/200\n",
      "20/20 - 0s - loss: 0.3392 - categorical_accuracy: 0.3275 - val_loss: 0.3407 - val_categorical_accuracy: 0.3717 - 61ms/epoch - 3ms/step\n",
      "Epoch 33/200\n",
      "20/20 - 0s - loss: 0.3379 - categorical_accuracy: 0.3350 - val_loss: 0.3451 - val_categorical_accuracy: 0.2974 - 79ms/epoch - 4ms/step\n",
      "Epoch 34/200\n",
      "20/20 - 0s - loss: 0.3381 - categorical_accuracy: 0.3050 - val_loss: 0.3397 - val_categorical_accuracy: 0.3383 - 67ms/epoch - 3ms/step\n",
      "Epoch 35/200\n",
      "20/20 - 0s - loss: 0.3367 - categorical_accuracy: 0.3100 - val_loss: 0.3386 - val_categorical_accuracy: 0.3383 - 68ms/epoch - 3ms/step\n",
      "Epoch 36/200\n",
      "20/20 - 0s - loss: 0.3366 - categorical_accuracy: 0.2700 - val_loss: 0.3394 - val_categorical_accuracy: 0.2751 - 58ms/epoch - 3ms/step\n",
      "Epoch 37/200\n",
      "20/20 - 0s - loss: 0.3348 - categorical_accuracy: 0.3400 - val_loss: 0.3379 - val_categorical_accuracy: 0.3643 - 65ms/epoch - 3ms/step\n",
      "Epoch 38/200\n",
      "20/20 - 0s - loss: 0.3336 - categorical_accuracy: 0.3450 - val_loss: 0.3368 - val_categorical_accuracy: 0.3569 - 61ms/epoch - 3ms/step\n",
      "Epoch 39/200\n",
      "20/20 - 0s - loss: 0.3324 - categorical_accuracy: 0.2875 - val_loss: 0.3361 - val_categorical_accuracy: 0.2825 - 64ms/epoch - 3ms/step\n",
      "Epoch 40/200\n",
      "20/20 - 0s - loss: 0.3323 - categorical_accuracy: 0.2850 - val_loss: 0.3358 - val_categorical_accuracy: 0.3383 - 62ms/epoch - 3ms/step\n",
      "Epoch 41/200\n",
      "20/20 - 0s - loss: 0.3319 - categorical_accuracy: 0.3375 - val_loss: 0.3389 - val_categorical_accuracy: 0.2825 - 63ms/epoch - 3ms/step\n",
      "Epoch 42/200\n",
      "20/20 - 0s - loss: 0.3323 - categorical_accuracy: 0.3450 - val_loss: 0.3382 - val_categorical_accuracy: 0.3569 - 70ms/epoch - 3ms/step\n",
      "Epoch 43/200\n",
      "20/20 - 0s - loss: 0.3304 - categorical_accuracy: 0.2850 - val_loss: 0.3349 - val_categorical_accuracy: 0.2751 - 67ms/epoch - 3ms/step\n",
      "Epoch 44/200\n",
      "20/20 - 0s - loss: 0.3295 - categorical_accuracy: 0.2825 - val_loss: 0.3337 - val_categorical_accuracy: 0.2974 - 71ms/epoch - 4ms/step\n",
      "Epoch 45/200\n",
      "20/20 - 0s - loss: 0.3286 - categorical_accuracy: 0.3475 - val_loss: 0.3343 - val_categorical_accuracy: 0.2862 - 61ms/epoch - 3ms/step\n",
      "Epoch 46/200\n",
      "20/20 - 0s - loss: 0.3282 - categorical_accuracy: 0.3150 - val_loss: 0.3326 - val_categorical_accuracy: 0.3494 - 60ms/epoch - 3ms/step\n",
      "Epoch 47/200\n",
      "20/20 - 0s - loss: 0.3280 - categorical_accuracy: 0.3525 - val_loss: 0.3330 - val_categorical_accuracy: 0.3643 - 67ms/epoch - 3ms/step\n",
      "Epoch 48/200\n",
      "20/20 - 0s - loss: 0.3272 - categorical_accuracy: 0.3300 - val_loss: 0.3320 - val_categorical_accuracy: 0.3792 - 64ms/epoch - 3ms/step\n",
      "Epoch 49/200\n",
      "20/20 - 0s - loss: 0.3258 - categorical_accuracy: 0.3725 - val_loss: 0.3318 - val_categorical_accuracy: 0.3123 - 68ms/epoch - 3ms/step\n",
      "Epoch 50/200\n",
      "20/20 - 0s - loss: 0.3259 - categorical_accuracy: 0.3175 - val_loss: 0.3318 - val_categorical_accuracy: 0.3346 - 61ms/epoch - 3ms/step\n",
      "Epoch 51/200\n",
      "20/20 - 0s - loss: 0.3258 - categorical_accuracy: 0.3350 - val_loss: 0.3336 - val_categorical_accuracy: 0.3903 - 63ms/epoch - 3ms/step\n",
      "Epoch 52/200\n",
      "20/20 - 0s - loss: 0.3248 - categorical_accuracy: 0.3925 - val_loss: 0.3318 - val_categorical_accuracy: 0.3643 - 65ms/epoch - 3ms/step\n",
      "Epoch 53/200\n",
      "20/20 - 0s - loss: 0.3241 - categorical_accuracy: 0.3625 - val_loss: 0.3313 - val_categorical_accuracy: 0.3569 - 72ms/epoch - 4ms/step\n",
      "Epoch 54/200\n",
      "20/20 - 0s - loss: 0.3229 - categorical_accuracy: 0.3550 - val_loss: 0.3302 - val_categorical_accuracy: 0.3494 - 61ms/epoch - 3ms/step\n",
      "Epoch 55/200\n",
      "20/20 - 0s - loss: 0.3224 - categorical_accuracy: 0.3525 - val_loss: 0.3298 - val_categorical_accuracy: 0.4387 - 66ms/epoch - 3ms/step\n",
      "Epoch 56/200\n",
      "20/20 - 0s - loss: 0.3220 - categorical_accuracy: 0.3825 - val_loss: 0.3296 - val_categorical_accuracy: 0.3829 - 61ms/epoch - 3ms/step\n",
      "Epoch 57/200\n",
      "20/20 - 0s - loss: 0.3210 - categorical_accuracy: 0.3800 - val_loss: 0.3291 - val_categorical_accuracy: 0.3383 - 58ms/epoch - 3ms/step\n",
      "Epoch 58/200\n",
      "20/20 - 0s - loss: 0.3208 - categorical_accuracy: 0.3550 - val_loss: 0.3290 - val_categorical_accuracy: 0.3606 - 73ms/epoch - 4ms/step\n",
      "Epoch 59/200\n",
      "20/20 - 0s - loss: 0.3206 - categorical_accuracy: 0.3950 - val_loss: 0.3284 - val_categorical_accuracy: 0.4312 - 66ms/epoch - 3ms/step\n",
      "Epoch 60/200\n",
      "20/20 - 0s - loss: 0.3201 - categorical_accuracy: 0.3225 - val_loss: 0.3281 - val_categorical_accuracy: 0.3494 - 67ms/epoch - 3ms/step\n",
      "Epoch 61/200\n",
      "20/20 - 0s - loss: 0.3196 - categorical_accuracy: 0.3750 - val_loss: 0.3279 - val_categorical_accuracy: 0.3792 - 53ms/epoch - 3ms/step\n",
      "Epoch 62/200\n",
      "20/20 - 0s - loss: 0.3194 - categorical_accuracy: 0.3400 - val_loss: 0.3278 - val_categorical_accuracy: 0.3978 - 66ms/epoch - 3ms/step\n",
      "Epoch 63/200\n",
      "20/20 - 0s - loss: 0.3184 - categorical_accuracy: 0.3575 - val_loss: 0.3279 - val_categorical_accuracy: 0.3941 - 57ms/epoch - 3ms/step\n",
      "Epoch 64/200\n",
      "20/20 - 0s - loss: 0.3180 - categorical_accuracy: 0.3575 - val_loss: 0.3282 - val_categorical_accuracy: 0.3271 - 69ms/epoch - 3ms/step\n",
      "Epoch 65/200\n",
      "20/20 - 0s - loss: 0.3169 - categorical_accuracy: 0.4150 - val_loss: 0.3268 - val_categorical_accuracy: 0.3978 - 66ms/epoch - 3ms/step\n",
      "Epoch 66/200\n",
      "20/20 - 0s - loss: 0.3168 - categorical_accuracy: 0.3650 - val_loss: 0.3279 - val_categorical_accuracy: 0.3680 - 61ms/epoch - 3ms/step\n",
      "Epoch 67/200\n",
      "20/20 - 0s - loss: 0.3164 - categorical_accuracy: 0.3850 - val_loss: 0.3290 - val_categorical_accuracy: 0.3680 - 59ms/epoch - 3ms/step\n",
      "Epoch 68/200\n",
      "20/20 - 0s - loss: 0.3156 - categorical_accuracy: 0.4100 - val_loss: 0.3260 - val_categorical_accuracy: 0.3903 - 65ms/epoch - 3ms/step\n",
      "Epoch 69/200\n",
      "20/20 - 0s - loss: 0.3154 - categorical_accuracy: 0.3800 - val_loss: 0.3256 - val_categorical_accuracy: 0.3532 - 104ms/epoch - 5ms/step\n",
      "Epoch 70/200\n",
      "20/20 - 0s - loss: 0.3146 - categorical_accuracy: 0.4000 - val_loss: 0.3257 - val_categorical_accuracy: 0.3792 - 58ms/epoch - 3ms/step\n",
      "Epoch 71/200\n",
      "20/20 - 0s - loss: 0.3135 - categorical_accuracy: 0.4200 - val_loss: 0.3271 - val_categorical_accuracy: 0.3903 - 59ms/epoch - 3ms/step\n",
      "Epoch 72/200\n",
      "20/20 - 0s - loss: 0.3137 - categorical_accuracy: 0.4000 - val_loss: 0.3249 - val_categorical_accuracy: 0.3792 - 73ms/epoch - 4ms/step\n",
      "Epoch 73/200\n",
      "20/20 - 0s - loss: 0.3124 - categorical_accuracy: 0.4250 - val_loss: 0.3265 - val_categorical_accuracy: 0.4461 - 56ms/epoch - 3ms/step\n",
      "Epoch 74/200\n",
      "20/20 - 0s - loss: 0.3129 - categorical_accuracy: 0.3750 - val_loss: 0.3240 - val_categorical_accuracy: 0.3941 - 62ms/epoch - 3ms/step\n",
      "Epoch 75/200\n",
      "20/20 - 0s - loss: 0.3115 - categorical_accuracy: 0.4250 - val_loss: 0.3246 - val_categorical_accuracy: 0.4535 - 57ms/epoch - 3ms/step\n",
      "Epoch 76/200\n",
      "20/20 - 0s - loss: 0.3109 - categorical_accuracy: 0.4150 - val_loss: 0.3239 - val_categorical_accuracy: 0.4275 - 63ms/epoch - 3ms/step\n",
      "Epoch 77/200\n",
      "20/20 - 0s - loss: 0.3105 - categorical_accuracy: 0.4100 - val_loss: 0.3247 - val_categorical_accuracy: 0.3829 - 73ms/epoch - 4ms/step\n",
      "Epoch 78/200\n",
      "20/20 - 0s - loss: 0.3092 - categorical_accuracy: 0.4425 - val_loss: 0.3230 - val_categorical_accuracy: 0.3903 - 72ms/epoch - 4ms/step\n",
      "Epoch 79/200\n",
      "20/20 - 0s - loss: 0.3084 - categorical_accuracy: 0.4325 - val_loss: 0.3247 - val_categorical_accuracy: 0.4498 - 59ms/epoch - 3ms/step\n",
      "Epoch 80/200\n",
      "20/20 - 0s - loss: 0.3079 - categorical_accuracy: 0.4700 - val_loss: 0.3230 - val_categorical_accuracy: 0.4164 - 63ms/epoch - 3ms/step\n",
      "Epoch 81/200\n",
      "20/20 - 0s - loss: 0.3070 - categorical_accuracy: 0.4225 - val_loss: 0.3217 - val_categorical_accuracy: 0.3903 - 62ms/epoch - 3ms/step\n",
      "Epoch 82/200\n",
      "20/20 - 0s - loss: 0.3069 - categorical_accuracy: 0.4150 - val_loss: 0.3213 - val_categorical_accuracy: 0.4238 - 63ms/epoch - 3ms/step\n",
      "Epoch 83/200\n",
      "20/20 - 0s - loss: 0.3066 - categorical_accuracy: 0.4300 - val_loss: 0.3221 - val_categorical_accuracy: 0.4275 - 59ms/epoch - 3ms/step\n",
      "Epoch 84/200\n",
      "20/20 - 0s - loss: 0.3039 - categorical_accuracy: 0.4400 - val_loss: 0.3214 - val_categorical_accuracy: 0.3941 - 59ms/epoch - 3ms/step\n",
      "Epoch 85/200\n",
      "20/20 - 0s - loss: 0.3037 - categorical_accuracy: 0.4475 - val_loss: 0.3199 - val_categorical_accuracy: 0.4684 - 63ms/epoch - 3ms/step\n",
      "Epoch 86/200\n",
      "20/20 - 0s - loss: 0.3024 - categorical_accuracy: 0.4450 - val_loss: 0.3194 - val_categorical_accuracy: 0.4052 - 71ms/epoch - 4ms/step\n",
      "Epoch 87/200\n",
      "20/20 - 0s - loss: 0.3021 - categorical_accuracy: 0.4450 - val_loss: 0.3198 - val_categorical_accuracy: 0.4424 - 65ms/epoch - 3ms/step\n",
      "Epoch 88/200\n",
      "20/20 - 0s - loss: 0.3008 - categorical_accuracy: 0.4600 - val_loss: 0.3181 - val_categorical_accuracy: 0.4275 - 58ms/epoch - 3ms/step\n",
      "Epoch 89/200\n",
      "20/20 - 0s - loss: 0.3007 - categorical_accuracy: 0.4400 - val_loss: 0.3178 - val_categorical_accuracy: 0.4126 - 75ms/epoch - 4ms/step\n",
      "Epoch 90/200\n",
      "20/20 - 0s - loss: 0.3004 - categorical_accuracy: 0.4500 - val_loss: 0.3183 - val_categorical_accuracy: 0.4164 - 82ms/epoch - 4ms/step\n",
      "Epoch 91/200\n",
      "20/20 - 0s - loss: 0.2990 - categorical_accuracy: 0.4450 - val_loss: 0.3181 - val_categorical_accuracy: 0.4275 - 97ms/epoch - 5ms/step\n",
      "Epoch 92/200\n",
      "20/20 - 0s - loss: 0.2983 - categorical_accuracy: 0.4450 - val_loss: 0.3160 - val_categorical_accuracy: 0.4015 - 85ms/epoch - 4ms/step\n",
      "Epoch 93/200\n",
      "20/20 - 0s - loss: 0.2993 - categorical_accuracy: 0.4475 - val_loss: 0.3200 - val_categorical_accuracy: 0.4535 - 82ms/epoch - 4ms/step\n",
      "Epoch 94/200\n",
      "20/20 - 0s - loss: 0.2966 - categorical_accuracy: 0.4625 - val_loss: 0.3188 - val_categorical_accuracy: 0.3792 - 77ms/epoch - 4ms/step\n",
      "Epoch 95/200\n",
      "20/20 - 0s - loss: 0.2945 - categorical_accuracy: 0.4575 - val_loss: 0.3157 - val_categorical_accuracy: 0.4387 - 72ms/epoch - 4ms/step\n",
      "Epoch 96/200\n",
      "20/20 - 0s - loss: 0.2935 - categorical_accuracy: 0.4875 - val_loss: 0.3132 - val_categorical_accuracy: 0.4684 - 77ms/epoch - 4ms/step\n",
      "Epoch 97/200\n",
      "20/20 - 0s - loss: 0.2919 - categorical_accuracy: 0.4975 - val_loss: 0.3124 - val_categorical_accuracy: 0.4721 - 84ms/epoch - 4ms/step\n",
      "Epoch 98/200\n",
      "20/20 - 0s - loss: 0.2907 - categorical_accuracy: 0.4900 - val_loss: 0.3113 - val_categorical_accuracy: 0.4572 - 75ms/epoch - 4ms/step\n",
      "Epoch 99/200\n",
      "20/20 - 0s - loss: 0.2901 - categorical_accuracy: 0.4925 - val_loss: 0.3116 - val_categorical_accuracy: 0.4647 - 89ms/epoch - 4ms/step\n",
      "Epoch 100/200\n",
      "20/20 - 0s - loss: 0.2883 - categorical_accuracy: 0.4750 - val_loss: 0.3112 - val_categorical_accuracy: 0.4944 - 83ms/epoch - 4ms/step\n",
      "Epoch 101/200\n",
      "20/20 - 0s - loss: 0.2874 - categorical_accuracy: 0.4975 - val_loss: 0.3087 - val_categorical_accuracy: 0.4647 - 94ms/epoch - 5ms/step\n",
      "Epoch 102/200\n",
      "20/20 - 0s - loss: 0.2856 - categorical_accuracy: 0.5225 - val_loss: 0.3096 - val_categorical_accuracy: 0.5130 - 75ms/epoch - 4ms/step\n",
      "Epoch 103/200\n",
      "20/20 - 0s - loss: 0.2856 - categorical_accuracy: 0.5000 - val_loss: 0.3085 - val_categorical_accuracy: 0.4424 - 121ms/epoch - 6ms/step\n",
      "Epoch 104/200\n",
      "20/20 - 0s - loss: 0.2845 - categorical_accuracy: 0.4900 - val_loss: 0.3066 - val_categorical_accuracy: 0.4424 - 84ms/epoch - 4ms/step\n",
      "Epoch 105/200\n",
      "20/20 - 0s - loss: 0.2840 - categorical_accuracy: 0.4775 - val_loss: 0.3081 - val_categorical_accuracy: 0.4684 - 72ms/epoch - 4ms/step\n",
      "Epoch 106/200\n",
      "20/20 - 0s - loss: 0.2821 - categorical_accuracy: 0.4900 - val_loss: 0.3057 - val_categorical_accuracy: 0.4312 - 80ms/epoch - 4ms/step\n",
      "Epoch 107/200\n",
      "20/20 - 0s - loss: 0.2793 - categorical_accuracy: 0.4850 - val_loss: 0.3040 - val_categorical_accuracy: 0.4870 - 77ms/epoch - 4ms/step\n",
      "Epoch 108/200\n",
      "20/20 - 0s - loss: 0.2789 - categorical_accuracy: 0.4950 - val_loss: 0.3081 - val_categorical_accuracy: 0.4535 - 77ms/epoch - 4ms/step\n",
      "Epoch 109/200\n",
      "20/20 - 0s - loss: 0.2783 - categorical_accuracy: 0.5275 - val_loss: 0.3063 - val_categorical_accuracy: 0.4981 - 87ms/epoch - 4ms/step\n",
      "Epoch 110/200\n",
      "20/20 - 0s - loss: 0.2776 - categorical_accuracy: 0.5250 - val_loss: 0.3045 - val_categorical_accuracy: 0.4610 - 83ms/epoch - 4ms/step\n",
      "Epoch 111/200\n",
      "20/20 - 0s - loss: 0.2760 - categorical_accuracy: 0.5050 - val_loss: 0.3020 - val_categorical_accuracy: 0.5242 - 123ms/epoch - 6ms/step\n",
      "Epoch 112/200\n",
      "20/20 - 0s - loss: 0.2733 - categorical_accuracy: 0.5200 - val_loss: 0.3013 - val_categorical_accuracy: 0.4610 - 60ms/epoch - 3ms/step\n",
      "Epoch 113/200\n",
      "20/20 - 0s - loss: 0.2729 - categorical_accuracy: 0.5375 - val_loss: 0.3016 - val_categorical_accuracy: 0.4684 - 73ms/epoch - 4ms/step\n",
      "Epoch 114/200\n",
      "20/20 - 0s - loss: 0.2709 - categorical_accuracy: 0.5525 - val_loss: 0.2994 - val_categorical_accuracy: 0.4833 - 59ms/epoch - 3ms/step\n",
      "Epoch 115/200\n",
      "20/20 - 0s - loss: 0.2692 - categorical_accuracy: 0.5175 - val_loss: 0.2985 - val_categorical_accuracy: 0.4981 - 79ms/epoch - 4ms/step\n",
      "Epoch 116/200\n",
      "20/20 - 0s - loss: 0.2689 - categorical_accuracy: 0.5375 - val_loss: 0.2978 - val_categorical_accuracy: 0.4944 - 58ms/epoch - 3ms/step\n",
      "Epoch 117/200\n",
      "20/20 - 0s - loss: 0.2685 - categorical_accuracy: 0.5075 - val_loss: 0.2985 - val_categorical_accuracy: 0.4647 - 57ms/epoch - 3ms/step\n",
      "Epoch 118/200\n",
      "20/20 - 0s - loss: 0.2672 - categorical_accuracy: 0.5250 - val_loss: 0.2976 - val_categorical_accuracy: 0.4870 - 59ms/epoch - 3ms/step\n",
      "Epoch 119/200\n",
      "20/20 - 0s - loss: 0.2654 - categorical_accuracy: 0.5375 - val_loss: 0.3027 - val_categorical_accuracy: 0.4758 - 61ms/epoch - 3ms/step\n",
      "Epoch 120/200\n",
      "20/20 - 0s - loss: 0.2677 - categorical_accuracy: 0.5150 - val_loss: 0.2978 - val_categorical_accuracy: 0.5204 - 61ms/epoch - 3ms/step\n",
      "Epoch 121/200\n",
      "20/20 - 0s - loss: 0.2641 - categorical_accuracy: 0.5275 - val_loss: 0.2944 - val_categorical_accuracy: 0.4796 - 60ms/epoch - 3ms/step\n",
      "Epoch 122/200\n",
      "20/20 - 0s - loss: 0.2652 - categorical_accuracy: 0.4800 - val_loss: 0.3028 - val_categorical_accuracy: 0.4387 - 75ms/epoch - 4ms/step\n",
      "Epoch 123/200\n",
      "20/20 - 0s - loss: 0.2635 - categorical_accuracy: 0.4975 - val_loss: 0.2964 - val_categorical_accuracy: 0.4796 - 70ms/epoch - 4ms/step\n",
      "Epoch 124/200\n",
      "20/20 - 0s - loss: 0.2626 - categorical_accuracy: 0.5300 - val_loss: 0.3030 - val_categorical_accuracy: 0.4535 - 59ms/epoch - 3ms/step\n",
      "Epoch 125/200\n",
      "20/20 - 0s - loss: 0.2634 - categorical_accuracy: 0.4925 - val_loss: 0.2946 - val_categorical_accuracy: 0.4944 - 67ms/epoch - 3ms/step\n",
      "Epoch 126/200\n",
      "20/20 - 0s - loss: 0.2576 - categorical_accuracy: 0.5750 - val_loss: 0.2918 - val_categorical_accuracy: 0.5204 - 65ms/epoch - 3ms/step\n",
      "Epoch 127/200\n",
      "20/20 - 0s - loss: 0.2564 - categorical_accuracy: 0.5275 - val_loss: 0.2931 - val_categorical_accuracy: 0.5316 - 82ms/epoch - 4ms/step\n",
      "Epoch 128/200\n",
      "20/20 - 0s - loss: 0.2553 - categorical_accuracy: 0.5575 - val_loss: 0.2906 - val_categorical_accuracy: 0.5242 - 64ms/epoch - 3ms/step\n",
      "Epoch 129/200\n",
      "20/20 - 0s - loss: 0.2548 - categorical_accuracy: 0.5125 - val_loss: 0.2904 - val_categorical_accuracy: 0.5279 - 68ms/epoch - 3ms/step\n",
      "Epoch 130/200\n",
      "20/20 - 0s - loss: 0.2545 - categorical_accuracy: 0.5225 - val_loss: 0.2919 - val_categorical_accuracy: 0.4907 - 67ms/epoch - 3ms/step\n",
      "Epoch 131/200\n",
      "20/20 - 0s - loss: 0.2542 - categorical_accuracy: 0.5450 - val_loss: 0.2934 - val_categorical_accuracy: 0.5353 - 64ms/epoch - 3ms/step\n",
      "Epoch 132/200\n",
      "20/20 - 0s - loss: 0.2563 - categorical_accuracy: 0.5375 - val_loss: 0.2910 - val_categorical_accuracy: 0.5390 - 59ms/epoch - 3ms/step\n",
      "Epoch 133/200\n",
      "20/20 - 0s - loss: 0.2530 - categorical_accuracy: 0.5600 - val_loss: 0.2911 - val_categorical_accuracy: 0.5019 - 64ms/epoch - 3ms/step\n",
      "Epoch 134/200\n",
      "20/20 - 0s - loss: 0.2516 - categorical_accuracy: 0.5325 - val_loss: 0.2903 - val_categorical_accuracy: 0.5056 - 58ms/epoch - 3ms/step\n",
      "Epoch 135/200\n",
      "20/20 - 0s - loss: 0.2488 - categorical_accuracy: 0.5500 - val_loss: 0.2904 - val_categorical_accuracy: 0.5428 - 54ms/epoch - 3ms/step\n",
      "Epoch 136/200\n",
      "20/20 - 0s - loss: 0.2496 - categorical_accuracy: 0.5675 - val_loss: 0.2884 - val_categorical_accuracy: 0.5428 - 64ms/epoch - 3ms/step\n",
      "Epoch 137/200\n",
      "20/20 - 0s - loss: 0.2497 - categorical_accuracy: 0.5250 - val_loss: 0.2976 - val_categorical_accuracy: 0.5130 - 69ms/epoch - 3ms/step\n",
      "Epoch 138/200\n",
      "20/20 - 0s - loss: 0.2486 - categorical_accuracy: 0.5325 - val_loss: 0.2882 - val_categorical_accuracy: 0.5130 - 75ms/epoch - 4ms/step\n",
      "Epoch 139/200\n",
      "20/20 - 0s - loss: 0.2461 - categorical_accuracy: 0.5475 - val_loss: 0.2905 - val_categorical_accuracy: 0.5502 - 61ms/epoch - 3ms/step\n",
      "Epoch 140/200\n",
      "20/20 - 0s - loss: 0.2440 - categorical_accuracy: 0.5675 - val_loss: 0.2882 - val_categorical_accuracy: 0.5353 - 56ms/epoch - 3ms/step\n",
      "Epoch 141/200\n",
      "20/20 - 0s - loss: 0.2445 - categorical_accuracy: 0.5450 - val_loss: 0.2879 - val_categorical_accuracy: 0.5390 - 64ms/epoch - 3ms/step\n",
      "Epoch 142/200\n",
      "20/20 - 0s - loss: 0.2449 - categorical_accuracy: 0.5475 - val_loss: 0.2885 - val_categorical_accuracy: 0.5502 - 63ms/epoch - 3ms/step\n",
      "Epoch 143/200\n",
      "20/20 - 0s - loss: 0.2442 - categorical_accuracy: 0.5450 - val_loss: 0.2877 - val_categorical_accuracy: 0.5167 - 64ms/epoch - 3ms/step\n",
      "Epoch 144/200\n",
      "20/20 - 0s - loss: 0.2425 - categorical_accuracy: 0.5350 - val_loss: 0.2906 - val_categorical_accuracy: 0.5093 - 55ms/epoch - 3ms/step\n",
      "Epoch 145/200\n",
      "20/20 - 0s - loss: 0.2417 - categorical_accuracy: 0.5675 - val_loss: 0.2892 - val_categorical_accuracy: 0.5130 - 72ms/epoch - 4ms/step\n",
      "Epoch 146/200\n",
      "20/20 - 0s - loss: 0.2440 - categorical_accuracy: 0.5375 - val_loss: 0.2872 - val_categorical_accuracy: 0.5390 - 59ms/epoch - 3ms/step\n",
      "Epoch 147/200\n",
      "20/20 - 0s - loss: 0.2395 - categorical_accuracy: 0.5725 - val_loss: 0.2874 - val_categorical_accuracy: 0.5465 - 66ms/epoch - 3ms/step\n",
      "Epoch 148/200\n",
      "20/20 - 0s - loss: 0.2379 - categorical_accuracy: 0.5600 - val_loss: 0.2860 - val_categorical_accuracy: 0.5316 - 69ms/epoch - 3ms/step\n",
      "Epoch 149/200\n",
      "20/20 - 0s - loss: 0.2387 - categorical_accuracy: 0.5875 - val_loss: 0.2869 - val_categorical_accuracy: 0.5502 - 55ms/epoch - 3ms/step\n",
      "Epoch 150/200\n",
      "20/20 - 0s - loss: 0.2375 - categorical_accuracy: 0.5775 - val_loss: 0.2855 - val_categorical_accuracy: 0.5242 - 65ms/epoch - 3ms/step\n",
      "Epoch 151/200\n",
      "20/20 - 0s - loss: 0.2364 - categorical_accuracy: 0.5975 - val_loss: 0.2868 - val_categorical_accuracy: 0.5428 - 69ms/epoch - 3ms/step\n",
      "Epoch 152/200\n",
      "20/20 - 0s - loss: 0.2344 - categorical_accuracy: 0.6250 - val_loss: 0.2872 - val_categorical_accuracy: 0.6208 - 64ms/epoch - 3ms/step\n",
      "Epoch 153/200\n",
      "20/20 - 0s - loss: 0.2307 - categorical_accuracy: 0.6525 - val_loss: 0.2809 - val_categorical_accuracy: 0.6134 - 65ms/epoch - 3ms/step\n",
      "Epoch 154/200\n",
      "20/20 - 0s - loss: 0.2275 - categorical_accuracy: 0.6525 - val_loss: 0.2803 - val_categorical_accuracy: 0.6171 - 67ms/epoch - 3ms/step\n",
      "Epoch 155/200\n",
      "20/20 - 0s - loss: 0.2257 - categorical_accuracy: 0.6350 - val_loss: 0.2786 - val_categorical_accuracy: 0.6134 - 55ms/epoch - 3ms/step\n",
      "Epoch 156/200\n",
      "20/20 - 0s - loss: 0.2229 - categorical_accuracy: 0.6600 - val_loss: 0.2755 - val_categorical_accuracy: 0.6097 - 62ms/epoch - 3ms/step\n",
      "Epoch 157/200\n",
      "20/20 - 0s - loss: 0.2237 - categorical_accuracy: 0.6375 - val_loss: 0.2788 - val_categorical_accuracy: 0.5688 - 70ms/epoch - 3ms/step\n",
      "Epoch 158/200\n",
      "20/20 - 0s - loss: 0.2237 - categorical_accuracy: 0.6425 - val_loss: 0.2734 - val_categorical_accuracy: 0.6059 - 67ms/epoch - 3ms/step\n",
      "Epoch 159/200\n",
      "20/20 - 0s - loss: 0.2217 - categorical_accuracy: 0.6325 - val_loss: 0.2711 - val_categorical_accuracy: 0.6320 - 65ms/epoch - 3ms/step\n",
      "Epoch 160/200\n",
      "20/20 - 0s - loss: 0.2162 - categorical_accuracy: 0.6300 - val_loss: 0.2702 - val_categorical_accuracy: 0.6245 - 70ms/epoch - 4ms/step\n",
      "Epoch 161/200\n",
      "20/20 - 0s - loss: 0.2120 - categorical_accuracy: 0.6475 - val_loss: 0.2799 - val_categorical_accuracy: 0.6022 - 65ms/epoch - 3ms/step\n",
      "Epoch 162/200\n",
      "20/20 - 0s - loss: 0.2085 - categorical_accuracy: 0.6475 - val_loss: 0.2653 - val_categorical_accuracy: 0.6208 - 57ms/epoch - 3ms/step\n",
      "Epoch 163/200\n",
      "20/20 - 0s - loss: 0.2074 - categorical_accuracy: 0.6550 - val_loss: 0.2698 - val_categorical_accuracy: 0.6320 - 67ms/epoch - 3ms/step\n",
      "Epoch 164/200\n",
      "20/20 - 0s - loss: 0.2042 - categorical_accuracy: 0.6500 - val_loss: 0.2644 - val_categorical_accuracy: 0.6171 - 64ms/epoch - 3ms/step\n",
      "Epoch 165/200\n",
      "20/20 - 0s - loss: 0.2058 - categorical_accuracy: 0.6575 - val_loss: 0.2650 - val_categorical_accuracy: 0.6431 - 61ms/epoch - 3ms/step\n",
      "Epoch 166/200\n",
      "20/20 - 0s - loss: 0.2013 - categorical_accuracy: 0.6625 - val_loss: 0.2622 - val_categorical_accuracy: 0.6283 - 59ms/epoch - 3ms/step\n",
      "Epoch 167/200\n",
      "20/20 - 0s - loss: 0.2022 - categorical_accuracy: 0.6500 - val_loss: 0.2624 - val_categorical_accuracy: 0.6245 - 63ms/epoch - 3ms/step\n",
      "Epoch 168/200\n",
      "20/20 - 0s - loss: 0.1978 - categorical_accuracy: 0.6675 - val_loss: 0.2636 - val_categorical_accuracy: 0.6022 - 69ms/epoch - 3ms/step\n",
      "Epoch 169/200\n",
      "20/20 - 0s - loss: 0.1989 - categorical_accuracy: 0.6800 - val_loss: 0.2621 - val_categorical_accuracy: 0.6059 - 63ms/epoch - 3ms/step\n",
      "Epoch 170/200\n",
      "20/20 - 0s - loss: 0.2008 - categorical_accuracy: 0.6575 - val_loss: 0.2604 - val_categorical_accuracy: 0.6171 - 68ms/epoch - 3ms/step\n",
      "Epoch 171/200\n",
      "20/20 - 0s - loss: 0.1985 - categorical_accuracy: 0.6525 - val_loss: 0.2605 - val_categorical_accuracy: 0.6394 - 60ms/epoch - 3ms/step\n",
      "Epoch 172/200\n",
      "20/20 - 0s - loss: 0.1938 - categorical_accuracy: 0.6600 - val_loss: 0.2602 - val_categorical_accuracy: 0.6245 - 67ms/epoch - 3ms/step\n",
      "Epoch 173/200\n",
      "20/20 - 0s - loss: 0.1928 - categorical_accuracy: 0.6600 - val_loss: 0.2627 - val_categorical_accuracy: 0.6245 - 59ms/epoch - 3ms/step\n",
      "Epoch 174/200\n",
      "20/20 - 0s - loss: 0.1918 - categorical_accuracy: 0.6700 - val_loss: 0.2576 - val_categorical_accuracy: 0.6357 - 73ms/epoch - 4ms/step\n",
      "Epoch 175/200\n",
      "20/20 - 0s - loss: 0.1916 - categorical_accuracy: 0.6625 - val_loss: 0.2593 - val_categorical_accuracy: 0.6320 - 56ms/epoch - 3ms/step\n",
      "Epoch 176/200\n",
      "20/20 - 0s - loss: 0.1893 - categorical_accuracy: 0.6750 - val_loss: 0.2580 - val_categorical_accuracy: 0.6283 - 65ms/epoch - 3ms/step\n",
      "Epoch 177/200\n",
      "20/20 - 0s - loss: 0.1868 - categorical_accuracy: 0.6800 - val_loss: 0.2585 - val_categorical_accuracy: 0.6320 - 63ms/epoch - 3ms/step\n",
      "Epoch 178/200\n",
      "20/20 - 0s - loss: 0.1913 - categorical_accuracy: 0.6825 - val_loss: 0.2584 - val_categorical_accuracy: 0.6097 - 67ms/epoch - 3ms/step\n",
      "Epoch 179/200\n",
      "20/20 - 0s - loss: 0.1878 - categorical_accuracy: 0.6800 - val_loss: 0.2608 - val_categorical_accuracy: 0.6097 - 60ms/epoch - 3ms/step\n",
      "Epoch 180/200\n",
      "20/20 - 0s - loss: 0.1918 - categorical_accuracy: 0.6575 - val_loss: 0.2599 - val_categorical_accuracy: 0.6171 - 62ms/epoch - 3ms/step\n",
      "Epoch 181/200\n",
      "20/20 - 0s - loss: 0.1878 - categorical_accuracy: 0.6625 - val_loss: 0.2623 - val_categorical_accuracy: 0.6171 - 70ms/epoch - 4ms/step\n",
      "Epoch 182/200\n",
      "20/20 - 0s - loss: 0.1840 - categorical_accuracy: 0.6800 - val_loss: 0.2568 - val_categorical_accuracy: 0.6506 - 66ms/epoch - 3ms/step\n",
      "Epoch 183/200\n",
      "20/20 - 0s - loss: 0.1842 - categorical_accuracy: 0.6725 - val_loss: 0.2548 - val_categorical_accuracy: 0.6357 - 58ms/epoch - 3ms/step\n",
      "Epoch 184/200\n",
      "20/20 - 0s - loss: 0.1807 - categorical_accuracy: 0.6975 - val_loss: 0.2573 - val_categorical_accuracy: 0.6394 - 75ms/epoch - 4ms/step\n",
      "Epoch 185/200\n",
      "20/20 - 0s - loss: 0.1822 - categorical_accuracy: 0.6800 - val_loss: 0.2629 - val_categorical_accuracy: 0.6320 - 56ms/epoch - 3ms/step\n",
      "Epoch 186/200\n",
      "20/20 - 0s - loss: 0.1873 - categorical_accuracy: 0.6875 - val_loss: 0.2563 - val_categorical_accuracy: 0.6283 - 67ms/epoch - 3ms/step\n",
      "Epoch 187/200\n",
      "20/20 - 0s - loss: 0.1787 - categorical_accuracy: 0.6900 - val_loss: 0.2551 - val_categorical_accuracy: 0.6357 - 65ms/epoch - 3ms/step\n",
      "Epoch 188/200\n",
      "20/20 - 0s - loss: 0.1780 - categorical_accuracy: 0.7125 - val_loss: 0.2663 - val_categorical_accuracy: 0.6283 - 61ms/epoch - 3ms/step\n",
      "Epoch 189/200\n",
      "20/20 - 0s - loss: 0.1793 - categorical_accuracy: 0.6900 - val_loss: 0.2609 - val_categorical_accuracy: 0.6468 - 76ms/epoch - 4ms/step\n",
      "Epoch 190/200\n",
      "20/20 - 0s - loss: 0.1761 - categorical_accuracy: 0.6975 - val_loss: 0.2565 - val_categorical_accuracy: 0.6357 - 62ms/epoch - 3ms/step\n",
      "Epoch 191/200\n",
      "20/20 - 0s - loss: 0.1750 - categorical_accuracy: 0.6925 - val_loss: 0.2541 - val_categorical_accuracy: 0.6245 - 69ms/epoch - 3ms/step\n",
      "Epoch 192/200\n",
      "20/20 - 0s - loss: 0.1756 - categorical_accuracy: 0.6850 - val_loss: 0.2555 - val_categorical_accuracy: 0.6431 - 57ms/epoch - 3ms/step\n",
      "Epoch 193/200\n",
      "20/20 - 0s - loss: 0.1748 - categorical_accuracy: 0.6950 - val_loss: 0.2544 - val_categorical_accuracy: 0.6245 - 59ms/epoch - 3ms/step\n",
      "Epoch 194/200\n",
      "20/20 - 0s - loss: 0.1776 - categorical_accuracy: 0.7000 - val_loss: 0.2588 - val_categorical_accuracy: 0.6208 - 71ms/epoch - 4ms/step\n",
      "Epoch 195/200\n",
      "20/20 - 0s - loss: 0.1816 - categorical_accuracy: 0.6850 - val_loss: 0.2553 - val_categorical_accuracy: 0.6357 - 61ms/epoch - 3ms/step\n",
      "Epoch 196/200\n",
      "20/20 - 0s - loss: 0.1733 - categorical_accuracy: 0.6950 - val_loss: 0.2560 - val_categorical_accuracy: 0.6468 - 66ms/epoch - 3ms/step\n",
      "Epoch 197/200\n",
      "20/20 - 0s - loss: 0.1727 - categorical_accuracy: 0.7000 - val_loss: 0.2643 - val_categorical_accuracy: 0.6357 - 70ms/epoch - 4ms/step\n",
      "Epoch 198/200\n",
      "20/20 - 0s - loss: 0.1722 - categorical_accuracy: 0.6925 - val_loss: 0.2551 - val_categorical_accuracy: 0.6431 - 64ms/epoch - 3ms/step\n",
      "Epoch 199/200\n",
      "20/20 - 0s - loss: 0.1723 - categorical_accuracy: 0.7150 - val_loss: 0.2620 - val_categorical_accuracy: 0.6468 - 62ms/epoch - 3ms/step\n",
      "Epoch 200/200\n",
      "20/20 - 0s - loss: 0.1732 - categorical_accuracy: 0.6975 - val_loss: 0.2582 - val_categorical_accuracy: 0.6357 - 65ms/epoch - 3ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "dim = X_train.shape[1]\n",
    "np.random.seed(2023)\n",
    "model = Sequential()\n",
    "model.add(Dense(40, activation='relu', input_dim=dim))\n",
    "model.add(Dense(15, activation='relu', input_dim=dim))\n",
    "model.add(Dense(5, activation='relu', input_dim=dim))\n",
    "model.add(Dense(7, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['categorical_accuracy'])\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=200, batch_size=20, verbose=2)\n",
    "prob = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CBLul7v4XPGF",
    "outputId": "79c555dd-10b0-4b84-938a-8d36a6eca7a7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Rate: 0.635688\n",
      "\n",
      "Confusion matrix:\n",
      "[[34  1  1  0  0  0  2]\n",
      " [ 0 33  3  1  1  1  0]\n",
      " [ 0  7  1 16 12  2  1]\n",
      " [ 1  3  0 23  9  1  2]\n",
      " [ 1  2  0 23 11  1  0]\n",
      " [ 2  0  0  0  0 36  0]\n",
      " [ 3  0  1  0  1  0 33]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.89      0.86        38\n",
      "           1       0.72      0.85      0.78        39\n",
      "           2       0.17      0.03      0.04        39\n",
      "           3       0.37      0.59      0.45        39\n",
      "           4       0.32      0.29      0.31        38\n",
      "           5       0.88      0.95      0.91        38\n",
      "           6       0.87      0.87      0.87        38\n",
      "\n",
      "    accuracy                           0.64       269\n",
      "   macro avg       0.59      0.64      0.60       269\n",
      "weighted avg       0.59      0.64      0.60       269\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Report the acheived accuracy (categorical) over the test sample.\n",
    "print('Accuracy Rate: %f' % accuracy_score(y_test.argmax(axis = 1),prob.argmax(axis = 1)))\n",
    "print('')\n",
    "print('Confusion matrix:\\n%s' % confusion_matrix(y_test.argmax(axis = 1),prob.argmax(axis = 1)))\n",
    "print('')\n",
    "print('Classification Report:')\n",
    "print(classification_report(y_test.argmax(axis = 1),prob.argmax(axis = 1)))\n",
    "print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s30cDsJA5uOL"
   },
   "source": [
    "## part 2\n",
    "\n",
    "Use the same datasets as in the Advanced NN lab and further train NN with different architectures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EG48ZPI35uOL"
   },
   "source": [
    "## Task 1\n",
    "\n",
    "Try the facial recognition task from NN lab 2 with different model specifications and report model accuracy:\n",
    "1. Try different dropouts - 0.2, 0.3, 0.4\n",
    "2. Try different convolution windows: (3$\\times$3, 10$\\times$10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VoZPEjZ55uOL"
   },
   "outputs": [],
   "source": [
    "# load the data\n",
    "\n",
    "from sklearn.datasets import fetch_lfw_people \n",
    "from keras.datasets import mnist\n",
    "\n",
    "lfw_people = fetch_lfw_people(min_faces_per_person = 70, resize = 0.4) \n",
    "  \n",
    "# the images arrays to find the shapes (for plotting) \n",
    "n_samples, h, w = lfw_people.images.shape \n",
    "  \n",
    "# Instead of providing 2D data, X has data already in the form  of a vector that \n",
    "# is required in this approach. \n",
    "X = lfw_people.data \n",
    "n_features = X.shape[1] \n",
    "\n",
    "y = lfw_people.target \n",
    "target_names = lfw_people.target_names \n",
    "n_classes = target_names.shape[0] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gMhq6Ew55uOL"
   },
   "outputs": [],
   "source": [
    "# lets split and reform the dataset in the format compatible for CNN\n",
    "# basically we are restructuring the data into grid shapes which are apt for convolutions and further steps\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split( \n",
    "    X, y, test_size = 0.2)\n",
    "\n",
    "X_train_pp = (X_train.reshape(X_train.shape[0], 50, 37, 1).astype('float32')) / 255 # normalize\n",
    "X_test_pp = (X_test.reshape(X_test.shape[0], 50, 37, 1).astype('float32')) / 255\n",
    "\n",
    "y_train_pp = np_utils.to_categorical(y_train)\n",
    "y_test_pp = np_utils.to_categorical(y_test)\n",
    "\n",
    "num_classes = y_train_pp.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IvhW1cM0agdq",
    "outputId": "47828013-c62d-4a5a-fa05-ba755b892cbc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1030, 50, 37, 1) (258, 50, 37, 1)\n"
     ]
    }
   ],
   "source": [
    "print(X_train_pp.shape, X_test_pp.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pXad4mtlaiFz"
   },
   "outputs": [],
   "source": [
    "Drops=[0.2,0.3,0.4]\n",
    "Convolution_windows=[(3,3),(10,10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Sxg9_3gJasmi",
    "outputId": "277eefa8-6ebf-4ee2-d3f8-6f1346567ae2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/250\n",
      "6/6 - 4s - loss: 1.9017 - accuracy: 0.3456 - val_loss: 1.7675 - val_accuracy: 0.3876 - 4s/epoch - 737ms/step\n",
      "Epoch 2/250\n",
      "6/6 - 2s - loss: 1.7174 - accuracy: 0.4175 - val_loss: 1.7561 - val_accuracy: 0.3876 - 2s/epoch - 292ms/step\n",
      "Epoch 3/250\n",
      "6/6 - 2s - loss: 1.6918 - accuracy: 0.4175 - val_loss: 1.7505 - val_accuracy: 0.3876 - 2s/epoch - 393ms/step\n",
      "Epoch 4/250\n",
      "6/6 - 3s - loss: 1.6774 - accuracy: 0.4175 - val_loss: 1.7549 - val_accuracy: 0.3876 - 3s/epoch - 493ms/step\n",
      "Epoch 5/250\n",
      "6/6 - 3s - loss: 1.6770 - accuracy: 0.4175 - val_loss: 1.7284 - val_accuracy: 0.3876 - 3s/epoch - 560ms/step\n",
      "Epoch 6/250\n",
      "6/6 - 2s - loss: 1.6761 - accuracy: 0.4175 - val_loss: 1.7321 - val_accuracy: 0.3876 - 2s/epoch - 318ms/step\n",
      "Epoch 7/250\n",
      "6/6 - 2s - loss: 1.6756 - accuracy: 0.4175 - val_loss: 1.7387 - val_accuracy: 0.3876 - 2s/epoch - 303ms/step\n",
      "Epoch 8/250\n",
      "6/6 - 3s - loss: 1.6738 - accuracy: 0.4175 - val_loss: 1.7280 - val_accuracy: 0.3876 - 3s/epoch - 460ms/step\n",
      "Epoch 9/250\n",
      "6/6 - 2s - loss: 1.6698 - accuracy: 0.4175 - val_loss: 1.7319 - val_accuracy: 0.3876 - 2s/epoch - 279ms/step\n",
      "Epoch 10/250\n",
      "6/6 - 2s - loss: 1.6703 - accuracy: 0.4175 - val_loss: 1.7378 - val_accuracy: 0.3876 - 2s/epoch - 290ms/step\n",
      "Epoch 11/250\n",
      "6/6 - 2s - loss: 1.6694 - accuracy: 0.4175 - val_loss: 1.7403 - val_accuracy: 0.3876 - 2s/epoch - 291ms/step\n",
      "Epoch 12/250\n",
      "6/6 - 2s - loss: 1.6695 - accuracy: 0.4175 - val_loss: 1.7399 - val_accuracy: 0.3876 - 2s/epoch - 286ms/step\n",
      "Epoch 13/250\n",
      "6/6 - 2s - loss: 1.6710 - accuracy: 0.4175 - val_loss: 1.7431 - val_accuracy: 0.3876 - 2s/epoch - 297ms/step\n",
      "Epoch 14/250\n",
      "6/6 - 2s - loss: 1.6702 - accuracy: 0.4175 - val_loss: 1.7459 - val_accuracy: 0.3876 - 2s/epoch - 381ms/step\n",
      "Epoch 15/250\n",
      "6/6 - 2s - loss: 1.6697 - accuracy: 0.4175 - val_loss: 1.7381 - val_accuracy: 0.3876 - 2s/epoch - 335ms/step\n",
      "Epoch 16/250\n",
      "6/6 - 2s - loss: 1.6691 - accuracy: 0.4175 - val_loss: 1.7315 - val_accuracy: 0.3876 - 2s/epoch - 286ms/step\n",
      "Epoch 17/250\n",
      "6/6 - 2s - loss: 1.6723 - accuracy: 0.4175 - val_loss: 1.7263 - val_accuracy: 0.3876 - 2s/epoch - 287ms/step\n",
      "Epoch 18/250\n",
      "6/6 - 2s - loss: 1.6723 - accuracy: 0.4175 - val_loss: 1.7271 - val_accuracy: 0.3876 - 2s/epoch - 291ms/step\n",
      "Epoch 19/250\n",
      "6/6 - 2s - loss: 1.6718 - accuracy: 0.4175 - val_loss: 1.7376 - val_accuracy: 0.3876 - 2s/epoch - 295ms/step\n",
      "Epoch 20/250\n",
      "6/6 - 2s - loss: 1.6752 - accuracy: 0.4175 - val_loss: 1.7351 - val_accuracy: 0.3876 - 2s/epoch - 299ms/step\n",
      "Epoch 21/250\n",
      "6/6 - 3s - loss: 1.6718 - accuracy: 0.4175 - val_loss: 1.7372 - val_accuracy: 0.3876 - 3s/epoch - 440ms/step\n",
      "Epoch 22/250\n",
      "6/6 - 2s - loss: 1.6762 - accuracy: 0.4175 - val_loss: 1.7406 - val_accuracy: 0.3876 - 2s/epoch - 285ms/step\n",
      "Epoch 23/250\n",
      "6/6 - 2s - loss: 1.6731 - accuracy: 0.4175 - val_loss: 1.7504 - val_accuracy: 0.3876 - 2s/epoch - 288ms/step\n",
      "Epoch 24/250\n",
      "6/6 - 2s - loss: 1.6704 - accuracy: 0.4175 - val_loss: 1.7418 - val_accuracy: 0.3876 - 2s/epoch - 289ms/step\n",
      "Epoch 25/250\n",
      "6/6 - 2s - loss: 1.6688 - accuracy: 0.4175 - val_loss: 1.7447 - val_accuracy: 0.3876 - 2s/epoch - 287ms/step\n",
      "Epoch 26/250\n",
      "6/6 - 2s - loss: 1.6703 - accuracy: 0.4175 - val_loss: 1.7342 - val_accuracy: 0.3876 - 2s/epoch - 292ms/step\n",
      "Epoch 27/250\n",
      "6/6 - 2s - loss: 1.6697 - accuracy: 0.4175 - val_loss: 1.7394 - val_accuracy: 0.3876 - 2s/epoch - 391ms/step\n",
      "Epoch 28/250\n",
      "6/6 - 2s - loss: 1.6706 - accuracy: 0.4175 - val_loss: 1.7336 - val_accuracy: 0.3876 - 2s/epoch - 317ms/step\n",
      "Epoch 29/250\n",
      "6/6 - 2s - loss: 1.6744 - accuracy: 0.4175 - val_loss: 1.7327 - val_accuracy: 0.3876 - 2s/epoch - 284ms/step\n",
      "Epoch 30/250\n",
      "6/6 - 2s - loss: 1.6700 - accuracy: 0.4175 - val_loss: 1.7371 - val_accuracy: 0.3876 - 2s/epoch - 288ms/step\n",
      "Epoch 31/250\n",
      "6/6 - 2s - loss: 1.6695 - accuracy: 0.4175 - val_loss: 1.7335 - val_accuracy: 0.3876 - 2s/epoch - 288ms/step\n",
      "Epoch 32/250\n",
      "6/6 - 2s - loss: 1.6724 - accuracy: 0.4175 - val_loss: 1.7324 - val_accuracy: 0.3876 - 2s/epoch - 288ms/step\n",
      "Epoch 33/250\n",
      "6/6 - 2s - loss: 1.6782 - accuracy: 0.4175 - val_loss: 1.7307 - val_accuracy: 0.3876 - 2s/epoch - 285ms/step\n",
      "Epoch 34/250\n",
      "6/6 - 3s - loss: 1.6707 - accuracy: 0.4175 - val_loss: 1.7450 - val_accuracy: 0.3876 - 3s/epoch - 425ms/step\n",
      "Epoch 35/250\n",
      "6/6 - 2s - loss: 1.6733 - accuracy: 0.4175 - val_loss: 1.7315 - val_accuracy: 0.3876 - 2s/epoch - 275ms/step\n",
      "Epoch 36/250\n",
      "6/6 - 2s - loss: 1.6727 - accuracy: 0.4175 - val_loss: 1.7450 - val_accuracy: 0.3876 - 2s/epoch - 282ms/step\n",
      "Epoch 37/250\n",
      "6/6 - 2s - loss: 1.6737 - accuracy: 0.4175 - val_loss: 1.7414 - val_accuracy: 0.3876 - 2s/epoch - 285ms/step\n",
      "Epoch 38/250\n",
      "6/6 - 2s - loss: 1.6709 - accuracy: 0.4175 - val_loss: 1.7393 - val_accuracy: 0.3876 - 2s/epoch - 281ms/step\n",
      "Epoch 39/250\n",
      "6/6 - 2s - loss: 1.6716 - accuracy: 0.4175 - val_loss: 1.7508 - val_accuracy: 0.3876 - 2s/epoch - 290ms/step\n",
      "Epoch 40/250\n",
      "6/6 - 2s - loss: 1.6762 - accuracy: 0.4175 - val_loss: 1.7344 - val_accuracy: 0.3876 - 2s/epoch - 366ms/step\n",
      "Epoch 41/250\n",
      "6/6 - 2s - loss: 1.6706 - accuracy: 0.4175 - val_loss: 1.7381 - val_accuracy: 0.3876 - 2s/epoch - 340ms/step\n",
      "Epoch 42/250\n",
      "6/6 - 2s - loss: 1.6695 - accuracy: 0.4175 - val_loss: 1.7292 - val_accuracy: 0.3876 - 2s/epoch - 283ms/step\n",
      "Epoch 43/250\n",
      "6/6 - 2s - loss: 1.6689 - accuracy: 0.4175 - val_loss: 1.7475 - val_accuracy: 0.3876 - 2s/epoch - 290ms/step\n",
      "Epoch 44/250\n",
      "6/6 - 2s - loss: 1.6741 - accuracy: 0.4175 - val_loss: 1.7336 - val_accuracy: 0.3876 - 2s/epoch - 293ms/step\n",
      "Epoch 45/250\n",
      "6/6 - 2s - loss: 1.6749 - accuracy: 0.4175 - val_loss: 1.7351 - val_accuracy: 0.3876 - 2s/epoch - 287ms/step\n",
      "Epoch 46/250\n",
      "6/6 - 2s - loss: 1.6775 - accuracy: 0.4175 - val_loss: 1.7408 - val_accuracy: 0.3876 - 2s/epoch - 291ms/step\n",
      "Epoch 47/250\n",
      "6/6 - 3s - loss: 1.6704 - accuracy: 0.4175 - val_loss: 1.7367 - val_accuracy: 0.3876 - 3s/epoch - 432ms/step\n",
      "Epoch 48/250\n",
      "6/6 - 2s - loss: 1.6690 - accuracy: 0.4175 - val_loss: 1.7433 - val_accuracy: 0.3876 - 2s/epoch - 288ms/step\n",
      "Epoch 49/250\n",
      "6/6 - 2s - loss: 1.6719 - accuracy: 0.4175 - val_loss: 1.7268 - val_accuracy: 0.3876 - 2s/epoch - 287ms/step\n",
      "Epoch 50/250\n",
      "6/6 - 2s - loss: 1.6698 - accuracy: 0.4175 - val_loss: 1.7263 - val_accuracy: 0.3876 - 2s/epoch - 283ms/step\n",
      "Epoch 51/250\n",
      "6/6 - 2s - loss: 1.6684 - accuracy: 0.4175 - val_loss: 1.7250 - val_accuracy: 0.3876 - 2s/epoch - 285ms/step\n",
      "Epoch 52/250\n",
      "6/6 - 2s - loss: 1.6682 - accuracy: 0.4175 - val_loss: 1.7252 - val_accuracy: 0.3876 - 2s/epoch - 294ms/step\n",
      "Epoch 53/250\n",
      "6/6 - 2s - loss: 1.6664 - accuracy: 0.4175 - val_loss: 1.7430 - val_accuracy: 0.3876 - 2s/epoch - 347ms/step\n",
      "Epoch 54/250\n",
      "6/6 - 2s - loss: 1.6715 - accuracy: 0.4175 - val_loss: 1.7302 - val_accuracy: 0.3876 - 2s/epoch - 369ms/step\n",
      "Epoch 55/250\n",
      "6/6 - 2s - loss: 1.6675 - accuracy: 0.4175 - val_loss: 1.7311 - val_accuracy: 0.3876 - 2s/epoch - 287ms/step\n",
      "Epoch 56/250\n",
      "6/6 - 2s - loss: 1.6657 - accuracy: 0.4175 - val_loss: 1.7386 - val_accuracy: 0.3876 - 2s/epoch - 287ms/step\n",
      "Epoch 57/250\n",
      "6/6 - 2s - loss: 1.6657 - accuracy: 0.4175 - val_loss: 1.7298 - val_accuracy: 0.3876 - 2s/epoch - 289ms/step\n",
      "Epoch 58/250\n",
      "6/6 - 2s - loss: 1.6620 - accuracy: 0.4175 - val_loss: 1.7276 - val_accuracy: 0.3876 - 2s/epoch - 284ms/step\n",
      "Epoch 59/250\n",
      "6/6 - 2s - loss: 1.6602 - accuracy: 0.4175 - val_loss: 1.7373 - val_accuracy: 0.3876 - 2s/epoch - 281ms/step\n",
      "Epoch 60/250\n",
      "6/6 - 3s - loss: 1.6654 - accuracy: 0.4175 - val_loss: 1.7235 - val_accuracy: 0.3876 - 3s/epoch - 483ms/step\n",
      "Epoch 61/250\n",
      "6/6 - 2s - loss: 1.6525 - accuracy: 0.4175 - val_loss: 1.7205 - val_accuracy: 0.3876 - 2s/epoch - 387ms/step\n",
      "Epoch 62/250\n",
      "6/6 - 2s - loss: 1.6531 - accuracy: 0.4175 - val_loss: 1.7226 - val_accuracy: 0.3876 - 2s/epoch - 294ms/step\n",
      "Epoch 63/250\n",
      "6/6 - 2s - loss: 1.6461 - accuracy: 0.4175 - val_loss: 1.7207 - val_accuracy: 0.3876 - 2s/epoch - 288ms/step\n",
      "Epoch 64/250\n",
      "6/6 - 2s - loss: 1.6374 - accuracy: 0.4175 - val_loss: 1.7091 - val_accuracy: 0.3876 - 2s/epoch - 286ms/step\n",
      "Epoch 65/250\n",
      "6/6 - 2s - loss: 1.6425 - accuracy: 0.4175 - val_loss: 1.7363 - val_accuracy: 0.3876 - 2s/epoch - 290ms/step\n",
      "Epoch 66/250\n",
      "6/6 - 2s - loss: 1.6495 - accuracy: 0.4175 - val_loss: 1.6965 - val_accuracy: 0.3876 - 2s/epoch - 333ms/step\n",
      "Epoch 67/250\n",
      "6/6 - 2s - loss: 1.6320 - accuracy: 0.4379 - val_loss: 1.6863 - val_accuracy: 0.3915 - 2s/epoch - 378ms/step\n",
      "Epoch 68/250\n",
      "6/6 - 2s - loss: 1.6240 - accuracy: 0.4194 - val_loss: 1.7143 - val_accuracy: 0.3876 - 2s/epoch - 284ms/step\n",
      "Epoch 69/250\n",
      "6/6 - 2s - loss: 1.6075 - accuracy: 0.4175 - val_loss: 1.6808 - val_accuracy: 0.3876 - 2s/epoch - 287ms/step\n",
      "Epoch 70/250\n",
      "6/6 - 2s - loss: 1.6177 - accuracy: 0.4243 - val_loss: 1.6916 - val_accuracy: 0.4186 - 2s/epoch - 292ms/step\n",
      "Epoch 71/250\n",
      "6/6 - 2s - loss: 1.5903 - accuracy: 0.4330 - val_loss: 1.6585 - val_accuracy: 0.3953 - 2s/epoch - 292ms/step\n",
      "Epoch 72/250\n",
      "6/6 - 2s - loss: 1.5728 - accuracy: 0.4602 - val_loss: 1.6458 - val_accuracy: 0.4109 - 2s/epoch - 286ms/step\n",
      "Epoch 73/250\n",
      "6/6 - 3s - loss: 1.5532 - accuracy: 0.4369 - val_loss: 1.6619 - val_accuracy: 0.3915 - 3s/epoch - 436ms/step\n",
      "Epoch 74/250\n",
      "6/6 - 2s - loss: 1.5549 - accuracy: 0.4563 - val_loss: 1.6382 - val_accuracy: 0.3953 - 2s/epoch - 289ms/step\n",
      "Epoch 75/250\n",
      "6/6 - 2s - loss: 1.5375 - accuracy: 0.4359 - val_loss: 1.6382 - val_accuracy: 0.4419 - 2s/epoch - 288ms/step\n",
      "Epoch 76/250\n",
      "6/6 - 2s - loss: 1.5076 - accuracy: 0.4777 - val_loss: 1.6106 - val_accuracy: 0.4186 - 2s/epoch - 286ms/step\n",
      "Epoch 77/250\n",
      "6/6 - 2s - loss: 1.4966 - accuracy: 0.4641 - val_loss: 1.5857 - val_accuracy: 0.4419 - 2s/epoch - 287ms/step\n",
      "Epoch 78/250\n",
      "6/6 - 2s - loss: 1.4564 - accuracy: 0.4728 - val_loss: 1.5497 - val_accuracy: 0.4574 - 2s/epoch - 287ms/step\n",
      "Epoch 79/250\n",
      "6/6 - 2s - loss: 1.4484 - accuracy: 0.4883 - val_loss: 1.5566 - val_accuracy: 0.4380 - 2s/epoch - 367ms/step\n",
      "Epoch 80/250\n",
      "6/6 - 2s - loss: 1.4311 - accuracy: 0.4757 - val_loss: 1.5190 - val_accuracy: 0.4535 - 2s/epoch - 345ms/step\n",
      "Epoch 81/250\n",
      "6/6 - 2s - loss: 1.3889 - accuracy: 0.4913 - val_loss: 1.4912 - val_accuracy: 0.4535 - 2s/epoch - 284ms/step\n",
      "Epoch 82/250\n",
      "6/6 - 2s - loss: 1.3646 - accuracy: 0.5097 - val_loss: 1.4777 - val_accuracy: 0.4690 - 2s/epoch - 291ms/step\n",
      "Epoch 83/250\n",
      "6/6 - 2s - loss: 1.3571 - accuracy: 0.5184 - val_loss: 1.4696 - val_accuracy: 0.4961 - 2s/epoch - 290ms/step\n",
      "Epoch 84/250\n",
      "6/6 - 2s - loss: 1.3367 - accuracy: 0.5534 - val_loss: 1.4507 - val_accuracy: 0.4845 - 2s/epoch - 287ms/step\n",
      "Epoch 85/250\n",
      "6/6 - 2s - loss: 1.3274 - accuracy: 0.5126 - val_loss: 1.4268 - val_accuracy: 0.5078 - 2s/epoch - 288ms/step\n",
      "Epoch 86/250\n",
      "6/6 - 3s - loss: 1.3066 - accuracy: 0.5680 - val_loss: 1.4326 - val_accuracy: 0.5078 - 3s/epoch - 438ms/step\n",
      "Epoch 87/250\n",
      "6/6 - 2s - loss: 1.2706 - accuracy: 0.5573 - val_loss: 1.4273 - val_accuracy: 0.4961 - 2s/epoch - 292ms/step\n",
      "Epoch 88/250\n",
      "6/6 - 2s - loss: 1.2384 - accuracy: 0.5680 - val_loss: 1.3984 - val_accuracy: 0.5194 - 2s/epoch - 302ms/step\n",
      "Epoch 89/250\n",
      "6/6 - 2s - loss: 1.2132 - accuracy: 0.5699 - val_loss: 1.3436 - val_accuracy: 0.5426 - 2s/epoch - 289ms/step\n",
      "Epoch 90/250\n",
      "6/6 - 2s - loss: 1.1945 - accuracy: 0.5971 - val_loss: 1.3387 - val_accuracy: 0.5233 - 2s/epoch - 285ms/step\n",
      "Epoch 91/250\n",
      "6/6 - 2s - loss: 1.1695 - accuracy: 0.6000 - val_loss: 1.3199 - val_accuracy: 0.5310 - 2s/epoch - 277ms/step\n",
      "Epoch 92/250\n",
      "6/6 - 2s - loss: 1.1590 - accuracy: 0.6029 - val_loss: 1.2823 - val_accuracy: 0.5504 - 2s/epoch - 385ms/step\n",
      "Epoch 93/250\n",
      "6/6 - 2s - loss: 1.1190 - accuracy: 0.6097 - val_loss: 1.2659 - val_accuracy: 0.5853 - 2s/epoch - 336ms/step\n",
      "Epoch 94/250\n",
      "6/6 - 2s - loss: 1.1111 - accuracy: 0.6437 - val_loss: 1.2583 - val_accuracy: 0.5465 - 2s/epoch - 282ms/step\n",
      "Epoch 95/250\n",
      "6/6 - 2s - loss: 1.0889 - accuracy: 0.6233 - val_loss: 1.2840 - val_accuracy: 0.5659 - 2s/epoch - 301ms/step\n",
      "Epoch 96/250\n",
      "6/6 - 2s - loss: 1.0912 - accuracy: 0.6340 - val_loss: 1.2255 - val_accuracy: 0.5504 - 2s/epoch - 290ms/step\n",
      "Epoch 97/250\n",
      "6/6 - 2s - loss: 1.0437 - accuracy: 0.6369 - val_loss: 1.2275 - val_accuracy: 0.6085 - 2s/epoch - 289ms/step\n",
      "Epoch 98/250\n",
      "6/6 - 2s - loss: 1.0426 - accuracy: 0.6515 - val_loss: 1.1774 - val_accuracy: 0.5659 - 2s/epoch - 304ms/step\n",
      "Epoch 99/250\n",
      "6/6 - 2s - loss: 1.0057 - accuracy: 0.6505 - val_loss: 1.1627 - val_accuracy: 0.6008 - 2s/epoch - 406ms/step\n",
      "Epoch 100/250\n",
      "6/6 - 2s - loss: 0.9742 - accuracy: 0.6515 - val_loss: 1.1196 - val_accuracy: 0.6318 - 2s/epoch - 291ms/step\n",
      "Epoch 101/250\n",
      "6/6 - 2s - loss: 0.9866 - accuracy: 0.6650 - val_loss: 1.1027 - val_accuracy: 0.6395 - 2s/epoch - 298ms/step\n",
      "Epoch 102/250\n",
      "6/6 - 2s - loss: 0.9386 - accuracy: 0.6786 - val_loss: 1.1196 - val_accuracy: 0.6047 - 2s/epoch - 293ms/step\n",
      "Epoch 103/250\n",
      "6/6 - 2s - loss: 0.9310 - accuracy: 0.6573 - val_loss: 1.1056 - val_accuracy: 0.6279 - 2s/epoch - 291ms/step\n",
      "Epoch 104/250\n",
      "6/6 - 2s - loss: 0.9146 - accuracy: 0.6757 - val_loss: 1.0778 - val_accuracy: 0.6047 - 2s/epoch - 290ms/step\n",
      "Epoch 105/250\n",
      "6/6 - 2s - loss: 0.9035 - accuracy: 0.6932 - val_loss: 1.0700 - val_accuracy: 0.6667 - 2s/epoch - 414ms/step\n",
      "Epoch 106/250\n",
      "6/6 - 2s - loss: 0.8986 - accuracy: 0.6883 - val_loss: 1.1376 - val_accuracy: 0.5698 - 2s/epoch - 295ms/step\n",
      "Epoch 107/250\n",
      "6/6 - 2s - loss: 0.8959 - accuracy: 0.6718 - val_loss: 1.0470 - val_accuracy: 0.6705 - 2s/epoch - 294ms/step\n",
      "Epoch 108/250\n",
      "6/6 - 2s - loss: 0.8762 - accuracy: 0.7000 - val_loss: 1.1396 - val_accuracy: 0.5853 - 2s/epoch - 290ms/step\n",
      "Epoch 109/250\n",
      "6/6 - 2s - loss: 0.9059 - accuracy: 0.6670 - val_loss: 1.0817 - val_accuracy: 0.6550 - 2s/epoch - 291ms/step\n",
      "Epoch 110/250\n",
      "6/6 - 2s - loss: 0.8789 - accuracy: 0.7010 - val_loss: 1.0445 - val_accuracy: 0.6667 - 2s/epoch - 290ms/step\n",
      "Epoch 111/250\n",
      "6/6 - 2s - loss: 0.8271 - accuracy: 0.7155 - val_loss: 0.9961 - val_accuracy: 0.6822 - 2s/epoch - 356ms/step\n",
      "Epoch 112/250\n",
      "6/6 - 2s - loss: 0.8069 - accuracy: 0.7155 - val_loss: 0.9827 - val_accuracy: 0.6822 - 2s/epoch - 376ms/step\n",
      "Epoch 113/250\n",
      "6/6 - 2s - loss: 0.7927 - accuracy: 0.7272 - val_loss: 0.9665 - val_accuracy: 0.6860 - 2s/epoch - 290ms/step\n",
      "Epoch 114/250\n",
      "6/6 - 2s - loss: 0.7829 - accuracy: 0.7214 - val_loss: 0.9679 - val_accuracy: 0.6899 - 2s/epoch - 295ms/step\n",
      "Epoch 115/250\n",
      "6/6 - 2s - loss: 0.7826 - accuracy: 0.7485 - val_loss: 0.9587 - val_accuracy: 0.6977 - 2s/epoch - 294ms/step\n",
      "Epoch 116/250\n",
      "6/6 - 2s - loss: 0.7942 - accuracy: 0.7282 - val_loss: 1.0109 - val_accuracy: 0.6822 - 2s/epoch - 285ms/step\n",
      "Epoch 117/250\n",
      "6/6 - 2s - loss: 0.7741 - accuracy: 0.7233 - val_loss: 0.9689 - val_accuracy: 0.6822 - 2s/epoch - 294ms/step\n",
      "Epoch 118/250\n",
      "6/6 - 3s - loss: 0.7923 - accuracy: 0.7359 - val_loss: 0.9487 - val_accuracy: 0.6977 - 3s/epoch - 430ms/step\n",
      "Epoch 119/250\n",
      "6/6 - 2s - loss: 0.7376 - accuracy: 0.7311 - val_loss: 0.9736 - val_accuracy: 0.6744 - 2s/epoch - 294ms/step\n",
      "Epoch 120/250\n",
      "6/6 - 2s - loss: 0.7494 - accuracy: 0.7427 - val_loss: 0.9351 - val_accuracy: 0.6938 - 2s/epoch - 285ms/step\n",
      "Epoch 121/250\n",
      "6/6 - 2s - loss: 0.7288 - accuracy: 0.7544 - val_loss: 0.9086 - val_accuracy: 0.7171 - 2s/epoch - 288ms/step\n",
      "Epoch 122/250\n",
      "6/6 - 2s - loss: 0.7214 - accuracy: 0.7466 - val_loss: 0.9049 - val_accuracy: 0.7016 - 2s/epoch - 287ms/step\n",
      "Epoch 123/250\n",
      "6/6 - 2s - loss: 0.6958 - accuracy: 0.7612 - val_loss: 0.9118 - val_accuracy: 0.7248 - 2s/epoch - 294ms/step\n",
      "Epoch 124/250\n",
      "6/6 - 2s - loss: 0.7000 - accuracy: 0.7592 - val_loss: 0.9111 - val_accuracy: 0.7054 - 2s/epoch - 371ms/step\n",
      "Epoch 125/250\n",
      "6/6 - 2s - loss: 0.6782 - accuracy: 0.7641 - val_loss: 0.9008 - val_accuracy: 0.7248 - 2s/epoch - 344ms/step\n",
      "Epoch 126/250\n",
      "6/6 - 2s - loss: 0.6909 - accuracy: 0.7680 - val_loss: 0.9338 - val_accuracy: 0.6938 - 2s/epoch - 287ms/step\n",
      "Epoch 127/250\n",
      "6/6 - 2s - loss: 0.6714 - accuracy: 0.7786 - val_loss: 0.8859 - val_accuracy: 0.7209 - 2s/epoch - 291ms/step\n",
      "Epoch 128/250\n",
      "6/6 - 2s - loss: 0.6893 - accuracy: 0.7680 - val_loss: 0.9231 - val_accuracy: 0.7054 - 2s/epoch - 297ms/step\n",
      "Epoch 129/250\n",
      "6/6 - 2s - loss: 0.6718 - accuracy: 0.7718 - val_loss: 0.8767 - val_accuracy: 0.7171 - 2s/epoch - 292ms/step\n",
      "Epoch 130/250\n",
      "6/6 - 2s - loss: 0.6549 - accuracy: 0.7825 - val_loss: 0.8904 - val_accuracy: 0.7287 - 2s/epoch - 292ms/step\n",
      "Epoch 131/250\n",
      "6/6 - 2s - loss: 0.6591 - accuracy: 0.7709 - val_loss: 0.9016 - val_accuracy: 0.7171 - 2s/epoch - 411ms/step\n",
      "Epoch 132/250\n",
      "6/6 - 2s - loss: 0.6396 - accuracy: 0.7951 - val_loss: 0.8911 - val_accuracy: 0.7209 - 2s/epoch - 277ms/step\n",
      "Epoch 133/250\n",
      "6/6 - 2s - loss: 0.6233 - accuracy: 0.7845 - val_loss: 0.8934 - val_accuracy: 0.7287 - 2s/epoch - 293ms/step\n",
      "Epoch 134/250\n",
      "6/6 - 2s - loss: 0.6359 - accuracy: 0.7854 - val_loss: 0.8618 - val_accuracy: 0.7287 - 2s/epoch - 283ms/step\n",
      "Epoch 135/250\n",
      "6/6 - 2s - loss: 0.6255 - accuracy: 0.7806 - val_loss: 0.9075 - val_accuracy: 0.7132 - 2s/epoch - 284ms/step\n",
      "Epoch 136/250\n",
      "6/6 - 2s - loss: 0.6125 - accuracy: 0.7718 - val_loss: 0.8433 - val_accuracy: 0.7597 - 2s/epoch - 282ms/step\n",
      "Epoch 137/250\n",
      "6/6 - 2s - loss: 0.6004 - accuracy: 0.7932 - val_loss: 0.8412 - val_accuracy: 0.7597 - 2s/epoch - 364ms/step\n",
      "Epoch 138/250\n",
      "6/6 - 2s - loss: 0.5824 - accuracy: 0.7981 - val_loss: 0.8446 - val_accuracy: 0.7481 - 2s/epoch - 344ms/step\n",
      "Epoch 139/250\n",
      "6/6 - 2s - loss: 0.5877 - accuracy: 0.8039 - val_loss: 0.8574 - val_accuracy: 0.7442 - 2s/epoch - 282ms/step\n",
      "Epoch 140/250\n",
      "6/6 - 2s - loss: 0.5832 - accuracy: 0.7990 - val_loss: 0.8684 - val_accuracy: 0.7364 - 2s/epoch - 290ms/step\n",
      "Epoch 141/250\n",
      "6/6 - 2s - loss: 0.5923 - accuracy: 0.8019 - val_loss: 0.8546 - val_accuracy: 0.7326 - 2s/epoch - 292ms/step\n",
      "Epoch 142/250\n",
      "6/6 - 2s - loss: 0.5715 - accuracy: 0.8078 - val_loss: 0.8801 - val_accuracy: 0.7403 - 2s/epoch - 286ms/step\n",
      "Epoch 143/250\n",
      "6/6 - 2s - loss: 0.5722 - accuracy: 0.8000 - val_loss: 0.8442 - val_accuracy: 0.7403 - 2s/epoch - 285ms/step\n",
      "Epoch 144/250\n",
      "6/6 - 3s - loss: 0.5539 - accuracy: 0.8097 - val_loss: 0.8616 - val_accuracy: 0.7326 - 3s/epoch - 430ms/step\n",
      "Epoch 145/250\n",
      "6/6 - 2s - loss: 0.5415 - accuracy: 0.8039 - val_loss: 0.8454 - val_accuracy: 0.7481 - 2s/epoch - 282ms/step\n",
      "Epoch 146/250\n",
      "6/6 - 2s - loss: 0.5353 - accuracy: 0.8126 - val_loss: 0.8214 - val_accuracy: 0.7597 - 2s/epoch - 285ms/step\n",
      "Epoch 147/250\n",
      "6/6 - 2s - loss: 0.5254 - accuracy: 0.8262 - val_loss: 0.8615 - val_accuracy: 0.7326 - 2s/epoch - 284ms/step\n",
      "Epoch 148/250\n",
      "6/6 - 2s - loss: 0.5513 - accuracy: 0.8117 - val_loss: 0.8195 - val_accuracy: 0.7674 - 2s/epoch - 283ms/step\n",
      "Epoch 149/250\n",
      "6/6 - 2s - loss: 0.5336 - accuracy: 0.8155 - val_loss: 0.8458 - val_accuracy: 0.7442 - 2s/epoch - 287ms/step\n",
      "Epoch 150/250\n",
      "6/6 - 2s - loss: 0.5307 - accuracy: 0.8282 - val_loss: 0.8155 - val_accuracy: 0.7713 - 2s/epoch - 354ms/step\n",
      "Epoch 151/250\n",
      "6/6 - 2s - loss: 0.5266 - accuracy: 0.8155 - val_loss: 0.8733 - val_accuracy: 0.7364 - 2s/epoch - 355ms/step\n",
      "Epoch 152/250\n",
      "6/6 - 2s - loss: 0.5432 - accuracy: 0.8126 - val_loss: 0.8449 - val_accuracy: 0.7326 - 2s/epoch - 286ms/step\n",
      "Epoch 153/250\n",
      "6/6 - 2s - loss: 0.5210 - accuracy: 0.8117 - val_loss: 0.8628 - val_accuracy: 0.7326 - 2s/epoch - 288ms/step\n",
      "Epoch 154/250\n",
      "6/6 - 2s - loss: 0.5257 - accuracy: 0.8272 - val_loss: 0.8218 - val_accuracy: 0.7519 - 2s/epoch - 286ms/step\n",
      "Epoch 155/250\n",
      "6/6 - 2s - loss: 0.4953 - accuracy: 0.8320 - val_loss: 0.8904 - val_accuracy: 0.7364 - 2s/epoch - 288ms/step\n",
      "Epoch 156/250\n",
      "6/6 - 2s - loss: 0.5288 - accuracy: 0.8107 - val_loss: 0.8102 - val_accuracy: 0.7636 - 2s/epoch - 280ms/step\n",
      "Epoch 157/250\n",
      "6/6 - 3s - loss: 0.4863 - accuracy: 0.8369 - val_loss: 0.8097 - val_accuracy: 0.7519 - 3s/epoch - 426ms/step\n",
      "Epoch 158/250\n",
      "6/6 - 2s - loss: 0.5039 - accuracy: 0.8291 - val_loss: 0.8255 - val_accuracy: 0.7403 - 2s/epoch - 291ms/step\n",
      "Epoch 159/250\n",
      "6/6 - 2s - loss: 0.5098 - accuracy: 0.8204 - val_loss: 0.8161 - val_accuracy: 0.7597 - 2s/epoch - 283ms/step\n",
      "Epoch 160/250\n",
      "6/6 - 2s - loss: 0.4954 - accuracy: 0.8369 - val_loss: 0.8127 - val_accuracy: 0.7752 - 2s/epoch - 278ms/step\n",
      "Epoch 161/250\n",
      "6/6 - 2s - loss: 0.4694 - accuracy: 0.8379 - val_loss: 0.7888 - val_accuracy: 0.7791 - 2s/epoch - 284ms/step\n",
      "Epoch 162/250\n",
      "6/6 - 2s - loss: 0.4672 - accuracy: 0.8476 - val_loss: 0.7804 - val_accuracy: 0.7752 - 2s/epoch - 287ms/step\n",
      "Epoch 163/250\n",
      "6/6 - 2s - loss: 0.4934 - accuracy: 0.8262 - val_loss: 0.8193 - val_accuracy: 0.7442 - 2s/epoch - 355ms/step\n",
      "Epoch 164/250\n",
      "6/6 - 2s - loss: 0.4608 - accuracy: 0.8447 - val_loss: 0.8015 - val_accuracy: 0.7752 - 2s/epoch - 364ms/step\n",
      "Epoch 165/250\n",
      "6/6 - 2s - loss: 0.4621 - accuracy: 0.8456 - val_loss: 0.7962 - val_accuracy: 0.7713 - 2s/epoch - 293ms/step\n",
      "Epoch 166/250\n",
      "6/6 - 2s - loss: 0.4355 - accuracy: 0.8515 - val_loss: 0.7813 - val_accuracy: 0.7713 - 2s/epoch - 290ms/step\n",
      "Epoch 167/250\n",
      "6/6 - 2s - loss: 0.4358 - accuracy: 0.8476 - val_loss: 0.8049 - val_accuracy: 0.7636 - 2s/epoch - 285ms/step\n",
      "Epoch 168/250\n",
      "6/6 - 2s - loss: 0.4334 - accuracy: 0.8544 - val_loss: 0.7999 - val_accuracy: 0.7791 - 2s/epoch - 288ms/step\n",
      "Epoch 169/250\n",
      "6/6 - 2s - loss: 0.4129 - accuracy: 0.8680 - val_loss: 0.8033 - val_accuracy: 0.7636 - 2s/epoch - 286ms/step\n",
      "Epoch 170/250\n",
      "6/6 - 3s - loss: 0.4205 - accuracy: 0.8592 - val_loss: 0.7911 - val_accuracy: 0.7752 - 3s/epoch - 505ms/step\n",
      "Epoch 171/250\n",
      "6/6 - 2s - loss: 0.4278 - accuracy: 0.8583 - val_loss: 0.8038 - val_accuracy: 0.7791 - 2s/epoch - 323ms/step\n",
      "Epoch 172/250\n",
      "6/6 - 2s - loss: 0.4341 - accuracy: 0.8447 - val_loss: 0.7949 - val_accuracy: 0.7868 - 2s/epoch - 293ms/step\n",
      "Epoch 173/250\n",
      "6/6 - 2s - loss: 0.4324 - accuracy: 0.8476 - val_loss: 0.8249 - val_accuracy: 0.7636 - 2s/epoch - 289ms/step\n",
      "Epoch 174/250\n",
      "6/6 - 2s - loss: 0.4153 - accuracy: 0.8621 - val_loss: 0.7882 - val_accuracy: 0.7868 - 2s/epoch - 393ms/step\n",
      "Epoch 175/250\n",
      "6/6 - 3s - loss: 0.4114 - accuracy: 0.8602 - val_loss: 0.8125 - val_accuracy: 0.7791 - 3s/epoch - 463ms/step\n",
      "Epoch 176/250\n",
      "6/6 - 3s - loss: 0.4159 - accuracy: 0.8592 - val_loss: 0.8021 - val_accuracy: 0.7829 - 3s/epoch - 546ms/step\n",
      "Epoch 177/250\n",
      "6/6 - 2s - loss: 0.4073 - accuracy: 0.8592 - val_loss: 0.7752 - val_accuracy: 0.7907 - 2s/epoch - 334ms/step\n",
      "Epoch 178/250\n",
      "6/6 - 2s - loss: 0.3952 - accuracy: 0.8650 - val_loss: 0.7834 - val_accuracy: 0.7868 - 2s/epoch - 287ms/step\n",
      "Epoch 179/250\n",
      "6/6 - 2s - loss: 0.3943 - accuracy: 0.8689 - val_loss: 0.7992 - val_accuracy: 0.7752 - 2s/epoch - 287ms/step\n",
      "Epoch 180/250\n",
      "6/6 - 2s - loss: 0.3814 - accuracy: 0.8670 - val_loss: 0.7948 - val_accuracy: 0.7829 - 2s/epoch - 290ms/step\n",
      "Epoch 181/250\n",
      "6/6 - 3s - loss: 0.3805 - accuracy: 0.8777 - val_loss: 0.8000 - val_accuracy: 0.7752 - 3s/epoch - 437ms/step\n",
      "Epoch 182/250\n",
      "6/6 - 2s - loss: 0.3530 - accuracy: 0.8883 - val_loss: 0.8168 - val_accuracy: 0.7752 - 2s/epoch - 337ms/step\n",
      "Epoch 183/250\n",
      "6/6 - 3s - loss: 0.3743 - accuracy: 0.8689 - val_loss: 0.8023 - val_accuracy: 0.7868 - 3s/epoch - 433ms/step\n",
      "Epoch 184/250\n",
      "6/6 - 2s - loss: 0.3489 - accuracy: 0.8796 - val_loss: 0.7859 - val_accuracy: 0.7868 - 2s/epoch - 346ms/step\n",
      "Epoch 185/250\n",
      "6/6 - 2s - loss: 0.3552 - accuracy: 0.8883 - val_loss: 0.7926 - val_accuracy: 0.7791 - 2s/epoch - 287ms/step\n",
      "Epoch 186/250\n",
      "6/6 - 2s - loss: 0.3411 - accuracy: 0.8932 - val_loss: 0.8109 - val_accuracy: 0.7752 - 2s/epoch - 306ms/step\n",
      "Epoch 187/250\n",
      "6/6 - 3s - loss: 0.3703 - accuracy: 0.8816 - val_loss: 0.7942 - val_accuracy: 0.7907 - 3s/epoch - 417ms/step\n",
      "Epoch 188/250\n",
      "6/6 - 2s - loss: 0.3573 - accuracy: 0.8806 - val_loss: 0.7842 - val_accuracy: 0.7829 - 2s/epoch - 284ms/step\n",
      "Epoch 189/250\n",
      "6/6 - 2s - loss: 0.3576 - accuracy: 0.8757 - val_loss: 0.8107 - val_accuracy: 0.7791 - 2s/epoch - 283ms/step\n",
      "Epoch 190/250\n",
      "6/6 - 2s - loss: 0.3519 - accuracy: 0.8689 - val_loss: 0.7987 - val_accuracy: 0.7636 - 2s/epoch - 299ms/step\n",
      "Epoch 191/250\n",
      "6/6 - 2s - loss: 0.3371 - accuracy: 0.8951 - val_loss: 0.7787 - val_accuracy: 0.7868 - 2s/epoch - 293ms/step\n",
      "Epoch 192/250\n",
      "6/6 - 2s - loss: 0.3349 - accuracy: 0.8990 - val_loss: 0.7957 - val_accuracy: 0.7907 - 2s/epoch - 286ms/step\n",
      "Epoch 193/250\n",
      "6/6 - 3s - loss: 0.3189 - accuracy: 0.8961 - val_loss: 0.7963 - val_accuracy: 0.7752 - 3s/epoch - 437ms/step\n",
      "Epoch 194/250\n",
      "6/6 - 2s - loss: 0.3134 - accuracy: 0.8981 - val_loss: 0.7971 - val_accuracy: 0.7791 - 2s/epoch - 291ms/step\n",
      "Epoch 195/250\n",
      "6/6 - 2s - loss: 0.3226 - accuracy: 0.8786 - val_loss: 0.8097 - val_accuracy: 0.7597 - 2s/epoch - 289ms/step\n",
      "Epoch 196/250\n",
      "6/6 - 2s - loss: 0.3536 - accuracy: 0.8777 - val_loss: 0.7876 - val_accuracy: 0.7868 - 2s/epoch - 298ms/step\n",
      "Epoch 197/250\n",
      "6/6 - 2s - loss: 0.3334 - accuracy: 0.8786 - val_loss: 0.8329 - val_accuracy: 0.7597 - 2s/epoch - 280ms/step\n",
      "Epoch 198/250\n",
      "6/6 - 2s - loss: 0.3268 - accuracy: 0.8981 - val_loss: 0.8020 - val_accuracy: 0.7791 - 2s/epoch - 278ms/step\n",
      "Epoch 199/250\n",
      "6/6 - 2s - loss: 0.3094 - accuracy: 0.8893 - val_loss: 0.8059 - val_accuracy: 0.7713 - 2s/epoch - 337ms/step\n",
      "Epoch 200/250\n",
      "6/6 - 2s - loss: 0.2865 - accuracy: 0.9136 - val_loss: 0.8109 - val_accuracy: 0.7791 - 2s/epoch - 366ms/step\n",
      "Epoch 201/250\n",
      "6/6 - 2s - loss: 0.2933 - accuracy: 0.8971 - val_loss: 0.8362 - val_accuracy: 0.7674 - 2s/epoch - 290ms/step\n",
      "Epoch 202/250\n",
      "6/6 - 2s - loss: 0.3137 - accuracy: 0.8951 - val_loss: 0.8084 - val_accuracy: 0.7868 - 2s/epoch - 299ms/step\n",
      "Epoch 203/250\n",
      "6/6 - 2s - loss: 0.2896 - accuracy: 0.8961 - val_loss: 0.8242 - val_accuracy: 0.7829 - 2s/epoch - 288ms/step\n",
      "Epoch 204/250\n",
      "6/6 - 2s - loss: 0.2936 - accuracy: 0.9097 - val_loss: 0.8140 - val_accuracy: 0.7791 - 2s/epoch - 294ms/step\n",
      "Epoch 205/250\n",
      "6/6 - 2s - loss: 0.2819 - accuracy: 0.9087 - val_loss: 0.8090 - val_accuracy: 0.7868 - 2s/epoch - 286ms/step\n",
      "Epoch 206/250\n",
      "6/6 - 3s - loss: 0.2715 - accuracy: 0.9155 - val_loss: 0.8141 - val_accuracy: 0.7868 - 3s/epoch - 442ms/step\n",
      "Epoch 207/250\n",
      "6/6 - 2s - loss: 0.2788 - accuracy: 0.9146 - val_loss: 0.8131 - val_accuracy: 0.7713 - 2s/epoch - 273ms/step\n",
      "Epoch 208/250\n",
      "6/6 - 2s - loss: 0.2648 - accuracy: 0.9214 - val_loss: 0.8073 - val_accuracy: 0.7907 - 2s/epoch - 273ms/step\n",
      "Epoch 209/250\n",
      "6/6 - 2s - loss: 0.2674 - accuracy: 0.9146 - val_loss: 0.8195 - val_accuracy: 0.7829 - 2s/epoch - 275ms/step\n",
      "Epoch 210/250\n",
      "6/6 - 2s - loss: 0.2558 - accuracy: 0.9117 - val_loss: 0.8267 - val_accuracy: 0.7674 - 2s/epoch - 280ms/step\n",
      "Epoch 211/250\n",
      "6/6 - 2s - loss: 0.2885 - accuracy: 0.9019 - val_loss: 0.8270 - val_accuracy: 0.7752 - 2s/epoch - 273ms/step\n",
      "Epoch 212/250\n",
      "6/6 - 2s - loss: 0.2772 - accuracy: 0.9087 - val_loss: 0.8131 - val_accuracy: 0.7946 - 2s/epoch - 282ms/step\n",
      "Epoch 213/250\n",
      "6/6 - 3s - loss: 0.2651 - accuracy: 0.9165 - val_loss: 0.8088 - val_accuracy: 0.7791 - 3s/epoch - 417ms/step\n",
      "Epoch 214/250\n",
      "6/6 - 2s - loss: 0.2412 - accuracy: 0.9165 - val_loss: 0.8222 - val_accuracy: 0.7868 - 2s/epoch - 275ms/step\n",
      "Epoch 215/250\n",
      "6/6 - 2s - loss: 0.2440 - accuracy: 0.9184 - val_loss: 0.8132 - val_accuracy: 0.7829 - 2s/epoch - 283ms/step\n",
      "Epoch 216/250\n",
      "6/6 - 2s - loss: 0.2416 - accuracy: 0.9262 - val_loss: 0.8323 - val_accuracy: 0.7791 - 2s/epoch - 282ms/step\n",
      "Epoch 217/250\n",
      "6/6 - 2s - loss: 0.2528 - accuracy: 0.9165 - val_loss: 0.8174 - val_accuracy: 0.7868 - 2s/epoch - 275ms/step\n",
      "Epoch 218/250\n",
      "6/6 - 2s - loss: 0.2449 - accuracy: 0.9155 - val_loss: 0.8178 - val_accuracy: 0.7984 - 2s/epoch - 271ms/step\n",
      "Epoch 219/250\n",
      "6/6 - 2s - loss: 0.2363 - accuracy: 0.9262 - val_loss: 0.8413 - val_accuracy: 0.7829 - 2s/epoch - 325ms/step\n",
      "Epoch 220/250\n",
      "6/6 - 2s - loss: 0.2282 - accuracy: 0.9262 - val_loss: 0.8270 - val_accuracy: 0.7946 - 2s/epoch - 366ms/step\n",
      "Epoch 221/250\n",
      "6/6 - 2s - loss: 0.2413 - accuracy: 0.9243 - val_loss: 0.7998 - val_accuracy: 0.7907 - 2s/epoch - 281ms/step\n",
      "Epoch 222/250\n",
      "6/6 - 2s - loss: 0.2323 - accuracy: 0.9243 - val_loss: 0.8365 - val_accuracy: 0.7713 - 2s/epoch - 341ms/step\n",
      "Epoch 223/250\n",
      "6/6 - 2s - loss: 0.2613 - accuracy: 0.9097 - val_loss: 0.8333 - val_accuracy: 0.7829 - 2s/epoch - 359ms/step\n",
      "Epoch 224/250\n",
      "6/6 - 2s - loss: 0.2555 - accuracy: 0.9087 - val_loss: 0.8117 - val_accuracy: 0.7907 - 2s/epoch - 277ms/step\n",
      "Epoch 225/250\n",
      "6/6 - 2s - loss: 0.2403 - accuracy: 0.9262 - val_loss: 0.8901 - val_accuracy: 0.7791 - 2s/epoch - 271ms/step\n",
      "Epoch 226/250\n",
      "6/6 - 3s - loss: 0.2367 - accuracy: 0.9204 - val_loss: 0.7913 - val_accuracy: 0.7868 - 3s/epoch - 418ms/step\n",
      "Epoch 227/250\n",
      "6/6 - 2s - loss: 0.2322 - accuracy: 0.9272 - val_loss: 0.8286 - val_accuracy: 0.7946 - 2s/epoch - 273ms/step\n",
      "Epoch 228/250\n",
      "6/6 - 2s - loss: 0.2111 - accuracy: 0.9291 - val_loss: 0.7921 - val_accuracy: 0.8023 - 2s/epoch - 271ms/step\n",
      "Epoch 229/250\n",
      "6/6 - 2s - loss: 0.2314 - accuracy: 0.9282 - val_loss: 0.8297 - val_accuracy: 0.7829 - 2s/epoch - 284ms/step\n",
      "Epoch 230/250\n",
      "6/6 - 2s - loss: 0.2100 - accuracy: 0.9320 - val_loss: 0.8951 - val_accuracy: 0.7791 - 2s/epoch - 281ms/step\n",
      "Epoch 231/250\n",
      "6/6 - 2s - loss: 0.2060 - accuracy: 0.9447 - val_loss: 0.8282 - val_accuracy: 0.7791 - 2s/epoch - 277ms/step\n",
      "Epoch 232/250\n",
      "6/6 - 2s - loss: 0.2045 - accuracy: 0.9330 - val_loss: 0.8388 - val_accuracy: 0.7713 - 2s/epoch - 307ms/step\n",
      "Epoch 233/250\n",
      "6/6 - 3s - loss: 0.2136 - accuracy: 0.9330 - val_loss: 0.8132 - val_accuracy: 0.8023 - 3s/epoch - 441ms/step\n",
      "Epoch 234/250\n",
      "6/6 - 2s - loss: 0.1934 - accuracy: 0.9408 - val_loss: 0.8445 - val_accuracy: 0.8023 - 2s/epoch - 281ms/step\n",
      "Epoch 235/250\n",
      "6/6 - 2s - loss: 0.1988 - accuracy: 0.9369 - val_loss: 0.8149 - val_accuracy: 0.7984 - 2s/epoch - 275ms/step\n",
      "Epoch 236/250\n",
      "6/6 - 2s - loss: 0.1855 - accuracy: 0.9485 - val_loss: 0.8325 - val_accuracy: 0.7752 - 2s/epoch - 275ms/step\n",
      "Epoch 237/250\n",
      "6/6 - 2s - loss: 0.1856 - accuracy: 0.9398 - val_loss: 0.8431 - val_accuracy: 0.7868 - 2s/epoch - 278ms/step\n",
      "Epoch 238/250\n",
      "6/6 - 2s - loss: 0.1830 - accuracy: 0.9417 - val_loss: 0.8402 - val_accuracy: 0.7907 - 2s/epoch - 282ms/step\n",
      "Epoch 239/250\n",
      "6/6 - 3s - loss: 0.1719 - accuracy: 0.9505 - val_loss: 0.8415 - val_accuracy: 0.7829 - 3s/epoch - 421ms/step\n",
      "Epoch 240/250\n",
      "6/6 - 2s - loss: 0.1747 - accuracy: 0.9476 - val_loss: 0.8450 - val_accuracy: 0.7984 - 2s/epoch - 291ms/step\n",
      "Epoch 241/250\n",
      "6/6 - 2s - loss: 0.1818 - accuracy: 0.9379 - val_loss: 0.8547 - val_accuracy: 0.7868 - 2s/epoch - 277ms/step\n",
      "Epoch 242/250\n",
      "6/6 - 2s - loss: 0.1833 - accuracy: 0.9495 - val_loss: 0.8441 - val_accuracy: 0.8062 - 2s/epoch - 277ms/step\n",
      "Epoch 243/250\n",
      "6/6 - 2s - loss: 0.1703 - accuracy: 0.9583 - val_loss: 0.8655 - val_accuracy: 0.7984 - 2s/epoch - 278ms/step\n",
      "Epoch 244/250\n",
      "6/6 - 2s - loss: 0.1700 - accuracy: 0.9544 - val_loss: 0.8583 - val_accuracy: 0.7752 - 2s/epoch - 273ms/step\n",
      "Epoch 245/250\n",
      "6/6 - 2s - loss: 0.1835 - accuracy: 0.9447 - val_loss: 0.8518 - val_accuracy: 0.7713 - 2s/epoch - 276ms/step\n",
      "Epoch 246/250\n",
      "6/6 - 3s - loss: 0.1643 - accuracy: 0.9534 - val_loss: 0.8491 - val_accuracy: 0.8101 - 3s/epoch - 430ms/step\n",
      "Epoch 247/250\n",
      "6/6 - 2s - loss: 0.1616 - accuracy: 0.9534 - val_loss: 0.8292 - val_accuracy: 0.8023 - 2s/epoch - 278ms/step\n",
      "Epoch 248/250\n",
      "6/6 - 2s - loss: 0.1541 - accuracy: 0.9583 - val_loss: 0.8686 - val_accuracy: 0.7868 - 2s/epoch - 274ms/step\n",
      "Epoch 249/250\n",
      "6/6 - 2s - loss: 0.1571 - accuracy: 0.9592 - val_loss: 0.8437 - val_accuracy: 0.7907 - 2s/epoch - 272ms/step\n",
      "Epoch 250/250\n",
      "6/6 - 2s - loss: 0.1436 - accuracy: 0.9612 - val_loss: 0.9082 - val_accuracy: 0.7791 - 2s/epoch - 286ms/step\n",
      "9/9 [==============================] - 0s 13ms/step\n",
      "Epoch 1/250\n",
      "6/6 - 4s - loss: 1.8979 - accuracy: 0.3845 - val_loss: 1.7417 - val_accuracy: 0.3876 - 4s/epoch - 669ms/step\n",
      "Epoch 2/250\n",
      "6/6 - 3s - loss: 1.7048 - accuracy: 0.4175 - val_loss: 1.7406 - val_accuracy: 0.3876 - 3s/epoch - 456ms/step\n",
      "Epoch 3/250\n",
      "6/6 - 3s - loss: 1.6858 - accuracy: 0.4175 - val_loss: 1.7398 - val_accuracy: 0.3876 - 3s/epoch - 481ms/step\n",
      "Epoch 4/250\n",
      "6/6 - 4s - loss: 1.6699 - accuracy: 0.4175 - val_loss: 1.7352 - val_accuracy: 0.3876 - 4s/epoch - 598ms/step\n",
      "Epoch 5/250\n",
      "6/6 - 3s - loss: 1.6709 - accuracy: 0.4175 - val_loss: 1.7354 - val_accuracy: 0.3876 - 3s/epoch - 454ms/step\n",
      "Epoch 6/250\n",
      "6/6 - 3s - loss: 1.6754 - accuracy: 0.4175 - val_loss: 1.7345 - val_accuracy: 0.3876 - 3s/epoch - 458ms/step\n",
      "Epoch 7/250\n",
      "6/6 - 3s - loss: 1.7031 - accuracy: 0.4175 - val_loss: 1.7418 - val_accuracy: 0.3876 - 3s/epoch - 488ms/step\n",
      "Epoch 8/250\n",
      "6/6 - 3s - loss: 1.6915 - accuracy: 0.4175 - val_loss: 1.7566 - val_accuracy: 0.3876 - 3s/epoch - 576ms/step\n",
      "Epoch 9/250\n",
      "6/6 - 3s - loss: 1.6721 - accuracy: 0.4175 - val_loss: 1.7458 - val_accuracy: 0.3876 - 3s/epoch - 487ms/step\n",
      "Epoch 10/250\n",
      "6/6 - 3s - loss: 1.6713 - accuracy: 0.4175 - val_loss: 1.7660 - val_accuracy: 0.3876 - 3s/epoch - 457ms/step\n",
      "Epoch 11/250\n",
      "6/6 - 3s - loss: 1.6736 - accuracy: 0.4175 - val_loss: 1.7343 - val_accuracy: 0.3876 - 3s/epoch - 480ms/step\n",
      "Epoch 12/250\n",
      "6/6 - 3s - loss: 1.6700 - accuracy: 0.4175 - val_loss: 1.7418 - val_accuracy: 0.3876 - 3s/epoch - 573ms/step\n",
      "Epoch 13/250\n",
      "6/6 - 3s - loss: 1.6720 - accuracy: 0.4175 - val_loss: 1.7286 - val_accuracy: 0.3876 - 3s/epoch - 518ms/step\n",
      "Epoch 14/250\n",
      "6/6 - 3s - loss: 1.6703 - accuracy: 0.4175 - val_loss: 1.7430 - val_accuracy: 0.3876 - 3s/epoch - 506ms/step\n",
      "Epoch 15/250\n",
      "6/6 - 3s - loss: 1.6741 - accuracy: 0.4175 - val_loss: 1.7369 - val_accuracy: 0.3876 - 3s/epoch - 555ms/step\n",
      "Epoch 16/250\n",
      "6/6 - 3s - loss: 1.6688 - accuracy: 0.4175 - val_loss: 1.7344 - val_accuracy: 0.3876 - 3s/epoch - 506ms/step\n",
      "Epoch 17/250\n",
      "6/6 - 3s - loss: 1.6752 - accuracy: 0.4175 - val_loss: 1.7306 - val_accuracy: 0.3876 - 3s/epoch - 458ms/step\n",
      "Epoch 18/250\n",
      "6/6 - 3s - loss: 1.6709 - accuracy: 0.4175 - val_loss: 1.7277 - val_accuracy: 0.3876 - 3s/epoch - 465ms/step\n",
      "Epoch 19/250\n",
      "6/6 - 3s - loss: 1.6694 - accuracy: 0.4175 - val_loss: 1.7284 - val_accuracy: 0.3876 - 3s/epoch - 511ms/step\n",
      "Epoch 20/250\n",
      "6/6 - 3s - loss: 1.6706 - accuracy: 0.4175 - val_loss: 1.7344 - val_accuracy: 0.3876 - 3s/epoch - 536ms/step\n",
      "Epoch 21/250\n",
      "6/6 - 3s - loss: 1.6705 - accuracy: 0.4175 - val_loss: 1.7318 - val_accuracy: 0.3876 - 3s/epoch - 571ms/step\n",
      "Epoch 22/250\n",
      "6/6 - 3s - loss: 1.6685 - accuracy: 0.4175 - val_loss: 1.7532 - val_accuracy: 0.3876 - 3s/epoch - 456ms/step\n",
      "Epoch 23/250\n",
      "6/6 - 3s - loss: 1.6706 - accuracy: 0.4175 - val_loss: 1.7381 - val_accuracy: 0.3876 - 3s/epoch - 568ms/step\n",
      "Epoch 24/250\n",
      "6/6 - 3s - loss: 1.6664 - accuracy: 0.4175 - val_loss: 1.7360 - val_accuracy: 0.3876 - 3s/epoch - 482ms/step\n",
      "Epoch 25/250\n",
      "6/6 - 3s - loss: 1.6651 - accuracy: 0.4175 - val_loss: 1.7296 - val_accuracy: 0.3876 - 3s/epoch - 456ms/step\n",
      "Epoch 26/250\n",
      "6/6 - 3s - loss: 1.6673 - accuracy: 0.4175 - val_loss: 1.7313 - val_accuracy: 0.3876 - 3s/epoch - 452ms/step\n",
      "Epoch 27/250\n",
      "6/6 - 3s - loss: 1.6673 - accuracy: 0.4175 - val_loss: 1.7323 - val_accuracy: 0.3876 - 3s/epoch - 511ms/step\n",
      "Epoch 28/250\n",
      "6/6 - 3s - loss: 1.6638 - accuracy: 0.4175 - val_loss: 1.7394 - val_accuracy: 0.3876 - 3s/epoch - 534ms/step\n",
      "Epoch 29/250\n",
      "6/6 - 3s - loss: 1.6640 - accuracy: 0.4175 - val_loss: 1.7418 - val_accuracy: 0.3876 - 3s/epoch - 451ms/step\n",
      "Epoch 30/250\n",
      "6/6 - 3s - loss: 1.6689 - accuracy: 0.4175 - val_loss: 1.7369 - val_accuracy: 0.3876 - 3s/epoch - 460ms/step\n",
      "Epoch 31/250\n",
      "6/6 - 3s - loss: 1.6745 - accuracy: 0.4175 - val_loss: 1.7339 - val_accuracy: 0.3876 - 3s/epoch - 483ms/step\n",
      "Epoch 32/250\n",
      "6/6 - 3s - loss: 1.6664 - accuracy: 0.4175 - val_loss: 1.7440 - val_accuracy: 0.3876 - 3s/epoch - 572ms/step\n",
      "Epoch 33/250\n",
      "6/6 - 3s - loss: 1.6706 - accuracy: 0.4175 - val_loss: 1.7362 - val_accuracy: 0.3876 - 3s/epoch - 452ms/step\n",
      "Epoch 34/250\n",
      "6/6 - 3s - loss: 1.6624 - accuracy: 0.4175 - val_loss: 1.7558 - val_accuracy: 0.3876 - 3s/epoch - 459ms/step\n",
      "Epoch 35/250\n",
      "6/6 - 3s - loss: 1.6643 - accuracy: 0.4175 - val_loss: 1.7368 - val_accuracy: 0.3876 - 3s/epoch - 450ms/step\n",
      "Epoch 36/250\n",
      "6/6 - 4s - loss: 1.6624 - accuracy: 0.4175 - val_loss: 1.7360 - val_accuracy: 0.3876 - 4s/epoch - 589ms/step\n",
      "Epoch 37/250\n",
      "6/6 - 3s - loss: 1.6607 - accuracy: 0.4175 - val_loss: 1.7295 - val_accuracy: 0.3876 - 3s/epoch - 451ms/step\n",
      "Epoch 38/250\n",
      "6/6 - 3s - loss: 1.6608 - accuracy: 0.4175 - val_loss: 1.7279 - val_accuracy: 0.3876 - 3s/epoch - 451ms/step\n",
      "Epoch 39/250\n",
      "6/6 - 3s - loss: 1.6685 - accuracy: 0.4175 - val_loss: 1.7294 - val_accuracy: 0.3876 - 3s/epoch - 449ms/step\n",
      "Epoch 40/250\n",
      "6/6 - 4s - loss: 1.6582 - accuracy: 0.4175 - val_loss: 1.7372 - val_accuracy: 0.3876 - 4s/epoch - 599ms/step\n",
      "Epoch 41/250\n",
      "6/6 - 3s - loss: 1.6567 - accuracy: 0.4175 - val_loss: 1.7317 - val_accuracy: 0.3876 - 3s/epoch - 454ms/step\n",
      "Epoch 42/250\n",
      "6/6 - 3s - loss: 1.6556 - accuracy: 0.4175 - val_loss: 1.7318 - val_accuracy: 0.3876 - 3s/epoch - 448ms/step\n",
      "Epoch 43/250\n",
      "6/6 - 3s - loss: 1.6549 - accuracy: 0.4175 - val_loss: 1.7329 - val_accuracy: 0.3876 - 3s/epoch - 452ms/step\n",
      "Epoch 44/250\n",
      "6/6 - 4s - loss: 1.6543 - accuracy: 0.4175 - val_loss: 1.7282 - val_accuracy: 0.3876 - 4s/epoch - 590ms/step\n",
      "Epoch 45/250\n",
      "6/6 - 3s - loss: 1.6510 - accuracy: 0.4175 - val_loss: 1.7379 - val_accuracy: 0.3876 - 3s/epoch - 450ms/step\n",
      "Epoch 46/250\n",
      "6/6 - 3s - loss: 1.6639 - accuracy: 0.4175 - val_loss: 1.7235 - val_accuracy: 0.3876 - 3s/epoch - 446ms/step\n",
      "Epoch 47/250\n",
      "6/6 - 3s - loss: 1.6533 - accuracy: 0.4175 - val_loss: 1.7287 - val_accuracy: 0.3876 - 3s/epoch - 449ms/step\n",
      "Epoch 48/250\n",
      "6/6 - 3s - loss: 1.6449 - accuracy: 0.4175 - val_loss: 1.7296 - val_accuracy: 0.3876 - 3s/epoch - 575ms/step\n",
      "Epoch 49/250\n",
      "6/6 - 3s - loss: 1.6548 - accuracy: 0.4175 - val_loss: 1.7206 - val_accuracy: 0.3876 - 3s/epoch - 501ms/step\n",
      "Epoch 50/250\n",
      "6/6 - 3s - loss: 1.6507 - accuracy: 0.4175 - val_loss: 1.7240 - val_accuracy: 0.3876 - 3s/epoch - 450ms/step\n",
      "Epoch 51/250\n",
      "6/6 - 3s - loss: 1.6458 - accuracy: 0.4175 - val_loss: 1.7157 - val_accuracy: 0.3876 - 3s/epoch - 451ms/step\n",
      "Epoch 52/250\n",
      "6/6 - 3s - loss: 1.6327 - accuracy: 0.4175 - val_loss: 1.7180 - val_accuracy: 0.3876 - 3s/epoch - 560ms/step\n",
      "Epoch 53/250\n",
      "6/6 - 3s - loss: 1.6209 - accuracy: 0.4175 - val_loss: 1.7065 - val_accuracy: 0.3876 - 3s/epoch - 494ms/step\n",
      "Epoch 54/250\n",
      "6/6 - 3s - loss: 1.6297 - accuracy: 0.4175 - val_loss: 1.7085 - val_accuracy: 0.3876 - 3s/epoch - 452ms/step\n",
      "Epoch 55/250\n",
      "6/6 - 3s - loss: 1.5996 - accuracy: 0.4175 - val_loss: 1.6969 - val_accuracy: 0.3876 - 3s/epoch - 454ms/step\n",
      "Epoch 56/250\n",
      "6/6 - 3s - loss: 1.5863 - accuracy: 0.4184 - val_loss: 1.6835 - val_accuracy: 0.3876 - 3s/epoch - 508ms/step\n",
      "Epoch 57/250\n",
      "6/6 - 3s - loss: 1.5754 - accuracy: 0.4194 - val_loss: 1.6729 - val_accuracy: 0.3876 - 3s/epoch - 544ms/step\n",
      "Epoch 58/250\n",
      "6/6 - 3s - loss: 1.5596 - accuracy: 0.4194 - val_loss: 1.6696 - val_accuracy: 0.3876 - 3s/epoch - 482ms/step\n",
      "Epoch 59/250\n",
      "6/6 - 3s - loss: 1.5500 - accuracy: 0.4243 - val_loss: 1.6505 - val_accuracy: 0.4147 - 3s/epoch - 455ms/step\n",
      "Epoch 60/250\n",
      "6/6 - 3s - loss: 1.5291 - accuracy: 0.4515 - val_loss: 1.6495 - val_accuracy: 0.4109 - 3s/epoch - 466ms/step\n",
      "Epoch 61/250\n",
      "6/6 - 3s - loss: 1.5055 - accuracy: 0.4505 - val_loss: 1.6249 - val_accuracy: 0.4186 - 3s/epoch - 576ms/step\n",
      "Epoch 62/250\n",
      "6/6 - 3s - loss: 1.4820 - accuracy: 0.4583 - val_loss: 1.6349 - val_accuracy: 0.4186 - 3s/epoch - 456ms/step\n",
      "Epoch 63/250\n",
      "6/6 - 3s - loss: 1.4845 - accuracy: 0.4553 - val_loss: 1.5900 - val_accuracy: 0.4225 - 3s/epoch - 453ms/step\n",
      "Epoch 64/250\n",
      "6/6 - 3s - loss: 1.4505 - accuracy: 0.4786 - val_loss: 1.5935 - val_accuracy: 0.4264 - 3s/epoch - 452ms/step\n",
      "Epoch 65/250\n",
      "6/6 - 4s - loss: 1.4251 - accuracy: 0.4796 - val_loss: 1.5842 - val_accuracy: 0.4380 - 4s/epoch - 591ms/step\n",
      "Epoch 66/250\n",
      "6/6 - 3s - loss: 1.4215 - accuracy: 0.4835 - val_loss: 1.5662 - val_accuracy: 0.4186 - 3s/epoch - 454ms/step\n",
      "Epoch 67/250\n",
      "6/6 - 3s - loss: 1.3956 - accuracy: 0.4854 - val_loss: 1.5704 - val_accuracy: 0.4574 - 3s/epoch - 449ms/step\n",
      "Epoch 68/250\n",
      "6/6 - 3s - loss: 1.3890 - accuracy: 0.4913 - val_loss: 1.5876 - val_accuracy: 0.4380 - 3s/epoch - 452ms/step\n",
      "Epoch 69/250\n",
      "6/6 - 4s - loss: 1.3939 - accuracy: 0.4767 - val_loss: 1.5602 - val_accuracy: 0.4341 - 4s/epoch - 594ms/step\n",
      "Epoch 70/250\n",
      "6/6 - 3s - loss: 1.3656 - accuracy: 0.5039 - val_loss: 1.5376 - val_accuracy: 0.4574 - 3s/epoch - 447ms/step\n",
      "Epoch 71/250\n",
      "6/6 - 3s - loss: 1.3723 - accuracy: 0.5019 - val_loss: 1.5371 - val_accuracy: 0.4690 - 3s/epoch - 453ms/step\n",
      "Epoch 72/250\n",
      "6/6 - 3s - loss: 1.3432 - accuracy: 0.5078 - val_loss: 1.4944 - val_accuracy: 0.4806 - 3s/epoch - 450ms/step\n",
      "Epoch 73/250\n",
      "6/6 - 4s - loss: 1.3151 - accuracy: 0.5282 - val_loss: 1.5095 - val_accuracy: 0.4922 - 4s/epoch - 588ms/step\n",
      "Epoch 74/250\n",
      "6/6 - 3s - loss: 1.3105 - accuracy: 0.5301 - val_loss: 1.4761 - val_accuracy: 0.5078 - 3s/epoch - 453ms/step\n",
      "Epoch 75/250\n",
      "6/6 - 3s - loss: 1.3013 - accuracy: 0.5515 - val_loss: 1.5236 - val_accuracy: 0.4690 - 3s/epoch - 450ms/step\n",
      "Epoch 76/250\n",
      "6/6 - 3s - loss: 1.2975 - accuracy: 0.5379 - val_loss: 1.4571 - val_accuracy: 0.5116 - 3s/epoch - 452ms/step\n",
      "Epoch 77/250\n",
      "6/6 - 4s - loss: 1.2805 - accuracy: 0.5534 - val_loss: 1.4579 - val_accuracy: 0.5039 - 4s/epoch - 588ms/step\n",
      "Epoch 78/250\n",
      "6/6 - 3s - loss: 1.2629 - accuracy: 0.5563 - val_loss: 1.4609 - val_accuracy: 0.5155 - 3s/epoch - 448ms/step\n",
      "Epoch 79/250\n",
      "6/6 - 3s - loss: 1.2706 - accuracy: 0.5485 - val_loss: 1.4389 - val_accuracy: 0.5194 - 3s/epoch - 480ms/step\n",
      "Epoch 80/250\n",
      "6/6 - 3s - loss: 1.2514 - accuracy: 0.5650 - val_loss: 1.4266 - val_accuracy: 0.5233 - 3s/epoch - 486ms/step\n",
      "Epoch 81/250\n",
      "6/6 - 3s - loss: 1.2322 - accuracy: 0.5757 - val_loss: 1.5050 - val_accuracy: 0.4884 - 3s/epoch - 582ms/step\n",
      "Epoch 82/250\n",
      "6/6 - 3s - loss: 1.2381 - accuracy: 0.5680 - val_loss: 1.4370 - val_accuracy: 0.5194 - 3s/epoch - 448ms/step\n",
      "Epoch 83/250\n",
      "6/6 - 3s - loss: 1.2583 - accuracy: 0.5612 - val_loss: 1.4349 - val_accuracy: 0.5388 - 3s/epoch - 480ms/step\n",
      "Epoch 84/250\n",
      "6/6 - 3s - loss: 1.2589 - accuracy: 0.5544 - val_loss: 1.4286 - val_accuracy: 0.5078 - 3s/epoch - 456ms/step\n",
      "Epoch 85/250\n",
      "6/6 - 3s - loss: 1.2303 - accuracy: 0.5709 - val_loss: 1.4083 - val_accuracy: 0.5155 - 3s/epoch - 576ms/step\n",
      "Epoch 86/250\n",
      "6/6 - 3s - loss: 1.2135 - accuracy: 0.5757 - val_loss: 1.4072 - val_accuracy: 0.5233 - 3s/epoch - 468ms/step\n",
      "Epoch 87/250\n",
      "6/6 - 3s - loss: 1.1970 - accuracy: 0.5699 - val_loss: 1.4172 - val_accuracy: 0.5388 - 3s/epoch - 448ms/step\n",
      "Epoch 88/250\n",
      "6/6 - 3s - loss: 1.2016 - accuracy: 0.5971 - val_loss: 1.3719 - val_accuracy: 0.5310 - 3s/epoch - 450ms/step\n",
      "Epoch 89/250\n",
      "6/6 - 3s - loss: 1.1902 - accuracy: 0.5961 - val_loss: 1.3703 - val_accuracy: 0.5310 - 3s/epoch - 518ms/step\n",
      "Epoch 90/250\n",
      "6/6 - 3s - loss: 1.1799 - accuracy: 0.5932 - val_loss: 1.3735 - val_accuracy: 0.5465 - 3s/epoch - 527ms/step\n",
      "Epoch 91/250\n",
      "6/6 - 3s - loss: 1.1863 - accuracy: 0.5903 - val_loss: 1.3805 - val_accuracy: 0.5388 - 3s/epoch - 454ms/step\n",
      "Epoch 92/250\n",
      "6/6 - 3s - loss: 1.1802 - accuracy: 0.5961 - val_loss: 1.3570 - val_accuracy: 0.5504 - 3s/epoch - 459ms/step\n",
      "Epoch 93/250\n",
      "6/6 - 3s - loss: 1.1898 - accuracy: 0.5893 - val_loss: 1.3927 - val_accuracy: 0.5039 - 3s/epoch - 491ms/step\n",
      "Epoch 94/250\n",
      "6/6 - 3s - loss: 1.1724 - accuracy: 0.5971 - val_loss: 1.3494 - val_accuracy: 0.5504 - 3s/epoch - 565ms/step\n",
      "Epoch 95/250\n",
      "6/6 - 3s - loss: 1.1511 - accuracy: 0.6019 - val_loss: 1.3720 - val_accuracy: 0.5543 - 3s/epoch - 461ms/step\n",
      "Epoch 96/250\n",
      "6/6 - 3s - loss: 1.1524 - accuracy: 0.6049 - val_loss: 1.3369 - val_accuracy: 0.5581 - 3s/epoch - 460ms/step\n",
      "Epoch 97/250\n",
      "6/6 - 3s - loss: 1.1470 - accuracy: 0.6175 - val_loss: 1.3522 - val_accuracy: 0.5581 - 3s/epoch - 484ms/step\n",
      "Epoch 98/250\n",
      "6/6 - 3s - loss: 1.1461 - accuracy: 0.6223 - val_loss: 1.3155 - val_accuracy: 0.5581 - 3s/epoch - 570ms/step\n",
      "Epoch 99/250\n",
      "6/6 - 3s - loss: 1.1308 - accuracy: 0.6214 - val_loss: 1.3660 - val_accuracy: 0.5233 - 3s/epoch - 450ms/step\n",
      "Epoch 100/250\n",
      "6/6 - 3s - loss: 1.1436 - accuracy: 0.6039 - val_loss: 1.3115 - val_accuracy: 0.5426 - 3s/epoch - 461ms/step\n",
      "Epoch 101/250\n",
      "6/6 - 3s - loss: 1.1526 - accuracy: 0.6000 - val_loss: 1.3928 - val_accuracy: 0.5233 - 3s/epoch - 448ms/step\n",
      "Epoch 102/250\n",
      "6/6 - 4s - loss: 1.1839 - accuracy: 0.5913 - val_loss: 1.4165 - val_accuracy: 0.5078 - 4s/epoch - 591ms/step\n",
      "Epoch 103/250\n",
      "6/6 - 3s - loss: 1.1611 - accuracy: 0.6019 - val_loss: 1.3506 - val_accuracy: 0.5426 - 3s/epoch - 452ms/step\n",
      "Epoch 104/250\n",
      "6/6 - 3s - loss: 1.1367 - accuracy: 0.6223 - val_loss: 1.3321 - val_accuracy: 0.5310 - 3s/epoch - 451ms/step\n",
      "Epoch 105/250\n",
      "6/6 - 3s - loss: 1.1086 - accuracy: 0.6282 - val_loss: 1.3132 - val_accuracy: 0.5465 - 3s/epoch - 454ms/step\n",
      "Epoch 106/250\n",
      "6/6 - 4s - loss: 1.1129 - accuracy: 0.6262 - val_loss: 1.2881 - val_accuracy: 0.5659 - 4s/epoch - 589ms/step\n",
      "Epoch 107/250\n",
      "6/6 - 3s - loss: 1.0955 - accuracy: 0.6350 - val_loss: 1.2754 - val_accuracy: 0.5581 - 3s/epoch - 450ms/step\n",
      "Epoch 108/250\n",
      "6/6 - 3s - loss: 1.0876 - accuracy: 0.6369 - val_loss: 1.2812 - val_accuracy: 0.5504 - 3s/epoch - 447ms/step\n",
      "Epoch 109/250\n",
      "6/6 - 3s - loss: 1.0719 - accuracy: 0.6369 - val_loss: 1.3653 - val_accuracy: 0.5426 - 3s/epoch - 456ms/step\n",
      "Epoch 110/250\n",
      "6/6 - 4s - loss: 1.1107 - accuracy: 0.6107 - val_loss: 1.2822 - val_accuracy: 0.5736 - 4s/epoch - 594ms/step\n",
      "Epoch 111/250\n",
      "6/6 - 3s - loss: 1.1176 - accuracy: 0.6117 - val_loss: 1.2560 - val_accuracy: 0.5581 - 3s/epoch - 449ms/step\n",
      "Epoch 112/250\n",
      "6/6 - 3s - loss: 1.1185 - accuracy: 0.6155 - val_loss: 1.2733 - val_accuracy: 0.5504 - 3s/epoch - 446ms/step\n",
      "Epoch 113/250\n",
      "6/6 - 3s - loss: 1.0819 - accuracy: 0.6437 - val_loss: 1.2973 - val_accuracy: 0.5426 - 3s/epoch - 451ms/step\n",
      "Epoch 114/250\n",
      "6/6 - 3s - loss: 1.0807 - accuracy: 0.6437 - val_loss: 1.2964 - val_accuracy: 0.5388 - 3s/epoch - 559ms/step\n",
      "Epoch 115/250\n",
      "6/6 - 3s - loss: 1.0652 - accuracy: 0.6437 - val_loss: 1.2574 - val_accuracy: 0.5736 - 3s/epoch - 483ms/step\n",
      "Epoch 116/250\n",
      "6/6 - 3s - loss: 1.0493 - accuracy: 0.6476 - val_loss: 1.2521 - val_accuracy: 0.5698 - 3s/epoch - 452ms/step\n",
      "Epoch 117/250\n",
      "6/6 - 3s - loss: 1.0382 - accuracy: 0.6495 - val_loss: 1.2483 - val_accuracy: 0.5543 - 3s/epoch - 456ms/step\n",
      "Epoch 118/250\n",
      "6/6 - 3s - loss: 1.0509 - accuracy: 0.6583 - val_loss: 1.2392 - val_accuracy: 0.5620 - 3s/epoch - 529ms/step\n",
      "Epoch 119/250\n",
      "6/6 - 3s - loss: 1.0227 - accuracy: 0.6515 - val_loss: 1.2329 - val_accuracy: 0.5659 - 3s/epoch - 520ms/step\n",
      "Epoch 120/250\n",
      "6/6 - 3s - loss: 1.0171 - accuracy: 0.6641 - val_loss: 1.2265 - val_accuracy: 0.5736 - 3s/epoch - 451ms/step\n",
      "Epoch 121/250\n",
      "6/6 - 3s - loss: 1.0239 - accuracy: 0.6485 - val_loss: 1.2224 - val_accuracy: 0.5891 - 3s/epoch - 455ms/step\n",
      "Epoch 122/250\n",
      "6/6 - 3s - loss: 1.0246 - accuracy: 0.6612 - val_loss: 1.2391 - val_accuracy: 0.5736 - 3s/epoch - 478ms/step\n",
      "Epoch 123/250\n",
      "6/6 - 3s - loss: 1.0381 - accuracy: 0.6485 - val_loss: 1.2024 - val_accuracy: 0.5969 - 3s/epoch - 567ms/step\n",
      "Epoch 124/250\n",
      "6/6 - 3s - loss: 1.0236 - accuracy: 0.6689 - val_loss: 1.2451 - val_accuracy: 0.5620 - 3s/epoch - 451ms/step\n",
      "Epoch 125/250\n",
      "6/6 - 3s - loss: 1.0191 - accuracy: 0.6544 - val_loss: 1.2214 - val_accuracy: 0.5736 - 3s/epoch - 447ms/step\n",
      "Epoch 126/250\n",
      "6/6 - 3s - loss: 1.0058 - accuracy: 0.6592 - val_loss: 1.2093 - val_accuracy: 0.5736 - 3s/epoch - 452ms/step\n",
      "Epoch 127/250\n",
      "6/6 - 4s - loss: 0.9949 - accuracy: 0.6660 - val_loss: 1.2119 - val_accuracy: 0.5736 - 4s/epoch - 591ms/step\n",
      "Epoch 128/250\n",
      "6/6 - 3s - loss: 1.0266 - accuracy: 0.6476 - val_loss: 1.2279 - val_accuracy: 0.5698 - 3s/epoch - 447ms/step\n",
      "Epoch 129/250\n",
      "6/6 - 3s - loss: 1.0082 - accuracy: 0.6602 - val_loss: 1.2014 - val_accuracy: 0.5698 - 3s/epoch - 452ms/step\n",
      "Epoch 130/250\n",
      "6/6 - 3s - loss: 0.9774 - accuracy: 0.6631 - val_loss: 1.2061 - val_accuracy: 0.5736 - 3s/epoch - 450ms/step\n",
      "Epoch 131/250\n",
      "6/6 - 4s - loss: 0.9818 - accuracy: 0.6680 - val_loss: 1.2156 - val_accuracy: 0.5775 - 4s/epoch - 595ms/step\n",
      "Epoch 132/250\n",
      "6/6 - 3s - loss: 0.9874 - accuracy: 0.6602 - val_loss: 1.1811 - val_accuracy: 0.6202 - 3s/epoch - 449ms/step\n",
      "Epoch 133/250\n",
      "6/6 - 3s - loss: 0.9917 - accuracy: 0.6738 - val_loss: 1.1651 - val_accuracy: 0.6163 - 3s/epoch - 454ms/step\n",
      "Epoch 134/250\n",
      "6/6 - 3s - loss: 0.9934 - accuracy: 0.6728 - val_loss: 1.1877 - val_accuracy: 0.5930 - 3s/epoch - 452ms/step\n",
      "Epoch 135/250\n",
      "6/6 - 4s - loss: 0.9598 - accuracy: 0.6864 - val_loss: 1.1605 - val_accuracy: 0.6085 - 4s/epoch - 619ms/step\n",
      "Epoch 136/250\n",
      "6/6 - 3s - loss: 0.9470 - accuracy: 0.6796 - val_loss: 1.1729 - val_accuracy: 0.5891 - 3s/epoch - 457ms/step\n",
      "Epoch 137/250\n",
      "6/6 - 3s - loss: 0.9416 - accuracy: 0.6854 - val_loss: 1.1383 - val_accuracy: 0.6395 - 3s/epoch - 451ms/step\n",
      "Epoch 138/250\n",
      "6/6 - 3s - loss: 0.9659 - accuracy: 0.6709 - val_loss: 1.1792 - val_accuracy: 0.5930 - 3s/epoch - 448ms/step\n",
      "Epoch 139/250\n",
      "6/6 - 4s - loss: 0.9561 - accuracy: 0.6874 - val_loss: 1.1664 - val_accuracy: 0.6202 - 4s/epoch - 593ms/step\n",
      "Epoch 140/250\n",
      "6/6 - 3s - loss: 0.9561 - accuracy: 0.6796 - val_loss: 1.1202 - val_accuracy: 0.6279 - 3s/epoch - 448ms/step\n",
      "Epoch 141/250\n",
      "6/6 - 3s - loss: 0.9244 - accuracy: 0.7068 - val_loss: 1.1546 - val_accuracy: 0.6047 - 3s/epoch - 448ms/step\n",
      "Epoch 142/250\n",
      "6/6 - 3s - loss: 0.9398 - accuracy: 0.6786 - val_loss: 1.1431 - val_accuracy: 0.6163 - 3s/epoch - 451ms/step\n",
      "Epoch 143/250\n",
      "6/6 - 3s - loss: 0.9432 - accuracy: 0.6874 - val_loss: 1.1297 - val_accuracy: 0.6124 - 3s/epoch - 553ms/step\n",
      "Epoch 144/250\n",
      "6/6 - 3s - loss: 0.9290 - accuracy: 0.6922 - val_loss: 1.1315 - val_accuracy: 0.6163 - 3s/epoch - 516ms/step\n",
      "Epoch 145/250\n",
      "6/6 - 3s - loss: 0.9066 - accuracy: 0.7097 - val_loss: 1.1569 - val_accuracy: 0.5969 - 3s/epoch - 452ms/step\n",
      "Epoch 146/250\n",
      "6/6 - 3s - loss: 0.9166 - accuracy: 0.7019 - val_loss: 1.1177 - val_accuracy: 0.6124 - 3s/epoch - 447ms/step\n",
      "Epoch 147/250\n",
      "6/6 - 3s - loss: 0.9077 - accuracy: 0.7126 - val_loss: 1.1023 - val_accuracy: 0.6512 - 3s/epoch - 512ms/step\n",
      "Epoch 148/250\n",
      "6/6 - 3s - loss: 0.9016 - accuracy: 0.7097 - val_loss: 1.1077 - val_accuracy: 0.6395 - 3s/epoch - 520ms/step\n",
      "Epoch 149/250\n",
      "6/6 - 3s - loss: 0.8924 - accuracy: 0.7097 - val_loss: 1.1050 - val_accuracy: 0.6202 - 3s/epoch - 453ms/step\n",
      "Epoch 150/250\n",
      "6/6 - 3s - loss: 0.8810 - accuracy: 0.7058 - val_loss: 1.0902 - val_accuracy: 0.6434 - 3s/epoch - 452ms/step\n",
      "Epoch 151/250\n",
      "6/6 - 3s - loss: 0.8831 - accuracy: 0.7117 - val_loss: 1.0841 - val_accuracy: 0.6589 - 3s/epoch - 452ms/step\n",
      "Epoch 152/250\n",
      "6/6 - 4s - loss: 0.8706 - accuracy: 0.7223 - val_loss: 1.0855 - val_accuracy: 0.6357 - 4s/epoch - 589ms/step\n",
      "Epoch 153/250\n",
      "6/6 - 3s - loss: 0.8633 - accuracy: 0.7184 - val_loss: 1.1068 - val_accuracy: 0.6279 - 3s/epoch - 455ms/step\n",
      "Epoch 154/250\n",
      "6/6 - 3s - loss: 0.8952 - accuracy: 0.7049 - val_loss: 1.1283 - val_accuracy: 0.6202 - 3s/epoch - 456ms/step\n",
      "Epoch 155/250\n",
      "6/6 - 3s - loss: 0.8845 - accuracy: 0.7029 - val_loss: 1.0555 - val_accuracy: 0.6589 - 3s/epoch - 451ms/step\n",
      "Epoch 156/250\n",
      "6/6 - 4s - loss: 0.8703 - accuracy: 0.7214 - val_loss: 1.0692 - val_accuracy: 0.6589 - 4s/epoch - 590ms/step\n",
      "Epoch 157/250\n",
      "6/6 - 3s - loss: 0.9184 - accuracy: 0.6981 - val_loss: 1.1967 - val_accuracy: 0.5930 - 3s/epoch - 451ms/step\n",
      "Epoch 158/250\n",
      "6/6 - 3s - loss: 0.9012 - accuracy: 0.6951 - val_loss: 1.1431 - val_accuracy: 0.6163 - 3s/epoch - 456ms/step\n",
      "Epoch 159/250\n",
      "6/6 - 3s - loss: 0.8740 - accuracy: 0.7155 - val_loss: 1.0870 - val_accuracy: 0.6085 - 3s/epoch - 448ms/step\n",
      "Epoch 160/250\n",
      "6/6 - 4s - loss: 0.8635 - accuracy: 0.7175 - val_loss: 1.0844 - val_accuracy: 0.6512 - 4s/epoch - 596ms/step\n",
      "Epoch 161/250\n",
      "6/6 - 3s - loss: 0.8587 - accuracy: 0.7087 - val_loss: 1.0341 - val_accuracy: 0.6628 - 3s/epoch - 454ms/step\n",
      "Epoch 162/250\n",
      "6/6 - 3s - loss: 0.8548 - accuracy: 0.7117 - val_loss: 1.0538 - val_accuracy: 0.6783 - 3s/epoch - 455ms/step\n",
      "Epoch 163/250\n",
      "6/6 - 3s - loss: 0.8368 - accuracy: 0.7398 - val_loss: 1.0696 - val_accuracy: 0.6589 - 3s/epoch - 457ms/step\n",
      "Epoch 164/250\n",
      "6/6 - 4s - loss: 0.8413 - accuracy: 0.7272 - val_loss: 1.0729 - val_accuracy: 0.6550 - 4s/epoch - 596ms/step\n",
      "Epoch 165/250\n",
      "6/6 - 3s - loss: 0.8627 - accuracy: 0.7087 - val_loss: 1.0286 - val_accuracy: 0.6822 - 3s/epoch - 455ms/step\n",
      "Epoch 166/250\n",
      "6/6 - 3s - loss: 0.8539 - accuracy: 0.7262 - val_loss: 1.0622 - val_accuracy: 0.6667 - 3s/epoch - 477ms/step\n",
      "Epoch 167/250\n",
      "6/6 - 3s - loss: 0.8333 - accuracy: 0.7233 - val_loss: 1.0432 - val_accuracy: 0.6860 - 3s/epoch - 456ms/step\n",
      "Epoch 168/250\n",
      "6/6 - 4s - loss: 0.8422 - accuracy: 0.7136 - val_loss: 1.0110 - val_accuracy: 0.6860 - 4s/epoch - 591ms/step\n",
      "Epoch 169/250\n",
      "6/6 - 3s - loss: 0.8199 - accuracy: 0.7301 - val_loss: 1.0320 - val_accuracy: 0.6667 - 3s/epoch - 450ms/step\n",
      "Epoch 170/250\n",
      "6/6 - 3s - loss: 0.7969 - accuracy: 0.7466 - val_loss: 1.0257 - val_accuracy: 0.7016 - 3s/epoch - 458ms/step\n",
      "Epoch 171/250\n",
      "6/6 - 3s - loss: 0.8156 - accuracy: 0.7340 - val_loss: 1.0264 - val_accuracy: 0.6705 - 3s/epoch - 457ms/step\n",
      "Epoch 172/250\n",
      "6/6 - 4s - loss: 0.8004 - accuracy: 0.7340 - val_loss: 1.0204 - val_accuracy: 0.6705 - 4s/epoch - 592ms/step\n",
      "Epoch 173/250\n",
      "6/6 - 3s - loss: 0.7865 - accuracy: 0.7330 - val_loss: 1.0136 - val_accuracy: 0.6899 - 3s/epoch - 460ms/step\n",
      "Epoch 174/250\n",
      "6/6 - 3s - loss: 0.8099 - accuracy: 0.7262 - val_loss: 1.0612 - val_accuracy: 0.6357 - 3s/epoch - 455ms/step\n",
      "Epoch 175/250\n",
      "6/6 - 3s - loss: 0.7925 - accuracy: 0.7437 - val_loss: 0.9951 - val_accuracy: 0.6899 - 3s/epoch - 449ms/step\n",
      "Epoch 176/250\n",
      "6/6 - 3s - loss: 0.7730 - accuracy: 0.7408 - val_loss: 0.9881 - val_accuracy: 0.6822 - 3s/epoch - 574ms/step\n",
      "Epoch 177/250\n",
      "6/6 - 3s - loss: 0.7807 - accuracy: 0.7388 - val_loss: 1.0083 - val_accuracy: 0.6783 - 3s/epoch - 482ms/step\n",
      "Epoch 178/250\n",
      "6/6 - 3s - loss: 0.7740 - accuracy: 0.7524 - val_loss: 1.0093 - val_accuracy: 0.6628 - 3s/epoch - 453ms/step\n",
      "Epoch 179/250\n",
      "6/6 - 3s - loss: 0.7647 - accuracy: 0.7340 - val_loss: 1.0111 - val_accuracy: 0.6783 - 3s/epoch - 457ms/step\n",
      "Epoch 180/250\n",
      "6/6 - 3s - loss: 0.7591 - accuracy: 0.7602 - val_loss: 1.0069 - val_accuracy: 0.6977 - 3s/epoch - 507ms/step\n",
      "Epoch 181/250\n",
      "6/6 - 3s - loss: 0.7470 - accuracy: 0.7602 - val_loss: 1.0003 - val_accuracy: 0.6744 - 3s/epoch - 543ms/step\n",
      "Epoch 182/250\n",
      "6/6 - 3s - loss: 0.7454 - accuracy: 0.7621 - val_loss: 0.9934 - val_accuracy: 0.7016 - 3s/epoch - 447ms/step\n",
      "Epoch 183/250\n",
      "6/6 - 3s - loss: 0.7455 - accuracy: 0.7495 - val_loss: 1.0024 - val_accuracy: 0.6899 - 3s/epoch - 455ms/step\n",
      "Epoch 184/250\n",
      "6/6 - 3s - loss: 0.7363 - accuracy: 0.7650 - val_loss: 0.9910 - val_accuracy: 0.6899 - 3s/epoch - 457ms/step\n",
      "Epoch 185/250\n",
      "6/6 - 3s - loss: 0.7383 - accuracy: 0.7485 - val_loss: 0.9810 - val_accuracy: 0.7132 - 3s/epoch - 581ms/step\n",
      "Epoch 186/250\n",
      "6/6 - 3s - loss: 0.7210 - accuracy: 0.7573 - val_loss: 0.9660 - val_accuracy: 0.6860 - 3s/epoch - 456ms/step\n",
      "Epoch 187/250\n",
      "6/6 - 3s - loss: 0.7312 - accuracy: 0.7485 - val_loss: 1.0217 - val_accuracy: 0.6822 - 3s/epoch - 453ms/step\n",
      "Epoch 188/250\n",
      "6/6 - 3s - loss: 0.7516 - accuracy: 0.7524 - val_loss: 0.9725 - val_accuracy: 0.6938 - 3s/epoch - 454ms/step\n",
      "Epoch 189/250\n",
      "6/6 - 4s - loss: 0.7332 - accuracy: 0.7515 - val_loss: 0.9699 - val_accuracy: 0.6938 - 4s/epoch - 589ms/step\n",
      "Epoch 190/250\n",
      "6/6 - 3s - loss: 0.7158 - accuracy: 0.7689 - val_loss: 1.0009 - val_accuracy: 0.6899 - 3s/epoch - 450ms/step\n",
      "Epoch 191/250\n",
      "6/6 - 3s - loss: 0.7113 - accuracy: 0.7689 - val_loss: 0.9710 - val_accuracy: 0.6744 - 3s/epoch - 447ms/step\n",
      "Epoch 192/250\n",
      "6/6 - 3s - loss: 0.7086 - accuracy: 0.7573 - val_loss: 0.9794 - val_accuracy: 0.6822 - 3s/epoch - 456ms/step\n",
      "Epoch 193/250\n",
      "6/6 - 4s - loss: 0.6820 - accuracy: 0.7806 - val_loss: 0.9578 - val_accuracy: 0.7054 - 4s/epoch - 592ms/step\n",
      "Epoch 194/250\n",
      "6/6 - 3s - loss: 0.6929 - accuracy: 0.7748 - val_loss: 0.9601 - val_accuracy: 0.7054 - 3s/epoch - 450ms/step\n",
      "Epoch 195/250\n",
      "6/6 - 3s - loss: 0.6945 - accuracy: 0.7631 - val_loss: 0.9495 - val_accuracy: 0.7093 - 3s/epoch - 456ms/step\n",
      "Epoch 196/250\n",
      "6/6 - 3s - loss: 0.6765 - accuracy: 0.7786 - val_loss: 0.9576 - val_accuracy: 0.7093 - 3s/epoch - 452ms/step\n",
      "Epoch 197/250\n",
      "6/6 - 4s - loss: 0.6731 - accuracy: 0.7709 - val_loss: 0.9568 - val_accuracy: 0.6783 - 4s/epoch - 598ms/step\n",
      "Epoch 198/250\n",
      "6/6 - 3s - loss: 0.6831 - accuracy: 0.7786 - val_loss: 0.9533 - val_accuracy: 0.6822 - 3s/epoch - 451ms/step\n",
      "Epoch 199/250\n",
      "6/6 - 3s - loss: 0.6755 - accuracy: 0.7718 - val_loss: 0.9509 - val_accuracy: 0.6938 - 3s/epoch - 456ms/step\n",
      "Epoch 200/250\n",
      "6/6 - 3s - loss: 0.6590 - accuracy: 0.7767 - val_loss: 0.9506 - val_accuracy: 0.6860 - 3s/epoch - 455ms/step\n",
      "Epoch 201/250\n",
      "6/6 - 3s - loss: 0.6653 - accuracy: 0.7796 - val_loss: 0.9436 - val_accuracy: 0.7093 - 3s/epoch - 582ms/step\n",
      "Epoch 202/250\n",
      "6/6 - 3s - loss: 0.6500 - accuracy: 0.7728 - val_loss: 0.9338 - val_accuracy: 0.7054 - 3s/epoch - 463ms/step\n",
      "Epoch 203/250\n",
      "6/6 - 3s - loss: 0.6384 - accuracy: 0.7883 - val_loss: 0.9474 - val_accuracy: 0.7171 - 3s/epoch - 456ms/step\n",
      "Epoch 204/250\n",
      "6/6 - 3s - loss: 0.6441 - accuracy: 0.7864 - val_loss: 0.9422 - val_accuracy: 0.7171 - 3s/epoch - 478ms/step\n",
      "Epoch 205/250\n",
      "6/6 - 3s - loss: 0.6406 - accuracy: 0.7951 - val_loss: 0.9294 - val_accuracy: 0.6977 - 3s/epoch - 576ms/step\n",
      "Epoch 206/250\n",
      "6/6 - 3s - loss: 0.6246 - accuracy: 0.7981 - val_loss: 0.9339 - val_accuracy: 0.7171 - 3s/epoch - 497ms/step\n",
      "Epoch 207/250\n",
      "6/6 - 3s - loss: 0.6437 - accuracy: 0.7854 - val_loss: 0.9284 - val_accuracy: 0.7093 - 3s/epoch - 455ms/step\n",
      "Epoch 208/250\n",
      "6/6 - 3s - loss: 0.6274 - accuracy: 0.7874 - val_loss: 0.9476 - val_accuracy: 0.6899 - 3s/epoch - 452ms/step\n",
      "Epoch 209/250\n",
      "6/6 - 3s - loss: 0.6286 - accuracy: 0.7913 - val_loss: 0.9132 - val_accuracy: 0.7093 - 3s/epoch - 546ms/step\n",
      "Epoch 210/250\n",
      "6/6 - 3s - loss: 0.6161 - accuracy: 0.8019 - val_loss: 0.9384 - val_accuracy: 0.6938 - 3s/epoch - 490ms/step\n",
      "Epoch 211/250\n",
      "6/6 - 3s - loss: 0.6249 - accuracy: 0.7874 - val_loss: 0.9182 - val_accuracy: 0.7054 - 3s/epoch - 451ms/step\n",
      "Epoch 212/250\n",
      "6/6 - 3s - loss: 0.6054 - accuracy: 0.8107 - val_loss: 0.9229 - val_accuracy: 0.6977 - 3s/epoch - 460ms/step\n",
      "Epoch 213/250\n",
      "6/6 - 3s - loss: 0.6145 - accuracy: 0.7922 - val_loss: 0.9036 - val_accuracy: 0.7171 - 3s/epoch - 500ms/step\n",
      "Epoch 214/250\n",
      "6/6 - 3s - loss: 0.6094 - accuracy: 0.8010 - val_loss: 0.9245 - val_accuracy: 0.7093 - 3s/epoch - 548ms/step\n",
      "Epoch 215/250\n",
      "6/6 - 3s - loss: 0.5921 - accuracy: 0.7951 - val_loss: 0.9324 - val_accuracy: 0.7093 - 3s/epoch - 459ms/step\n",
      "Epoch 216/250\n",
      "6/6 - 3s - loss: 0.5943 - accuracy: 0.8000 - val_loss: 0.9019 - val_accuracy: 0.7132 - 3s/epoch - 461ms/step\n",
      "Epoch 217/250\n",
      "6/6 - 3s - loss: 0.5733 - accuracy: 0.8107 - val_loss: 0.9566 - val_accuracy: 0.7054 - 3s/epoch - 487ms/step\n",
      "Epoch 218/250\n",
      "6/6 - 3s - loss: 0.5778 - accuracy: 0.7961 - val_loss: 0.9340 - val_accuracy: 0.7132 - 3s/epoch - 568ms/step\n",
      "Epoch 219/250\n",
      "6/6 - 3s - loss: 0.5849 - accuracy: 0.8029 - val_loss: 0.9015 - val_accuracy: 0.7403 - 3s/epoch - 483ms/step\n",
      "Epoch 220/250\n",
      "6/6 - 3s - loss: 0.5826 - accuracy: 0.8078 - val_loss: 0.9228 - val_accuracy: 0.7132 - 3s/epoch - 458ms/step\n",
      "Epoch 221/250\n",
      "6/6 - 3s - loss: 0.5803 - accuracy: 0.8214 - val_loss: 0.9063 - val_accuracy: 0.7248 - 3s/epoch - 460ms/step\n",
      "Epoch 222/250\n",
      "6/6 - 4s - loss: 0.5581 - accuracy: 0.8165 - val_loss: 0.9262 - val_accuracy: 0.7209 - 4s/epoch - 589ms/step\n",
      "Epoch 223/250\n",
      "6/6 - 3s - loss: 0.5655 - accuracy: 0.8126 - val_loss: 0.8852 - val_accuracy: 0.7093 - 3s/epoch - 452ms/step\n",
      "Epoch 224/250\n",
      "6/6 - 3s - loss: 0.5652 - accuracy: 0.8291 - val_loss: 0.9031 - val_accuracy: 0.7054 - 3s/epoch - 465ms/step\n",
      "Epoch 225/250\n",
      "6/6 - 3s - loss: 0.5496 - accuracy: 0.8214 - val_loss: 0.8935 - val_accuracy: 0.7326 - 3s/epoch - 449ms/step\n",
      "Epoch 226/250\n",
      "6/6 - 4s - loss: 0.5536 - accuracy: 0.8223 - val_loss: 0.9080 - val_accuracy: 0.7209 - 4s/epoch - 587ms/step\n",
      "Epoch 227/250\n",
      "6/6 - 3s - loss: 0.5523 - accuracy: 0.8087 - val_loss: 0.9028 - val_accuracy: 0.7209 - 3s/epoch - 456ms/step\n",
      "Epoch 228/250\n",
      "6/6 - 3s - loss: 0.5404 - accuracy: 0.8214 - val_loss: 0.8803 - val_accuracy: 0.7364 - 3s/epoch - 453ms/step\n",
      "Epoch 229/250\n",
      "6/6 - 3s - loss: 0.5202 - accuracy: 0.8340 - val_loss: 0.8963 - val_accuracy: 0.7093 - 3s/epoch - 455ms/step\n",
      "Epoch 230/250\n",
      "6/6 - 4s - loss: 0.5294 - accuracy: 0.8194 - val_loss: 0.8799 - val_accuracy: 0.7287 - 4s/epoch - 593ms/step\n",
      "Epoch 231/250\n",
      "6/6 - 3s - loss: 0.5248 - accuracy: 0.8194 - val_loss: 0.8859 - val_accuracy: 0.7442 - 3s/epoch - 462ms/step\n",
      "Epoch 232/250\n",
      "6/6 - 3s - loss: 0.5137 - accuracy: 0.8252 - val_loss: 0.8979 - val_accuracy: 0.7171 - 3s/epoch - 454ms/step\n",
      "Epoch 233/250\n",
      "6/6 - 3s - loss: 0.5286 - accuracy: 0.8252 - val_loss: 0.8935 - val_accuracy: 0.7364 - 3s/epoch - 449ms/step\n",
      "Epoch 234/250\n",
      "6/6 - 4s - loss: 0.5142 - accuracy: 0.8369 - val_loss: 0.8824 - val_accuracy: 0.7403 - 4s/epoch - 589ms/step\n",
      "Epoch 235/250\n",
      "6/6 - 3s - loss: 0.5016 - accuracy: 0.8437 - val_loss: 0.9117 - val_accuracy: 0.7171 - 3s/epoch - 455ms/step\n",
      "Epoch 236/250\n",
      "6/6 - 3s - loss: 0.5075 - accuracy: 0.8301 - val_loss: 0.8946 - val_accuracy: 0.7287 - 3s/epoch - 451ms/step\n",
      "Epoch 237/250\n",
      "6/6 - 3s - loss: 0.5132 - accuracy: 0.8204 - val_loss: 0.8852 - val_accuracy: 0.7326 - 3s/epoch - 447ms/step\n",
      "Epoch 238/250\n",
      "6/6 - 3s - loss: 0.5107 - accuracy: 0.8359 - val_loss: 0.8600 - val_accuracy: 0.7326 - 3s/epoch - 583ms/step\n",
      "Epoch 239/250\n",
      "6/6 - 3s - loss: 0.4970 - accuracy: 0.8379 - val_loss: 0.8837 - val_accuracy: 0.7171 - 3s/epoch - 463ms/step\n",
      "Epoch 240/250\n",
      "6/6 - 3s - loss: 0.4983 - accuracy: 0.8398 - val_loss: 0.8880 - val_accuracy: 0.7364 - 3s/epoch - 455ms/step\n",
      "Epoch 241/250\n",
      "6/6 - 3s - loss: 0.5019 - accuracy: 0.8272 - val_loss: 0.8918 - val_accuracy: 0.7132 - 3s/epoch - 476ms/step\n",
      "Epoch 242/250\n",
      "6/6 - 3s - loss: 0.4873 - accuracy: 0.8456 - val_loss: 0.9004 - val_accuracy: 0.7287 - 3s/epoch - 580ms/step\n",
      "Epoch 243/250\n",
      "6/6 - 3s - loss: 0.5003 - accuracy: 0.8359 - val_loss: 0.9137 - val_accuracy: 0.7093 - 3s/epoch - 465ms/step\n",
      "Epoch 244/250\n",
      "6/6 - 3s - loss: 0.5032 - accuracy: 0.8388 - val_loss: 0.8729 - val_accuracy: 0.7248 - 3s/epoch - 454ms/step\n",
      "Epoch 245/250\n",
      "6/6 - 3s - loss: 0.4752 - accuracy: 0.8476 - val_loss: 0.8677 - val_accuracy: 0.7519 - 3s/epoch - 457ms/step\n",
      "Epoch 246/250\n",
      "6/6 - 3s - loss: 0.4662 - accuracy: 0.8534 - val_loss: 0.8696 - val_accuracy: 0.7364 - 3s/epoch - 518ms/step\n",
      "Epoch 247/250\n",
      "6/6 - 3s - loss: 0.4654 - accuracy: 0.8340 - val_loss: 0.8501 - val_accuracy: 0.7171 - 3s/epoch - 521ms/step\n",
      "Epoch 248/250\n",
      "6/6 - 3s - loss: 0.4568 - accuracy: 0.8553 - val_loss: 0.8533 - val_accuracy: 0.7364 - 3s/epoch - 453ms/step\n",
      "Epoch 249/250\n",
      "6/6 - 3s - loss: 0.4658 - accuracy: 0.8417 - val_loss: 0.8677 - val_accuracy: 0.7403 - 3s/epoch - 452ms/step\n",
      "Epoch 250/250\n",
      "6/6 - 3s - loss: 0.4682 - accuracy: 0.8437 - val_loss: 0.8687 - val_accuracy: 0.7209 - 3s/epoch - 472ms/step\n",
      "9/9 [==============================] - 0s 22ms/step\n",
      "Epoch 1/250\n",
      "6/6 - 2s - loss: 1.8966 - accuracy: 0.3495 - val_loss: 1.7863 - val_accuracy: 0.3876 - 2s/epoch - 415ms/step\n",
      "Epoch 2/250\n",
      "6/6 - 2s - loss: 1.7306 - accuracy: 0.4175 - val_loss: 1.7398 - val_accuracy: 0.3876 - 2s/epoch - 329ms/step\n",
      "Epoch 3/250\n",
      "6/6 - 2s - loss: 1.6785 - accuracy: 0.4175 - val_loss: 1.7580 - val_accuracy: 0.3876 - 2s/epoch - 378ms/step\n",
      "Epoch 4/250\n",
      "6/6 - 2s - loss: 1.6746 - accuracy: 0.4175 - val_loss: 1.7562 - val_accuracy: 0.3876 - 2s/epoch - 283ms/step\n",
      "Epoch 5/250\n",
      "6/6 - 2s - loss: 1.6732 - accuracy: 0.4175 - val_loss: 1.7355 - val_accuracy: 0.3876 - 2s/epoch - 280ms/step\n",
      "Epoch 6/250\n",
      "6/6 - 2s - loss: 1.6740 - accuracy: 0.4175 - val_loss: 1.7401 - val_accuracy: 0.3876 - 2s/epoch - 292ms/step\n",
      "Epoch 7/250\n",
      "6/6 - 2s - loss: 1.6705 - accuracy: 0.4175 - val_loss: 1.7426 - val_accuracy: 0.3876 - 2s/epoch - 285ms/step\n",
      "Epoch 8/250\n",
      "6/6 - 2s - loss: 1.6705 - accuracy: 0.4175 - val_loss: 1.7382 - val_accuracy: 0.3876 - 2s/epoch - 282ms/step\n",
      "Epoch 9/250\n",
      "6/6 - 3s - loss: 1.6737 - accuracy: 0.4175 - val_loss: 1.7389 - val_accuracy: 0.3876 - 3s/epoch - 420ms/step\n",
      "Epoch 10/250\n",
      "6/6 - 2s - loss: 1.6721 - accuracy: 0.4175 - val_loss: 1.7418 - val_accuracy: 0.3876 - 2s/epoch - 285ms/step\n",
      "Epoch 11/250\n",
      "6/6 - 2s - loss: 1.6692 - accuracy: 0.4175 - val_loss: 1.7353 - val_accuracy: 0.3876 - 2s/epoch - 279ms/step\n",
      "Epoch 12/250\n",
      "6/6 - 2s - loss: 1.6710 - accuracy: 0.4175 - val_loss: 1.7339 - val_accuracy: 0.3876 - 2s/epoch - 287ms/step\n",
      "Epoch 13/250\n",
      "6/6 - 2s - loss: 1.6687 - accuracy: 0.4175 - val_loss: 1.7365 - val_accuracy: 0.3876 - 2s/epoch - 277ms/step\n",
      "Epoch 14/250\n",
      "6/6 - 2s - loss: 1.6698 - accuracy: 0.4175 - val_loss: 1.7375 - val_accuracy: 0.3876 - 2s/epoch - 276ms/step\n",
      "Epoch 15/250\n",
      "6/6 - 2s - loss: 1.6694 - accuracy: 0.4175 - val_loss: 1.7365 - val_accuracy: 0.3876 - 2s/epoch - 288ms/step\n",
      "Epoch 16/250\n",
      "6/6 - 3s - loss: 1.6700 - accuracy: 0.4175 - val_loss: 1.7338 - val_accuracy: 0.3876 - 3s/epoch - 424ms/step\n",
      "Epoch 17/250\n",
      "6/6 - 2s - loss: 1.6737 - accuracy: 0.4175 - val_loss: 1.7302 - val_accuracy: 0.3876 - 2s/epoch - 273ms/step\n",
      "Epoch 18/250\n",
      "6/6 - 2s - loss: 1.6808 - accuracy: 0.4175 - val_loss: 1.7339 - val_accuracy: 0.3876 - 2s/epoch - 287ms/step\n",
      "Epoch 19/250\n",
      "6/6 - 2s - loss: 1.6726 - accuracy: 0.4175 - val_loss: 1.7375 - val_accuracy: 0.3876 - 2s/epoch - 276ms/step\n",
      "Epoch 20/250\n",
      "6/6 - 2s - loss: 1.6763 - accuracy: 0.4175 - val_loss: 1.7346 - val_accuracy: 0.3876 - 2s/epoch - 289ms/step\n",
      "Epoch 21/250\n",
      "6/6 - 2s - loss: 1.6724 - accuracy: 0.4175 - val_loss: 1.7437 - val_accuracy: 0.3876 - 2s/epoch - 281ms/step\n",
      "Epoch 22/250\n",
      "6/6 - 2s - loss: 1.6709 - accuracy: 0.4175 - val_loss: 1.7388 - val_accuracy: 0.3876 - 2s/epoch - 357ms/step\n",
      "Epoch 23/250\n",
      "6/6 - 2s - loss: 1.6701 - accuracy: 0.4175 - val_loss: 1.7427 - val_accuracy: 0.3876 - 2s/epoch - 348ms/step\n",
      "Epoch 24/250\n",
      "6/6 - 2s - loss: 1.6700 - accuracy: 0.4175 - val_loss: 1.7363 - val_accuracy: 0.3876 - 2s/epoch - 287ms/step\n",
      "Epoch 25/250\n",
      "6/6 - 2s - loss: 1.6705 - accuracy: 0.4175 - val_loss: 1.7341 - val_accuracy: 0.3876 - 2s/epoch - 276ms/step\n",
      "Epoch 26/250\n",
      "6/6 - 2s - loss: 1.6714 - accuracy: 0.4175 - val_loss: 1.7439 - val_accuracy: 0.3876 - 2s/epoch - 277ms/step\n",
      "Epoch 27/250\n",
      "6/6 - 2s - loss: 1.6724 - accuracy: 0.4175 - val_loss: 1.7331 - val_accuracy: 0.3876 - 2s/epoch - 283ms/step\n",
      "Epoch 28/250\n",
      "6/6 - 2s - loss: 1.6712 - accuracy: 0.4175 - val_loss: 1.7325 - val_accuracy: 0.3876 - 2s/epoch - 272ms/step\n",
      "Epoch 29/250\n",
      "6/6 - 2s - loss: 1.6703 - accuracy: 0.4175 - val_loss: 1.7321 - val_accuracy: 0.3876 - 2s/epoch - 415ms/step\n",
      "Epoch 30/250\n",
      "6/6 - 2s - loss: 1.6693 - accuracy: 0.4175 - val_loss: 1.7371 - val_accuracy: 0.3876 - 2s/epoch - 275ms/step\n",
      "Epoch 31/250\n",
      "6/6 - 2s - loss: 1.6700 - accuracy: 0.4175 - val_loss: 1.7361 - val_accuracy: 0.3876 - 2s/epoch - 271ms/step\n",
      "Epoch 32/250\n",
      "6/6 - 2s - loss: 1.6669 - accuracy: 0.4175 - val_loss: 1.7416 - val_accuracy: 0.3876 - 2s/epoch - 288ms/step\n",
      "Epoch 33/250\n",
      "6/6 - 2s - loss: 1.6727 - accuracy: 0.4175 - val_loss: 1.7301 - val_accuracy: 0.3876 - 2s/epoch - 277ms/step\n",
      "Epoch 34/250\n",
      "6/6 - 2s - loss: 1.6672 - accuracy: 0.4175 - val_loss: 1.7381 - val_accuracy: 0.3876 - 2s/epoch - 279ms/step\n",
      "Epoch 35/250\n",
      "6/6 - 2s - loss: 1.6663 - accuracy: 0.4175 - val_loss: 1.7291 - val_accuracy: 0.3876 - 2s/epoch - 279ms/step\n",
      "Epoch 36/250\n",
      "6/6 - 2s - loss: 1.6703 - accuracy: 0.4175 - val_loss: 1.7240 - val_accuracy: 0.3876 - 2s/epoch - 412ms/step\n",
      "Epoch 37/250\n",
      "6/6 - 2s - loss: 1.6670 - accuracy: 0.4175 - val_loss: 1.7501 - val_accuracy: 0.3876 - 2s/epoch - 274ms/step\n",
      "Epoch 38/250\n",
      "6/6 - 2s - loss: 1.6712 - accuracy: 0.4175 - val_loss: 1.7323 - val_accuracy: 0.3876 - 2s/epoch - 286ms/step\n",
      "Epoch 39/250\n",
      "6/6 - 2s - loss: 1.6681 - accuracy: 0.4175 - val_loss: 1.7309 - val_accuracy: 0.3876 - 2s/epoch - 277ms/step\n",
      "Epoch 40/250\n",
      "6/6 - 2s - loss: 1.6679 - accuracy: 0.4175 - val_loss: 1.7352 - val_accuracy: 0.3876 - 2s/epoch - 281ms/step\n",
      "Epoch 41/250\n",
      "6/6 - 2s - loss: 1.6615 - accuracy: 0.4175 - val_loss: 1.7322 - val_accuracy: 0.3876 - 2s/epoch - 275ms/step\n",
      "Epoch 42/250\n",
      "6/6 - 2s - loss: 1.6626 - accuracy: 0.4175 - val_loss: 1.7301 - val_accuracy: 0.3876 - 2s/epoch - 322ms/step\n",
      "Epoch 43/250\n",
      "6/6 - 2s - loss: 1.6616 - accuracy: 0.4175 - val_loss: 1.7244 - val_accuracy: 0.3876 - 2s/epoch - 369ms/step\n",
      "Epoch 44/250\n",
      "6/6 - 2s - loss: 1.6590 - accuracy: 0.4175 - val_loss: 1.7144 - val_accuracy: 0.3876 - 2s/epoch - 279ms/step\n",
      "Epoch 45/250\n",
      "6/6 - 2s - loss: 1.6550 - accuracy: 0.4175 - val_loss: 1.7329 - val_accuracy: 0.3876 - 2s/epoch - 280ms/step\n",
      "Epoch 46/250\n",
      "6/6 - 2s - loss: 1.6613 - accuracy: 0.4175 - val_loss: 1.7263 - val_accuracy: 0.3876 - 2s/epoch - 283ms/step\n",
      "Epoch 47/250\n",
      "6/6 - 2s - loss: 1.6475 - accuracy: 0.4175 - val_loss: 1.7360 - val_accuracy: 0.3876 - 2s/epoch - 271ms/step\n",
      "Epoch 48/250\n",
      "6/6 - 2s - loss: 1.6715 - accuracy: 0.4175 - val_loss: 1.7124 - val_accuracy: 0.3876 - 2s/epoch - 277ms/step\n",
      "Epoch 49/250\n",
      "6/6 - 2s - loss: 1.6477 - accuracy: 0.4175 - val_loss: 1.7182 - val_accuracy: 0.3876 - 2s/epoch - 416ms/step\n",
      "Epoch 50/250\n",
      "6/6 - 2s - loss: 1.6401 - accuracy: 0.4175 - val_loss: 1.7052 - val_accuracy: 0.3876 - 2s/epoch - 285ms/step\n",
      "Epoch 51/250\n",
      "6/6 - 2s - loss: 1.6325 - accuracy: 0.4175 - val_loss: 1.6998 - val_accuracy: 0.3876 - 2s/epoch - 274ms/step\n",
      "Epoch 52/250\n",
      "6/6 - 2s - loss: 1.6233 - accuracy: 0.4175 - val_loss: 1.7100 - val_accuracy: 0.3876 - 2s/epoch - 271ms/step\n",
      "Epoch 53/250\n",
      "6/6 - 2s - loss: 1.6210 - accuracy: 0.4175 - val_loss: 1.6935 - val_accuracy: 0.3876 - 2s/epoch - 278ms/step\n",
      "Epoch 54/250\n",
      "6/6 - 2s - loss: 1.6139 - accuracy: 0.4175 - val_loss: 1.6816 - val_accuracy: 0.3876 - 2s/epoch - 274ms/step\n",
      "Epoch 55/250\n",
      "6/6 - 2s - loss: 1.5995 - accuracy: 0.4175 - val_loss: 1.6769 - val_accuracy: 0.3876 - 2s/epoch - 287ms/step\n",
      "Epoch 56/250\n",
      "6/6 - 3s - loss: 1.5959 - accuracy: 0.4175 - val_loss: 1.6784 - val_accuracy: 0.3915 - 3s/epoch - 419ms/step\n",
      "Epoch 57/250\n",
      "6/6 - 2s - loss: 1.5842 - accuracy: 0.4262 - val_loss: 1.6560 - val_accuracy: 0.3876 - 2s/epoch - 278ms/step\n",
      "Epoch 58/250\n",
      "6/6 - 2s - loss: 1.5789 - accuracy: 0.4243 - val_loss: 1.6682 - val_accuracy: 0.3992 - 2s/epoch - 276ms/step\n",
      "Epoch 59/250\n",
      "6/6 - 2s - loss: 1.5612 - accuracy: 0.4350 - val_loss: 1.6343 - val_accuracy: 0.3915 - 2s/epoch - 273ms/step\n",
      "Epoch 60/250\n",
      "6/6 - 2s - loss: 1.5489 - accuracy: 0.4485 - val_loss: 1.6298 - val_accuracy: 0.4147 - 2s/epoch - 287ms/step\n",
      "Epoch 61/250\n",
      "6/6 - 2s - loss: 1.5263 - accuracy: 0.4544 - val_loss: 1.6238 - val_accuracy: 0.4457 - 2s/epoch - 276ms/step\n",
      "Epoch 62/250\n",
      "6/6 - 2s - loss: 1.5204 - accuracy: 0.4553 - val_loss: 1.6125 - val_accuracy: 0.4225 - 2s/epoch - 305ms/step\n",
      "Epoch 63/250\n",
      "6/6 - 2s - loss: 1.4963 - accuracy: 0.4612 - val_loss: 1.5833 - val_accuracy: 0.4496 - 2s/epoch - 394ms/step\n",
      "Epoch 64/250\n",
      "6/6 - 2s - loss: 1.4729 - accuracy: 0.4689 - val_loss: 1.5923 - val_accuracy: 0.4457 - 2s/epoch - 286ms/step\n",
      "Epoch 65/250\n",
      "6/6 - 2s - loss: 1.4675 - accuracy: 0.4689 - val_loss: 1.5827 - val_accuracy: 0.4496 - 2s/epoch - 278ms/step\n",
      "Epoch 66/250\n",
      "6/6 - 2s - loss: 1.4694 - accuracy: 0.4767 - val_loss: 1.5570 - val_accuracy: 0.4535 - 2s/epoch - 285ms/step\n",
      "Epoch 67/250\n",
      "6/6 - 2s - loss: 1.4380 - accuracy: 0.4738 - val_loss: 1.5458 - val_accuracy: 0.4574 - 2s/epoch - 279ms/step\n",
      "Epoch 68/250\n",
      "6/6 - 2s - loss: 1.4142 - accuracy: 0.4825 - val_loss: 1.5294 - val_accuracy: 0.4535 - 2s/epoch - 275ms/step\n",
      "Epoch 69/250\n",
      "6/6 - 2s - loss: 1.4092 - accuracy: 0.4932 - val_loss: 1.5363 - val_accuracy: 0.4457 - 2s/epoch - 366ms/step\n",
      "Epoch 70/250\n",
      "6/6 - 2s - loss: 1.4115 - accuracy: 0.4883 - val_loss: 1.5236 - val_accuracy: 0.4729 - 2s/epoch - 330ms/step\n",
      "Epoch 71/250\n",
      "6/6 - 2s - loss: 1.3772 - accuracy: 0.5175 - val_loss: 1.5118 - val_accuracy: 0.4690 - 2s/epoch - 286ms/step\n",
      "Epoch 72/250\n",
      "6/6 - 2s - loss: 1.3699 - accuracy: 0.4971 - val_loss: 1.4760 - val_accuracy: 0.4729 - 2s/epoch - 284ms/step\n",
      "Epoch 73/250\n",
      "6/6 - 2s - loss: 1.3548 - accuracy: 0.5262 - val_loss: 1.4579 - val_accuracy: 0.4845 - 2s/epoch - 283ms/step\n",
      "Epoch 74/250\n",
      "6/6 - 2s - loss: 1.3381 - accuracy: 0.5175 - val_loss: 1.4574 - val_accuracy: 0.4961 - 2s/epoch - 279ms/step\n",
      "Epoch 75/250\n",
      "6/6 - 2s - loss: 1.3165 - accuracy: 0.5379 - val_loss: 1.4787 - val_accuracy: 0.4961 - 2s/epoch - 272ms/step\n",
      "Epoch 76/250\n",
      "6/6 - 3s - loss: 1.3369 - accuracy: 0.5301 - val_loss: 1.4454 - val_accuracy: 0.5039 - 3s/epoch - 423ms/step\n",
      "Epoch 77/250\n",
      "6/6 - 2s - loss: 1.2974 - accuracy: 0.5515 - val_loss: 1.4222 - val_accuracy: 0.5078 - 2s/epoch - 281ms/step\n",
      "Epoch 78/250\n",
      "6/6 - 2s - loss: 1.2952 - accuracy: 0.5485 - val_loss: 1.3848 - val_accuracy: 0.5388 - 2s/epoch - 282ms/step\n",
      "Epoch 79/250\n",
      "6/6 - 2s - loss: 1.2709 - accuracy: 0.5660 - val_loss: 1.3730 - val_accuracy: 0.5116 - 2s/epoch - 277ms/step\n",
      "Epoch 80/250\n",
      "6/6 - 2s - loss: 1.2483 - accuracy: 0.5728 - val_loss: 1.3624 - val_accuracy: 0.5233 - 2s/epoch - 274ms/step\n",
      "Epoch 81/250\n",
      "6/6 - 2s - loss: 1.2269 - accuracy: 0.5825 - val_loss: 1.3431 - val_accuracy: 0.5194 - 2s/epoch - 287ms/step\n",
      "Epoch 82/250\n",
      "6/6 - 2s - loss: 1.2069 - accuracy: 0.5757 - val_loss: 1.3210 - val_accuracy: 0.5465 - 2s/epoch - 325ms/step\n",
      "Epoch 83/250\n",
      "6/6 - 2s - loss: 1.1990 - accuracy: 0.5913 - val_loss: 1.3155 - val_accuracy: 0.5620 - 2s/epoch - 372ms/step\n",
      "Epoch 84/250\n",
      "6/6 - 2s - loss: 1.1696 - accuracy: 0.6165 - val_loss: 1.3136 - val_accuracy: 0.5465 - 2s/epoch - 277ms/step\n",
      "Epoch 85/250\n",
      "6/6 - 2s - loss: 1.1872 - accuracy: 0.5854 - val_loss: 1.2908 - val_accuracy: 0.5349 - 2s/epoch - 275ms/step\n",
      "Epoch 86/250\n",
      "6/6 - 2s - loss: 1.1503 - accuracy: 0.6146 - val_loss: 1.2843 - val_accuracy: 0.5426 - 2s/epoch - 277ms/step\n",
      "Epoch 87/250\n",
      "6/6 - 2s - loss: 1.1414 - accuracy: 0.6243 - val_loss: 1.2645 - val_accuracy: 0.5853 - 2s/epoch - 291ms/step\n",
      "Epoch 88/250\n",
      "6/6 - 2s - loss: 1.1229 - accuracy: 0.6223 - val_loss: 1.2717 - val_accuracy: 0.5349 - 2s/epoch - 290ms/step\n",
      "Epoch 89/250\n",
      "6/6 - 2s - loss: 1.0960 - accuracy: 0.6291 - val_loss: 1.2135 - val_accuracy: 0.5930 - 2s/epoch - 395ms/step\n",
      "Epoch 90/250\n",
      "6/6 - 2s - loss: 1.0884 - accuracy: 0.6262 - val_loss: 1.2081 - val_accuracy: 0.5891 - 2s/epoch - 308ms/step\n",
      "Epoch 91/250\n",
      "6/6 - 2s - loss: 1.0828 - accuracy: 0.6184 - val_loss: 1.2817 - val_accuracy: 0.5310 - 2s/epoch - 285ms/step\n",
      "Epoch 92/250\n",
      "6/6 - 2s - loss: 1.0816 - accuracy: 0.6252 - val_loss: 1.1809 - val_accuracy: 0.6008 - 2s/epoch - 284ms/step\n",
      "Epoch 93/250\n",
      "6/6 - 2s - loss: 1.0504 - accuracy: 0.6485 - val_loss: 1.1465 - val_accuracy: 0.6279 - 2s/epoch - 279ms/step\n",
      "Epoch 94/250\n",
      "6/6 - 2s - loss: 1.0493 - accuracy: 0.6369 - val_loss: 1.2443 - val_accuracy: 0.5426 - 2s/epoch - 276ms/step\n",
      "Epoch 95/250\n",
      "6/6 - 2s - loss: 1.0580 - accuracy: 0.6194 - val_loss: 1.1357 - val_accuracy: 0.6163 - 2s/epoch - 291ms/step\n",
      "Epoch 96/250\n",
      "6/6 - 3s - loss: 1.0171 - accuracy: 0.6602 - val_loss: 1.1220 - val_accuracy: 0.6008 - 3s/epoch - 436ms/step\n",
      "Epoch 97/250\n",
      "6/6 - 2s - loss: 0.9953 - accuracy: 0.6553 - val_loss: 1.1095 - val_accuracy: 0.6047 - 2s/epoch - 287ms/step\n",
      "Epoch 98/250\n",
      "6/6 - 2s - loss: 0.9987 - accuracy: 0.6505 - val_loss: 1.0935 - val_accuracy: 0.6240 - 2s/epoch - 279ms/step\n",
      "Epoch 99/250\n",
      "6/6 - 2s - loss: 0.9739 - accuracy: 0.6563 - val_loss: 1.1236 - val_accuracy: 0.6202 - 2s/epoch - 287ms/step\n",
      "Epoch 100/250\n",
      "6/6 - 2s - loss: 0.9626 - accuracy: 0.6563 - val_loss: 1.0832 - val_accuracy: 0.5969 - 2s/epoch - 277ms/step\n",
      "Epoch 101/250\n",
      "6/6 - 2s - loss: 0.9423 - accuracy: 0.6680 - val_loss: 1.0575 - val_accuracy: 0.6395 - 2s/epoch - 277ms/step\n",
      "Epoch 102/250\n",
      "6/6 - 2s - loss: 0.9295 - accuracy: 0.6893 - val_loss: 1.0920 - val_accuracy: 0.5891 - 2s/epoch - 359ms/step\n",
      "Epoch 103/250\n",
      "6/6 - 2s - loss: 0.9256 - accuracy: 0.6777 - val_loss: 1.0610 - val_accuracy: 0.6434 - 2s/epoch - 347ms/step\n",
      "Epoch 104/250\n",
      "6/6 - 2s - loss: 0.9042 - accuracy: 0.6767 - val_loss: 1.0456 - val_accuracy: 0.6279 - 2s/epoch - 277ms/step\n",
      "Epoch 105/250\n",
      "6/6 - 2s - loss: 0.8927 - accuracy: 0.7019 - val_loss: 1.0808 - val_accuracy: 0.6279 - 2s/epoch - 288ms/step\n",
      "Epoch 106/250\n",
      "6/6 - 2s - loss: 0.8844 - accuracy: 0.6971 - val_loss: 1.0457 - val_accuracy: 0.6318 - 2s/epoch - 285ms/step\n",
      "Epoch 107/250\n",
      "6/6 - 2s - loss: 0.8855 - accuracy: 0.6893 - val_loss: 1.0064 - val_accuracy: 0.6589 - 2s/epoch - 282ms/step\n",
      "Epoch 108/250\n",
      "6/6 - 2s - loss: 0.8775 - accuracy: 0.7097 - val_loss: 1.0384 - val_accuracy: 0.6589 - 2s/epoch - 279ms/step\n",
      "Epoch 109/250\n",
      "6/6 - 3s - loss: 0.8643 - accuracy: 0.6942 - val_loss: 1.0129 - val_accuracy: 0.6589 - 3s/epoch - 428ms/step\n",
      "Epoch 110/250\n",
      "6/6 - 2s - loss: 0.8373 - accuracy: 0.7049 - val_loss: 0.9936 - val_accuracy: 0.6589 - 2s/epoch - 272ms/step\n",
      "Epoch 111/250\n",
      "6/6 - 2s - loss: 0.8304 - accuracy: 0.7165 - val_loss: 0.9679 - val_accuracy: 0.6705 - 2s/epoch - 283ms/step\n",
      "Epoch 112/250\n",
      "6/6 - 2s - loss: 0.8194 - accuracy: 0.7136 - val_loss: 0.9807 - val_accuracy: 0.6473 - 2s/epoch - 282ms/step\n",
      "Epoch 113/250\n",
      "6/6 - 2s - loss: 0.8160 - accuracy: 0.7204 - val_loss: 0.9662 - val_accuracy: 0.6628 - 2s/epoch - 277ms/step\n",
      "Epoch 114/250\n",
      "6/6 - 2s - loss: 0.7940 - accuracy: 0.7175 - val_loss: 0.9678 - val_accuracy: 0.6550 - 2s/epoch - 279ms/step\n",
      "Epoch 115/250\n",
      "6/6 - 2s - loss: 0.7835 - accuracy: 0.7437 - val_loss: 0.9426 - val_accuracy: 0.7016 - 2s/epoch - 317ms/step\n",
      "Epoch 116/250\n",
      "6/6 - 2s - loss: 0.7960 - accuracy: 0.7175 - val_loss: 1.0066 - val_accuracy: 0.6163 - 2s/epoch - 397ms/step\n",
      "Epoch 117/250\n",
      "6/6 - 2s - loss: 0.7950 - accuracy: 0.7272 - val_loss: 0.9366 - val_accuracy: 0.6977 - 2s/epoch - 298ms/step\n",
      "Epoch 118/250\n",
      "6/6 - 2s - loss: 0.7770 - accuracy: 0.7350 - val_loss: 1.0416 - val_accuracy: 0.6550 - 2s/epoch - 280ms/step\n",
      "Epoch 119/250\n",
      "6/6 - 2s - loss: 0.7793 - accuracy: 0.7350 - val_loss: 0.9148 - val_accuracy: 0.6899 - 2s/epoch - 289ms/step\n",
      "Epoch 120/250\n",
      "6/6 - 2s - loss: 0.7548 - accuracy: 0.7427 - val_loss: 0.9467 - val_accuracy: 0.6938 - 2s/epoch - 281ms/step\n",
      "Epoch 121/250\n",
      "6/6 - 2s - loss: 0.7519 - accuracy: 0.7427 - val_loss: 0.9127 - val_accuracy: 0.6744 - 2s/epoch - 280ms/step\n",
      "Epoch 122/250\n",
      "6/6 - 2s - loss: 0.7303 - accuracy: 0.7456 - val_loss: 0.9059 - val_accuracy: 0.7093 - 2s/epoch - 400ms/step\n",
      "Epoch 123/250\n",
      "6/6 - 2s - loss: 0.7190 - accuracy: 0.7602 - val_loss: 0.9188 - val_accuracy: 0.6822 - 2s/epoch - 305ms/step\n",
      "Epoch 124/250\n",
      "6/6 - 2s - loss: 0.7410 - accuracy: 0.7466 - val_loss: 0.9256 - val_accuracy: 0.7016 - 2s/epoch - 285ms/step\n",
      "Epoch 125/250\n",
      "6/6 - 2s - loss: 0.7305 - accuracy: 0.7495 - val_loss: 0.9777 - val_accuracy: 0.6550 - 2s/epoch - 286ms/step\n",
      "Epoch 126/250\n",
      "6/6 - 2s - loss: 0.7185 - accuracy: 0.7476 - val_loss: 0.9080 - val_accuracy: 0.7132 - 2s/epoch - 274ms/step\n",
      "Epoch 127/250\n",
      "6/6 - 2s - loss: 0.7144 - accuracy: 0.7612 - val_loss: 0.9136 - val_accuracy: 0.6938 - 2s/epoch - 277ms/step\n",
      "Epoch 128/250\n",
      "6/6 - 2s - loss: 0.6924 - accuracy: 0.7495 - val_loss: 0.9311 - val_accuracy: 0.6899 - 2s/epoch - 293ms/step\n",
      "Epoch 129/250\n",
      "6/6 - 3s - loss: 0.6978 - accuracy: 0.7621 - val_loss: 0.9030 - val_accuracy: 0.7054 - 3s/epoch - 420ms/step\n",
      "Epoch 130/250\n",
      "6/6 - 2s - loss: 0.6873 - accuracy: 0.7718 - val_loss: 0.8951 - val_accuracy: 0.7054 - 2s/epoch - 286ms/step\n",
      "Epoch 131/250\n",
      "6/6 - 2s - loss: 0.6830 - accuracy: 0.7709 - val_loss: 0.8814 - val_accuracy: 0.7248 - 2s/epoch - 278ms/step\n",
      "Epoch 132/250\n",
      "6/6 - 2s - loss: 0.6628 - accuracy: 0.7835 - val_loss: 0.9069 - val_accuracy: 0.7093 - 2s/epoch - 282ms/step\n",
      "Epoch 133/250\n",
      "6/6 - 2s - loss: 0.6553 - accuracy: 0.7738 - val_loss: 0.8881 - val_accuracy: 0.7132 - 2s/epoch - 276ms/step\n",
      "Epoch 134/250\n",
      "6/6 - 2s - loss: 0.6470 - accuracy: 0.7806 - val_loss: 0.8600 - val_accuracy: 0.7326 - 2s/epoch - 277ms/step\n",
      "Epoch 135/250\n",
      "6/6 - 2s - loss: 0.6323 - accuracy: 0.7806 - val_loss: 0.8569 - val_accuracy: 0.7287 - 2s/epoch - 330ms/step\n",
      "Epoch 136/250\n",
      "6/6 - 2s - loss: 0.6453 - accuracy: 0.7806 - val_loss: 0.8967 - val_accuracy: 0.7093 - 2s/epoch - 376ms/step\n",
      "Epoch 137/250\n",
      "6/6 - 2s - loss: 0.6334 - accuracy: 0.7854 - val_loss: 0.8513 - val_accuracy: 0.7442 - 2s/epoch - 284ms/step\n",
      "Epoch 138/250\n",
      "6/6 - 2s - loss: 0.6140 - accuracy: 0.7825 - val_loss: 0.8560 - val_accuracy: 0.7326 - 2s/epoch - 274ms/step\n",
      "Epoch 139/250\n",
      "6/6 - 2s - loss: 0.6108 - accuracy: 0.7874 - val_loss: 0.8515 - val_accuracy: 0.7364 - 2s/epoch - 281ms/step\n",
      "Epoch 140/250\n",
      "6/6 - 2s - loss: 0.5898 - accuracy: 0.8039 - val_loss: 0.8380 - val_accuracy: 0.7287 - 2s/epoch - 276ms/step\n",
      "Epoch 141/250\n",
      "6/6 - 2s - loss: 0.5860 - accuracy: 0.7961 - val_loss: 0.8462 - val_accuracy: 0.7403 - 2s/epoch - 290ms/step\n",
      "Epoch 142/250\n",
      "6/6 - 2s - loss: 0.5933 - accuracy: 0.7922 - val_loss: 0.8400 - val_accuracy: 0.7403 - 2s/epoch - 397ms/step\n",
      "Epoch 143/250\n",
      "6/6 - 2s - loss: 0.5819 - accuracy: 0.8087 - val_loss: 0.8590 - val_accuracy: 0.7209 - 2s/epoch - 307ms/step\n",
      "Epoch 144/250\n",
      "6/6 - 2s - loss: 0.5715 - accuracy: 0.8029 - val_loss: 0.8452 - val_accuracy: 0.7481 - 2s/epoch - 288ms/step\n",
      "Epoch 145/250\n",
      "6/6 - 2s - loss: 0.5834 - accuracy: 0.8029 - val_loss: 0.8237 - val_accuracy: 0.7481 - 2s/epoch - 280ms/step\n",
      "Epoch 146/250\n",
      "6/6 - 2s - loss: 0.5689 - accuracy: 0.8097 - val_loss: 0.8309 - val_accuracy: 0.7519 - 2s/epoch - 285ms/step\n",
      "Epoch 147/250\n",
      "6/6 - 2s - loss: 0.5616 - accuracy: 0.8087 - val_loss: 0.8329 - val_accuracy: 0.7442 - 2s/epoch - 277ms/step\n",
      "Epoch 148/250\n",
      "6/6 - 2s - loss: 0.5623 - accuracy: 0.8136 - val_loss: 0.8362 - val_accuracy: 0.7481 - 2s/epoch - 281ms/step\n",
      "Epoch 149/250\n",
      "6/6 - 3s - loss: 0.5554 - accuracy: 0.8107 - val_loss: 0.8235 - val_accuracy: 0.7364 - 3s/epoch - 421ms/step\n",
      "Epoch 150/250\n",
      "6/6 - 2s - loss: 0.5416 - accuracy: 0.8223 - val_loss: 0.8342 - val_accuracy: 0.7403 - 2s/epoch - 267ms/step\n",
      "Epoch 151/250\n",
      "6/6 - 2s - loss: 0.5473 - accuracy: 0.8175 - val_loss: 0.8235 - val_accuracy: 0.7442 - 2s/epoch - 277ms/step\n",
      "Epoch 152/250\n",
      "6/6 - 2s - loss: 0.5787 - accuracy: 0.7981 - val_loss: 0.8615 - val_accuracy: 0.7442 - 2s/epoch - 278ms/step\n",
      "Epoch 153/250\n",
      "6/6 - 2s - loss: 0.5653 - accuracy: 0.8194 - val_loss: 0.8385 - val_accuracy: 0.7403 - 2s/epoch - 286ms/step\n",
      "Epoch 154/250\n",
      "6/6 - 2s - loss: 0.5541 - accuracy: 0.8097 - val_loss: 0.8182 - val_accuracy: 0.7519 - 2s/epoch - 277ms/step\n",
      "Epoch 155/250\n",
      "6/6 - 2s - loss: 0.5359 - accuracy: 0.8282 - val_loss: 0.8299 - val_accuracy: 0.7364 - 2s/epoch - 335ms/step\n",
      "Epoch 156/250\n",
      "6/6 - 2s - loss: 0.5387 - accuracy: 0.8155 - val_loss: 0.8491 - val_accuracy: 0.7364 - 2s/epoch - 363ms/step\n",
      "Epoch 157/250\n",
      "6/6 - 2s - loss: 0.5122 - accuracy: 0.8233 - val_loss: 0.8194 - val_accuracy: 0.7403 - 2s/epoch - 283ms/step\n",
      "Epoch 158/250\n",
      "6/6 - 2s - loss: 0.5214 - accuracy: 0.8204 - val_loss: 0.8272 - val_accuracy: 0.7519 - 2s/epoch - 280ms/step\n",
      "Epoch 159/250\n",
      "6/6 - 2s - loss: 0.5021 - accuracy: 0.8301 - val_loss: 0.8236 - val_accuracy: 0.7597 - 2s/epoch - 289ms/step\n",
      "Epoch 160/250\n",
      "6/6 - 2s - loss: 0.5041 - accuracy: 0.8272 - val_loss: 0.8297 - val_accuracy: 0.7481 - 2s/epoch - 275ms/step\n",
      "Epoch 161/250\n",
      "6/6 - 2s - loss: 0.5024 - accuracy: 0.8301 - val_loss: 0.8001 - val_accuracy: 0.7597 - 2s/epoch - 275ms/step\n",
      "Epoch 162/250\n",
      "6/6 - 2s - loss: 0.4985 - accuracy: 0.8291 - val_loss: 0.8297 - val_accuracy: 0.7442 - 2s/epoch - 402ms/step\n",
      "Epoch 163/250\n",
      "6/6 - 2s - loss: 0.4941 - accuracy: 0.8243 - val_loss: 0.8211 - val_accuracy: 0.7519 - 2s/epoch - 294ms/step\n",
      "Epoch 164/250\n",
      "6/6 - 2s - loss: 0.4744 - accuracy: 0.8340 - val_loss: 0.8232 - val_accuracy: 0.7558 - 2s/epoch - 276ms/step\n",
      "Epoch 165/250\n",
      "6/6 - 2s - loss: 0.4748 - accuracy: 0.8350 - val_loss: 0.8054 - val_accuracy: 0.7674 - 2s/epoch - 275ms/step\n",
      "Epoch 166/250\n",
      "6/6 - 2s - loss: 0.4764 - accuracy: 0.8447 - val_loss: 0.7951 - val_accuracy: 0.7752 - 2s/epoch - 276ms/step\n",
      "Epoch 167/250\n",
      "6/6 - 2s - loss: 0.4725 - accuracy: 0.8320 - val_loss: 0.8088 - val_accuracy: 0.7481 - 2s/epoch - 276ms/step\n",
      "Epoch 168/250\n",
      "6/6 - 2s - loss: 0.4732 - accuracy: 0.8437 - val_loss: 0.8021 - val_accuracy: 0.7868 - 2s/epoch - 275ms/step\n",
      "Epoch 169/250\n",
      "6/6 - 3s - loss: 0.4754 - accuracy: 0.8330 - val_loss: 0.8391 - val_accuracy: 0.7403 - 3s/epoch - 418ms/step\n",
      "Epoch 170/250\n",
      "6/6 - 2s - loss: 0.4803 - accuracy: 0.8340 - val_loss: 0.8657 - val_accuracy: 0.7364 - 2s/epoch - 274ms/step\n",
      "Epoch 171/250\n",
      "6/6 - 2s - loss: 0.4866 - accuracy: 0.8301 - val_loss: 0.8609 - val_accuracy: 0.7442 - 2s/epoch - 274ms/step\n",
      "Epoch 172/250\n",
      "6/6 - 2s - loss: 0.4758 - accuracy: 0.8350 - val_loss: 0.8599 - val_accuracy: 0.7248 - 2s/epoch - 285ms/step\n",
      "Epoch 173/250\n",
      "6/6 - 2s - loss: 0.4805 - accuracy: 0.8301 - val_loss: 0.7947 - val_accuracy: 0.7636 - 2s/epoch - 276ms/step\n",
      "Epoch 174/250\n",
      "6/6 - 2s - loss: 0.4549 - accuracy: 0.8456 - val_loss: 0.8033 - val_accuracy: 0.7674 - 2s/epoch - 283ms/step\n",
      "Epoch 175/250\n",
      "6/6 - 2s - loss: 0.4531 - accuracy: 0.8553 - val_loss: 0.7931 - val_accuracy: 0.7791 - 2s/epoch - 322ms/step\n",
      "Epoch 176/250\n",
      "6/6 - 2s - loss: 0.4332 - accuracy: 0.8534 - val_loss: 0.8160 - val_accuracy: 0.7674 - 2s/epoch - 372ms/step\n",
      "Epoch 177/250\n",
      "6/6 - 2s - loss: 0.4362 - accuracy: 0.8544 - val_loss: 0.7962 - val_accuracy: 0.7752 - 2s/epoch - 280ms/step\n",
      "Epoch 178/250\n",
      "6/6 - 2s - loss: 0.4260 - accuracy: 0.8612 - val_loss: 0.7820 - val_accuracy: 0.7636 - 2s/epoch - 275ms/step\n",
      "Epoch 179/250\n",
      "6/6 - 2s - loss: 0.4434 - accuracy: 0.8427 - val_loss: 0.7828 - val_accuracy: 0.7791 - 2s/epoch - 275ms/step\n",
      "Epoch 180/250\n",
      "6/6 - 2s - loss: 0.4194 - accuracy: 0.8621 - val_loss: 0.7862 - val_accuracy: 0.7752 - 2s/epoch - 274ms/step\n",
      "Epoch 181/250\n",
      "6/6 - 2s - loss: 0.4016 - accuracy: 0.8689 - val_loss: 0.7747 - val_accuracy: 0.7752 - 2s/epoch - 272ms/step\n",
      "Epoch 182/250\n",
      "6/6 - 2s - loss: 0.4194 - accuracy: 0.8524 - val_loss: 0.7937 - val_accuracy: 0.7713 - 2s/epoch - 360ms/step\n",
      "Epoch 183/250\n",
      "6/6 - 2s - loss: 0.4010 - accuracy: 0.8718 - val_loss: 0.8044 - val_accuracy: 0.7791 - 2s/epoch - 323ms/step\n",
      "Epoch 184/250\n",
      "6/6 - 2s - loss: 0.4131 - accuracy: 0.8553 - val_loss: 0.7853 - val_accuracy: 0.7868 - 2s/epoch - 277ms/step\n",
      "Epoch 185/250\n",
      "6/6 - 2s - loss: 0.3943 - accuracy: 0.8748 - val_loss: 0.7801 - val_accuracy: 0.7752 - 2s/epoch - 284ms/step\n",
      "Epoch 186/250\n",
      "6/6 - 2s - loss: 0.3970 - accuracy: 0.8660 - val_loss: 0.7902 - val_accuracy: 0.7829 - 2s/epoch - 277ms/step\n",
      "Epoch 187/250\n",
      "6/6 - 2s - loss: 0.3782 - accuracy: 0.8757 - val_loss: 0.7711 - val_accuracy: 0.7868 - 2s/epoch - 274ms/step\n",
      "Epoch 188/250\n",
      "6/6 - 2s - loss: 0.3841 - accuracy: 0.8728 - val_loss: 0.8042 - val_accuracy: 0.7636 - 2s/epoch - 274ms/step\n",
      "Epoch 189/250\n",
      "6/6 - 3s - loss: 0.3967 - accuracy: 0.8583 - val_loss: 0.7760 - val_accuracy: 0.7713 - 3s/epoch - 439ms/step\n",
      "Epoch 190/250\n",
      "6/6 - 2s - loss: 0.3838 - accuracy: 0.8728 - val_loss: 0.7835 - val_accuracy: 0.7791 - 2s/epoch - 275ms/step\n",
      "Epoch 191/250\n",
      "6/6 - 2s - loss: 0.3709 - accuracy: 0.8670 - val_loss: 0.8072 - val_accuracy: 0.7674 - 2s/epoch - 274ms/step\n",
      "Epoch 192/250\n",
      "6/6 - 2s - loss: 0.3809 - accuracy: 0.8680 - val_loss: 0.7887 - val_accuracy: 0.7829 - 2s/epoch - 284ms/step\n",
      "Epoch 193/250\n",
      "6/6 - 2s - loss: 0.3770 - accuracy: 0.8689 - val_loss: 0.7907 - val_accuracy: 0.7674 - 2s/epoch - 281ms/step\n",
      "Epoch 194/250\n",
      "6/6 - 2s - loss: 0.3887 - accuracy: 0.8612 - val_loss: 0.7824 - val_accuracy: 0.7752 - 2s/epoch - 268ms/step\n",
      "Epoch 195/250\n",
      "6/6 - 2s - loss: 0.3686 - accuracy: 0.8709 - val_loss: 0.7961 - val_accuracy: 0.7791 - 2s/epoch - 287ms/step\n",
      "Epoch 196/250\n",
      "6/6 - 2s - loss: 0.3734 - accuracy: 0.8845 - val_loss: 0.7921 - val_accuracy: 0.7791 - 2s/epoch - 403ms/step\n",
      "Epoch 197/250\n",
      "6/6 - 2s - loss: 0.3726 - accuracy: 0.8748 - val_loss: 0.7886 - val_accuracy: 0.7907 - 2s/epoch - 278ms/step\n",
      "Epoch 198/250\n",
      "6/6 - 2s - loss: 0.3513 - accuracy: 0.8786 - val_loss: 0.8141 - val_accuracy: 0.7558 - 2s/epoch - 276ms/step\n",
      "Epoch 199/250\n",
      "6/6 - 2s - loss: 0.3692 - accuracy: 0.8748 - val_loss: 0.8013 - val_accuracy: 0.7907 - 2s/epoch - 273ms/step\n",
      "Epoch 200/250\n",
      "6/6 - 2s - loss: 0.3488 - accuracy: 0.8738 - val_loss: 0.7892 - val_accuracy: 0.7713 - 2s/epoch - 276ms/step\n",
      "Epoch 201/250\n",
      "6/6 - 2s - loss: 0.3520 - accuracy: 0.8825 - val_loss: 0.7800 - val_accuracy: 0.7946 - 2s/epoch - 282ms/step\n",
      "Epoch 202/250\n",
      "6/6 - 2s - loss: 0.3636 - accuracy: 0.8757 - val_loss: 0.8269 - val_accuracy: 0.7481 - 2s/epoch - 331ms/step\n",
      "Epoch 203/250\n",
      "6/6 - 2s - loss: 0.3494 - accuracy: 0.8825 - val_loss: 0.8121 - val_accuracy: 0.7946 - 2s/epoch - 360ms/step\n",
      "Epoch 204/250\n",
      "6/6 - 2s - loss: 0.3478 - accuracy: 0.8689 - val_loss: 0.7922 - val_accuracy: 0.7829 - 2s/epoch - 268ms/step\n",
      "Epoch 205/250\n",
      "6/6 - 2s - loss: 0.3598 - accuracy: 0.8699 - val_loss: 0.7987 - val_accuracy: 0.7791 - 2s/epoch - 272ms/step\n",
      "Epoch 206/250\n",
      "6/6 - 2s - loss: 0.3374 - accuracy: 0.8806 - val_loss: 0.7784 - val_accuracy: 0.7907 - 2s/epoch - 277ms/step\n",
      "Epoch 207/250\n",
      "6/6 - 2s - loss: 0.3304 - accuracy: 0.8922 - val_loss: 0.7851 - val_accuracy: 0.7907 - 2s/epoch - 271ms/step\n",
      "Epoch 208/250\n",
      "6/6 - 2s - loss: 0.3353 - accuracy: 0.8883 - val_loss: 0.7992 - val_accuracy: 0.7791 - 2s/epoch - 272ms/step\n",
      "Epoch 209/250\n",
      "6/6 - 2s - loss: 0.3245 - accuracy: 0.8942 - val_loss: 0.8104 - val_accuracy: 0.7829 - 2s/epoch - 392ms/step\n",
      "Epoch 210/250\n",
      "6/6 - 2s - loss: 0.3473 - accuracy: 0.8845 - val_loss: 0.7866 - val_accuracy: 0.7791 - 2s/epoch - 307ms/step\n",
      "Epoch 211/250\n",
      "6/6 - 2s - loss: 0.3328 - accuracy: 0.8825 - val_loss: 0.8050 - val_accuracy: 0.7829 - 2s/epoch - 284ms/step\n",
      "Epoch 212/250\n",
      "6/6 - 2s - loss: 0.3326 - accuracy: 0.8786 - val_loss: 0.8037 - val_accuracy: 0.7829 - 2s/epoch - 271ms/step\n",
      "Epoch 213/250\n",
      "6/6 - 2s - loss: 0.3113 - accuracy: 0.8990 - val_loss: 0.7852 - val_accuracy: 0.7868 - 2s/epoch - 293ms/step\n",
      "Epoch 214/250\n",
      "6/6 - 2s - loss: 0.3220 - accuracy: 0.8893 - val_loss: 0.7845 - val_accuracy: 0.7791 - 2s/epoch - 277ms/step\n",
      "Epoch 215/250\n",
      "6/6 - 2s - loss: 0.3097 - accuracy: 0.9010 - val_loss: 0.8066 - val_accuracy: 0.7868 - 2s/epoch - 283ms/step\n",
      "Epoch 216/250\n",
      "6/6 - 3s - loss: 0.2987 - accuracy: 0.9107 - val_loss: 0.7931 - val_accuracy: 0.7791 - 3s/epoch - 424ms/step\n",
      "Epoch 217/250\n",
      "6/6 - 2s - loss: 0.3090 - accuracy: 0.8854 - val_loss: 0.7954 - val_accuracy: 0.7946 - 2s/epoch - 273ms/step\n",
      "Epoch 218/250\n",
      "6/6 - 2s - loss: 0.3006 - accuracy: 0.8913 - val_loss: 0.7796 - val_accuracy: 0.7946 - 2s/epoch - 270ms/step\n",
      "Epoch 219/250\n",
      "6/6 - 2s - loss: 0.3045 - accuracy: 0.8951 - val_loss: 0.7988 - val_accuracy: 0.7674 - 2s/epoch - 280ms/step\n",
      "Epoch 220/250\n",
      "6/6 - 2s - loss: 0.3131 - accuracy: 0.8990 - val_loss: 0.7834 - val_accuracy: 0.7984 - 2s/epoch - 291ms/step\n",
      "Epoch 221/250\n",
      "6/6 - 2s - loss: 0.2984 - accuracy: 0.8981 - val_loss: 0.7987 - val_accuracy: 0.7829 - 2s/epoch - 276ms/step\n",
      "Epoch 222/250\n",
      "6/6 - 2s - loss: 0.2950 - accuracy: 0.8951 - val_loss: 0.8114 - val_accuracy: 0.7791 - 2s/epoch - 317ms/step\n",
      "Epoch 223/250\n",
      "6/6 - 2s - loss: 0.2919 - accuracy: 0.9049 - val_loss: 0.7806 - val_accuracy: 0.7829 - 2s/epoch - 382ms/step\n",
      "Epoch 224/250\n",
      "6/6 - 2s - loss: 0.2839 - accuracy: 0.9019 - val_loss: 0.8153 - val_accuracy: 0.7829 - 2s/epoch - 270ms/step\n",
      "Epoch 225/250\n",
      "6/6 - 2s - loss: 0.2706 - accuracy: 0.9097 - val_loss: 0.8039 - val_accuracy: 0.7791 - 2s/epoch - 277ms/step\n",
      "Epoch 226/250\n",
      "6/6 - 2s - loss: 0.2658 - accuracy: 0.9117 - val_loss: 0.8015 - val_accuracy: 0.7907 - 2s/epoch - 277ms/step\n",
      "Epoch 227/250\n",
      "6/6 - 2s - loss: 0.2772 - accuracy: 0.9136 - val_loss: 0.7936 - val_accuracy: 0.7868 - 2s/epoch - 272ms/step\n",
      "Epoch 228/250\n",
      "6/6 - 2s - loss: 0.2841 - accuracy: 0.9136 - val_loss: 0.7915 - val_accuracy: 0.7791 - 2s/epoch - 273ms/step\n",
      "Epoch 229/250\n",
      "6/6 - 2s - loss: 0.2802 - accuracy: 0.9146 - val_loss: 0.8305 - val_accuracy: 0.7829 - 2s/epoch - 353ms/step\n",
      "Epoch 230/250\n",
      "6/6 - 2s - loss: 0.2787 - accuracy: 0.9000 - val_loss: 0.8170 - val_accuracy: 0.7791 - 2s/epoch - 333ms/step\n",
      "Epoch 231/250\n",
      "6/6 - 2s - loss: 0.2650 - accuracy: 0.9087 - val_loss: 0.8399 - val_accuracy: 0.7829 - 2s/epoch - 284ms/step\n",
      "Epoch 232/250\n",
      "6/6 - 2s - loss: 0.2804 - accuracy: 0.9029 - val_loss: 0.8089 - val_accuracy: 0.7907 - 2s/epoch - 284ms/step\n",
      "Epoch 233/250\n",
      "6/6 - 2s - loss: 0.2738 - accuracy: 0.8990 - val_loss: 0.7847 - val_accuracy: 0.7946 - 2s/epoch - 280ms/step\n",
      "Epoch 234/250\n",
      "6/6 - 2s - loss: 0.2992 - accuracy: 0.8942 - val_loss: 0.8484 - val_accuracy: 0.7403 - 2s/epoch - 273ms/step\n",
      "Epoch 235/250\n",
      "6/6 - 2s - loss: 0.2834 - accuracy: 0.9029 - val_loss: 0.8279 - val_accuracy: 0.7829 - 2s/epoch - 278ms/step\n",
      "Epoch 236/250\n",
      "6/6 - 3s - loss: 0.2741 - accuracy: 0.9087 - val_loss: 0.8290 - val_accuracy: 0.7752 - 3s/epoch - 421ms/step\n",
      "Epoch 237/250\n",
      "6/6 - 2s - loss: 0.2632 - accuracy: 0.9117 - val_loss: 0.8026 - val_accuracy: 0.7907 - 2s/epoch - 276ms/step\n",
      "Epoch 238/250\n",
      "6/6 - 2s - loss: 0.2565 - accuracy: 0.9194 - val_loss: 0.7800 - val_accuracy: 0.7907 - 2s/epoch - 283ms/step\n",
      "Epoch 239/250\n",
      "6/6 - 2s - loss: 0.2728 - accuracy: 0.9068 - val_loss: 0.8004 - val_accuracy: 0.7946 - 2s/epoch - 278ms/step\n",
      "Epoch 240/250\n",
      "6/6 - 2s - loss: 0.2577 - accuracy: 0.9136 - val_loss: 0.8249 - val_accuracy: 0.7791 - 2s/epoch - 278ms/step\n",
      "Epoch 241/250\n",
      "6/6 - 2s - loss: 0.2513 - accuracy: 0.9204 - val_loss: 0.8088 - val_accuracy: 0.7907 - 2s/epoch - 282ms/step\n",
      "Epoch 242/250\n",
      "6/6 - 2s - loss: 0.2471 - accuracy: 0.9175 - val_loss: 0.8067 - val_accuracy: 0.7907 - 2s/epoch - 284ms/step\n",
      "Epoch 243/250\n",
      "6/6 - 2s - loss: 0.2502 - accuracy: 0.9136 - val_loss: 0.8211 - val_accuracy: 0.7868 - 2s/epoch - 415ms/step\n",
      "Epoch 244/250\n",
      "6/6 - 2s - loss: 0.2257 - accuracy: 0.9223 - val_loss: 0.7988 - val_accuracy: 0.7868 - 2s/epoch - 287ms/step\n",
      "Epoch 245/250\n",
      "6/6 - 2s - loss: 0.2317 - accuracy: 0.9272 - val_loss: 0.8001 - val_accuracy: 0.7946 - 2s/epoch - 280ms/step\n",
      "Epoch 246/250\n",
      "6/6 - 2s - loss: 0.2403 - accuracy: 0.9155 - val_loss: 0.8091 - val_accuracy: 0.7829 - 2s/epoch - 271ms/step\n",
      "Epoch 247/250\n",
      "6/6 - 2s - loss: 0.2351 - accuracy: 0.9223 - val_loss: 0.8330 - val_accuracy: 0.7946 - 2s/epoch - 278ms/step\n",
      "Epoch 248/250\n",
      "6/6 - 2s - loss: 0.2402 - accuracy: 0.9155 - val_loss: 0.8064 - val_accuracy: 0.7752 - 2s/epoch - 282ms/step\n",
      "Epoch 249/250\n",
      "6/6 - 2s - loss: 0.2389 - accuracy: 0.9175 - val_loss: 0.8290 - val_accuracy: 0.7946 - 2s/epoch - 361ms/step\n",
      "Epoch 250/250\n",
      "6/6 - 2s - loss: 0.2211 - accuracy: 0.9262 - val_loss: 0.8356 - val_accuracy: 0.7674 - 2s/epoch - 330ms/step\n",
      "9/9 [==============================] - 0s 16ms/step\n",
      "Epoch 1/250\n",
      "6/6 - 4s - loss: 1.9136 - accuracy: 0.3456 - val_loss: 1.7559 - val_accuracy: 0.3876 - 4s/epoch - 584ms/step\n",
      "Epoch 2/250\n",
      "6/6 - 4s - loss: 1.7416 - accuracy: 0.4175 - val_loss: 1.7366 - val_accuracy: 0.3876 - 4s/epoch - 619ms/step\n",
      "Epoch 3/250\n",
      "6/6 - 3s - loss: 1.7070 - accuracy: 0.4175 - val_loss: 1.7453 - val_accuracy: 0.3876 - 3s/epoch - 450ms/step\n",
      "Epoch 4/250\n",
      "6/6 - 3s - loss: 1.6780 - accuracy: 0.4175 - val_loss: 1.7450 - val_accuracy: 0.3876 - 3s/epoch - 455ms/step\n",
      "Epoch 5/250\n",
      "6/6 - 3s - loss: 1.6731 - accuracy: 0.4175 - val_loss: 1.7372 - val_accuracy: 0.3876 - 3s/epoch - 455ms/step\n",
      "Epoch 6/250\n",
      "6/6 - 4s - loss: 1.6749 - accuracy: 0.4175 - val_loss: 1.7358 - val_accuracy: 0.3876 - 4s/epoch - 590ms/step\n",
      "Epoch 7/250\n",
      "6/6 - 3s - loss: 1.6782 - accuracy: 0.4175 - val_loss: 1.7317 - val_accuracy: 0.3876 - 3s/epoch - 448ms/step\n",
      "Epoch 8/250\n",
      "6/6 - 3s - loss: 1.6770 - accuracy: 0.4175 - val_loss: 1.7348 - val_accuracy: 0.3876 - 3s/epoch - 455ms/step\n",
      "Epoch 9/250\n",
      "6/6 - 3s - loss: 1.6721 - accuracy: 0.4175 - val_loss: 1.7315 - val_accuracy: 0.3876 - 3s/epoch - 450ms/step\n",
      "Epoch 10/250\n",
      "6/6 - 4s - loss: 1.6737 - accuracy: 0.4175 - val_loss: 1.7364 - val_accuracy: 0.3876 - 4s/epoch - 616ms/step\n",
      "Epoch 11/250\n",
      "6/6 - 3s - loss: 1.6677 - accuracy: 0.4175 - val_loss: 1.7326 - val_accuracy: 0.3876 - 3s/epoch - 477ms/step\n",
      "Epoch 12/250\n",
      "6/6 - 3s - loss: 1.6715 - accuracy: 0.4175 - val_loss: 1.7365 - val_accuracy: 0.3876 - 3s/epoch - 454ms/step\n",
      "Epoch 13/250\n",
      "6/6 - 3s - loss: 1.6679 - accuracy: 0.4175 - val_loss: 1.7328 - val_accuracy: 0.3876 - 3s/epoch - 477ms/step\n",
      "Epoch 14/250\n",
      "6/6 - 4s - loss: 1.6691 - accuracy: 0.4175 - val_loss: 1.7312 - val_accuracy: 0.3876 - 4s/epoch - 588ms/step\n",
      "Epoch 15/250\n",
      "6/6 - 3s - loss: 1.6670 - accuracy: 0.4175 - val_loss: 1.7310 - val_accuracy: 0.3876 - 3s/epoch - 452ms/step\n",
      "Epoch 16/250\n",
      "6/6 - 3s - loss: 1.6658 - accuracy: 0.4175 - val_loss: 1.7288 - val_accuracy: 0.3876 - 3s/epoch - 450ms/step\n",
      "Epoch 17/250\n",
      "6/6 - 3s - loss: 1.6656 - accuracy: 0.4175 - val_loss: 1.7335 - val_accuracy: 0.3876 - 3s/epoch - 449ms/step\n",
      "Epoch 18/250\n",
      "6/6 - 4s - loss: 1.6655 - accuracy: 0.4175 - val_loss: 1.7355 - val_accuracy: 0.3876 - 4s/epoch - 612ms/step\n",
      "Epoch 19/250\n",
      "6/6 - 3s - loss: 1.6654 - accuracy: 0.4175 - val_loss: 1.7378 - val_accuracy: 0.3876 - 3s/epoch - 453ms/step\n",
      "Epoch 20/250\n",
      "6/6 - 3s - loss: 1.6683 - accuracy: 0.4175 - val_loss: 1.7490 - val_accuracy: 0.3876 - 3s/epoch - 457ms/step\n",
      "Epoch 21/250\n",
      "6/6 - 3s - loss: 1.6680 - accuracy: 0.4175 - val_loss: 1.7398 - val_accuracy: 0.3876 - 3s/epoch - 453ms/step\n",
      "Epoch 22/250\n",
      "6/6 - 4s - loss: 1.6741 - accuracy: 0.4175 - val_loss: 1.7354 - val_accuracy: 0.3876 - 4s/epoch - 588ms/step\n",
      "Epoch 23/250\n",
      "6/6 - 3s - loss: 1.6667 - accuracy: 0.4175 - val_loss: 1.7304 - val_accuracy: 0.3876 - 3s/epoch - 451ms/step\n",
      "Epoch 24/250\n",
      "6/6 - 3s - loss: 1.6648 - accuracy: 0.4175 - val_loss: 1.7310 - val_accuracy: 0.3876 - 3s/epoch - 448ms/step\n",
      "Epoch 25/250\n",
      "6/6 - 3s - loss: 1.6649 - accuracy: 0.4175 - val_loss: 1.7259 - val_accuracy: 0.3876 - 3s/epoch - 471ms/step\n",
      "Epoch 26/250\n",
      "6/6 - 4s - loss: 1.6648 - accuracy: 0.4175 - val_loss: 1.7369 - val_accuracy: 0.3876 - 4s/epoch - 585ms/step\n",
      "Epoch 27/250\n",
      "6/6 - 3s - loss: 1.6624 - accuracy: 0.4175 - val_loss: 1.7305 - val_accuracy: 0.3876 - 3s/epoch - 455ms/step\n",
      "Epoch 28/250\n",
      "6/6 - 3s - loss: 1.6726 - accuracy: 0.4175 - val_loss: 1.7519 - val_accuracy: 0.3876 - 3s/epoch - 449ms/step\n",
      "Epoch 29/250\n",
      "6/6 - 3s - loss: 1.6761 - accuracy: 0.4175 - val_loss: 1.7334 - val_accuracy: 0.3876 - 3s/epoch - 454ms/step\n",
      "Epoch 30/250\n",
      "6/6 - 3s - loss: 1.6658 - accuracy: 0.4175 - val_loss: 1.7395 - val_accuracy: 0.3876 - 3s/epoch - 545ms/step\n",
      "Epoch 31/250\n",
      "6/6 - 3s - loss: 1.6639 - accuracy: 0.4175 - val_loss: 1.7266 - val_accuracy: 0.3876 - 3s/epoch - 488ms/step\n",
      "Epoch 32/250\n",
      "6/6 - 3s - loss: 1.6607 - accuracy: 0.4175 - val_loss: 1.7476 - val_accuracy: 0.3876 - 3s/epoch - 449ms/step\n",
      "Epoch 33/250\n",
      "6/6 - 3s - loss: 1.6697 - accuracy: 0.4175 - val_loss: 1.7333 - val_accuracy: 0.3876 - 3s/epoch - 449ms/step\n",
      "Epoch 34/250\n",
      "6/6 - 3s - loss: 1.6959 - accuracy: 0.4175 - val_loss: 1.7283 - val_accuracy: 0.3876 - 3s/epoch - 499ms/step\n",
      "Epoch 35/250\n",
      "6/6 - 3s - loss: 1.6647 - accuracy: 0.4175 - val_loss: 1.7455 - val_accuracy: 0.3876 - 3s/epoch - 534ms/step\n",
      "Epoch 36/250\n",
      "6/6 - 3s - loss: 1.6641 - accuracy: 0.4175 - val_loss: 1.7295 - val_accuracy: 0.3876 - 3s/epoch - 449ms/step\n",
      "Epoch 37/250\n",
      "6/6 - 3s - loss: 1.6603 - accuracy: 0.4175 - val_loss: 1.7390 - val_accuracy: 0.3876 - 3s/epoch - 454ms/step\n",
      "Epoch 38/250\n",
      "6/6 - 3s - loss: 1.6611 - accuracy: 0.4175 - val_loss: 1.7296 - val_accuracy: 0.3876 - 3s/epoch - 484ms/step\n",
      "Epoch 39/250\n",
      "6/6 - 3s - loss: 1.6550 - accuracy: 0.4175 - val_loss: 1.7411 - val_accuracy: 0.3876 - 3s/epoch - 565ms/step\n",
      "Epoch 40/250\n",
      "6/6 - 3s - loss: 1.6554 - accuracy: 0.4175 - val_loss: 1.7275 - val_accuracy: 0.3876 - 3s/epoch - 450ms/step\n",
      "Epoch 41/250\n",
      "6/6 - 3s - loss: 1.6616 - accuracy: 0.4175 - val_loss: 1.7355 - val_accuracy: 0.3876 - 3s/epoch - 456ms/step\n",
      "Epoch 42/250\n",
      "6/6 - 3s - loss: 1.6595 - accuracy: 0.4175 - val_loss: 1.7302 - val_accuracy: 0.3876 - 3s/epoch - 450ms/step\n",
      "Epoch 43/250\n",
      "6/6 - 4s - loss: 1.6498 - accuracy: 0.4175 - val_loss: 1.7248 - val_accuracy: 0.3876 - 4s/epoch - 589ms/step\n",
      "Epoch 44/250\n",
      "6/6 - 3s - loss: 1.6487 - accuracy: 0.4175 - val_loss: 1.7300 - val_accuracy: 0.3876 - 3s/epoch - 452ms/step\n",
      "Epoch 45/250\n",
      "6/6 - 3s - loss: 1.6441 - accuracy: 0.4175 - val_loss: 1.7227 - val_accuracy: 0.3876 - 3s/epoch - 452ms/step\n",
      "Epoch 46/250\n",
      "6/6 - 3s - loss: 1.6435 - accuracy: 0.4175 - val_loss: 1.7234 - val_accuracy: 0.3876 - 3s/epoch - 452ms/step\n",
      "Epoch 47/250\n",
      "6/6 - 4s - loss: 1.6385 - accuracy: 0.4175 - val_loss: 1.7151 - val_accuracy: 0.3876 - 4s/epoch - 592ms/step\n",
      "Epoch 48/250\n",
      "6/6 - 3s - loss: 1.6343 - accuracy: 0.4175 - val_loss: 1.7155 - val_accuracy: 0.3876 - 3s/epoch - 455ms/step\n",
      "Epoch 49/250\n",
      "6/6 - 3s - loss: 1.6281 - accuracy: 0.4175 - val_loss: 1.7093 - val_accuracy: 0.3876 - 3s/epoch - 450ms/step\n",
      "Epoch 50/250\n",
      "6/6 - 3s - loss: 1.6177 - accuracy: 0.4175 - val_loss: 1.7058 - val_accuracy: 0.3876 - 3s/epoch - 448ms/step\n",
      "Epoch 51/250\n",
      "6/6 - 4s - loss: 1.6106 - accuracy: 0.4175 - val_loss: 1.6978 - val_accuracy: 0.3876 - 4s/epoch - 591ms/step\n",
      "Epoch 52/250\n",
      "6/6 - 3s - loss: 1.6067 - accuracy: 0.4175 - val_loss: 1.7303 - val_accuracy: 0.3876 - 3s/epoch - 449ms/step\n",
      "Epoch 53/250\n",
      "6/6 - 3s - loss: 1.5941 - accuracy: 0.4175 - val_loss: 1.6793 - val_accuracy: 0.3876 - 3s/epoch - 450ms/step\n",
      "Epoch 54/250\n",
      "6/6 - 3s - loss: 1.5732 - accuracy: 0.4184 - val_loss: 1.6850 - val_accuracy: 0.3876 - 3s/epoch - 448ms/step\n",
      "Epoch 55/250\n",
      "6/6 - 4s - loss: 1.5573 - accuracy: 0.4184 - val_loss: 1.6503 - val_accuracy: 0.3876 - 4s/epoch - 591ms/step\n",
      "Epoch 56/250\n",
      "6/6 - 3s - loss: 1.5351 - accuracy: 0.4184 - val_loss: 1.6307 - val_accuracy: 0.3876 - 3s/epoch - 446ms/step\n",
      "Epoch 57/250\n",
      "6/6 - 3s - loss: 1.5258 - accuracy: 0.4311 - val_loss: 1.6480 - val_accuracy: 0.3876 - 3s/epoch - 454ms/step\n",
      "Epoch 58/250\n",
      "6/6 - 3s - loss: 1.5182 - accuracy: 0.4272 - val_loss: 1.6115 - val_accuracy: 0.4225 - 3s/epoch - 452ms/step\n",
      "Epoch 59/250\n",
      "6/6 - 3s - loss: 1.4874 - accuracy: 0.4456 - val_loss: 1.6251 - val_accuracy: 0.4109 - 3s/epoch - 571ms/step\n",
      "Epoch 60/250\n",
      "6/6 - 3s - loss: 1.4742 - accuracy: 0.4515 - val_loss: 1.5871 - val_accuracy: 0.4302 - 3s/epoch - 478ms/step\n",
      "Epoch 61/250\n",
      "6/6 - 3s - loss: 1.4611 - accuracy: 0.4670 - val_loss: 1.5940 - val_accuracy: 0.4264 - 3s/epoch - 454ms/step\n",
      "Epoch 62/250\n",
      "6/6 - 3s - loss: 1.4518 - accuracy: 0.4806 - val_loss: 1.5676 - val_accuracy: 0.4419 - 3s/epoch - 452ms/step\n",
      "Epoch 63/250\n",
      "6/6 - 3s - loss: 1.4302 - accuracy: 0.4854 - val_loss: 1.5627 - val_accuracy: 0.4535 - 3s/epoch - 511ms/step\n",
      "Epoch 64/250\n",
      "6/6 - 3s - loss: 1.4136 - accuracy: 0.4903 - val_loss: 1.5492 - val_accuracy: 0.4574 - 3s/epoch - 527ms/step\n",
      "Epoch 65/250\n",
      "6/6 - 3s - loss: 1.3977 - accuracy: 0.4942 - val_loss: 1.5779 - val_accuracy: 0.4612 - 3s/epoch - 450ms/step\n",
      "Epoch 66/250\n",
      "6/6 - 3s - loss: 1.4108 - accuracy: 0.4913 - val_loss: 1.5372 - val_accuracy: 0.4496 - 3s/epoch - 449ms/step\n",
      "Epoch 67/250\n",
      "6/6 - 3s - loss: 1.3876 - accuracy: 0.4932 - val_loss: 1.5839 - val_accuracy: 0.4535 - 3s/epoch - 486ms/step\n",
      "Epoch 68/250\n",
      "6/6 - 3s - loss: 1.4052 - accuracy: 0.4932 - val_loss: 1.5347 - val_accuracy: 0.4574 - 3s/epoch - 559ms/step\n",
      "Epoch 69/250\n",
      "6/6 - 3s - loss: 1.3957 - accuracy: 0.4961 - val_loss: 1.5850 - val_accuracy: 0.4419 - 3s/epoch - 453ms/step\n",
      "Epoch 70/250\n",
      "6/6 - 3s - loss: 1.3608 - accuracy: 0.5117 - val_loss: 1.5328 - val_accuracy: 0.4806 - 3s/epoch - 454ms/step\n",
      "Epoch 71/250\n",
      "6/6 - 3s - loss: 1.3677 - accuracy: 0.5146 - val_loss: 1.5524 - val_accuracy: 0.4574 - 3s/epoch - 450ms/step\n",
      "Epoch 72/250\n",
      "6/6 - 4s - loss: 1.3499 - accuracy: 0.5019 - val_loss: 1.4882 - val_accuracy: 0.4767 - 4s/epoch - 592ms/step\n",
      "Epoch 73/250\n",
      "6/6 - 3s - loss: 1.3231 - accuracy: 0.5223 - val_loss: 1.5144 - val_accuracy: 0.4767 - 3s/epoch - 454ms/step\n",
      "Epoch 74/250\n",
      "6/6 - 3s - loss: 1.3132 - accuracy: 0.5350 - val_loss: 1.4584 - val_accuracy: 0.5233 - 3s/epoch - 446ms/step\n",
      "Epoch 75/250\n",
      "6/6 - 3s - loss: 1.2892 - accuracy: 0.5718 - val_loss: 1.5397 - val_accuracy: 0.4380 - 3s/epoch - 449ms/step\n",
      "Epoch 76/250\n",
      "6/6 - 4s - loss: 1.3263 - accuracy: 0.5262 - val_loss: 1.4628 - val_accuracy: 0.5039 - 4s/epoch - 589ms/step\n",
      "Epoch 77/250\n",
      "6/6 - 3s - loss: 1.3162 - accuracy: 0.5204 - val_loss: 1.4459 - val_accuracy: 0.5116 - 3s/epoch - 477ms/step\n",
      "Epoch 78/250\n",
      "6/6 - 3s - loss: 1.2956 - accuracy: 0.5447 - val_loss: 1.4499 - val_accuracy: 0.5000 - 3s/epoch - 452ms/step\n",
      "Epoch 79/250\n",
      "6/6 - 3s - loss: 1.2691 - accuracy: 0.5553 - val_loss: 1.4598 - val_accuracy: 0.5271 - 3s/epoch - 449ms/step\n",
      "Epoch 80/250\n",
      "6/6 - 4s - loss: 1.2701 - accuracy: 0.5699 - val_loss: 1.4272 - val_accuracy: 0.5116 - 4s/epoch - 587ms/step\n",
      "Epoch 81/250\n",
      "6/6 - 3s - loss: 1.2524 - accuracy: 0.5641 - val_loss: 1.4457 - val_accuracy: 0.5310 - 3s/epoch - 454ms/step\n",
      "Epoch 82/250\n",
      "6/6 - 3s - loss: 1.2551 - accuracy: 0.5583 - val_loss: 1.4116 - val_accuracy: 0.5194 - 3s/epoch - 448ms/step\n",
      "Epoch 83/250\n",
      "6/6 - 3s - loss: 1.2402 - accuracy: 0.5728 - val_loss: 1.4038 - val_accuracy: 0.5155 - 3s/epoch - 447ms/step\n",
      "Epoch 84/250\n",
      "6/6 - 4s - loss: 1.2351 - accuracy: 0.5612 - val_loss: 1.4210 - val_accuracy: 0.5426 - 4s/epoch - 600ms/step\n",
      "Epoch 85/250\n",
      "6/6 - 3s - loss: 1.2337 - accuracy: 0.5748 - val_loss: 1.4111 - val_accuracy: 0.5271 - 3s/epoch - 449ms/step\n",
      "Epoch 86/250\n",
      "6/6 - 3s - loss: 1.2224 - accuracy: 0.5718 - val_loss: 1.3870 - val_accuracy: 0.5116 - 3s/epoch - 453ms/step\n",
      "Epoch 87/250\n",
      "6/6 - 3s - loss: 1.2160 - accuracy: 0.5806 - val_loss: 1.4513 - val_accuracy: 0.4922 - 3s/epoch - 450ms/step\n",
      "Epoch 88/250\n",
      "6/6 - 3s - loss: 1.2375 - accuracy: 0.5641 - val_loss: 1.3838 - val_accuracy: 0.5078 - 3s/epoch - 554ms/step\n",
      "Epoch 89/250\n",
      "6/6 - 3s - loss: 1.2193 - accuracy: 0.5748 - val_loss: 1.3655 - val_accuracy: 0.5465 - 3s/epoch - 481ms/step\n",
      "Epoch 90/250\n",
      "6/6 - 3s - loss: 1.1950 - accuracy: 0.5835 - val_loss: 1.3844 - val_accuracy: 0.5388 - 3s/epoch - 455ms/step\n",
      "Epoch 91/250\n",
      "6/6 - 3s - loss: 1.2009 - accuracy: 0.5816 - val_loss: 1.3734 - val_accuracy: 0.5620 - 3s/epoch - 446ms/step\n",
      "Epoch 92/250\n",
      "6/6 - 3s - loss: 1.2181 - accuracy: 0.5854 - val_loss: 1.4107 - val_accuracy: 0.5000 - 3s/epoch - 506ms/step\n",
      "Epoch 93/250\n",
      "6/6 - 3s - loss: 1.1963 - accuracy: 0.5845 - val_loss: 1.3643 - val_accuracy: 0.5581 - 3s/epoch - 524ms/step\n",
      "Epoch 94/250\n",
      "6/6 - 3s - loss: 1.1954 - accuracy: 0.5854 - val_loss: 1.3938 - val_accuracy: 0.5194 - 3s/epoch - 451ms/step\n",
      "Epoch 95/250\n",
      "6/6 - 3s - loss: 1.1916 - accuracy: 0.6029 - val_loss: 1.3590 - val_accuracy: 0.5271 - 3s/epoch - 451ms/step\n",
      "Epoch 96/250\n",
      "6/6 - 3s - loss: 1.1876 - accuracy: 0.5951 - val_loss: 1.3475 - val_accuracy: 0.5543 - 3s/epoch - 458ms/step\n",
      "Epoch 97/250\n",
      "Epoch 98/250\n",
      "6/6 - 3s - loss: 1.1724 - accuracy: 0.5922 - val_loss: 1.3708 - val_accuracy: 0.5426 - 3s/epoch - 450ms/step\n",
      "Epoch 99/250\n",
      "6/6 - 3s - loss: 1.1600 - accuracy: 0.6058 - val_loss: 1.3377 - val_accuracy: 0.5310 - 3s/epoch - 448ms/step\n",
      "Epoch 100/250\n",
      "6/6 - 3s - loss: 1.1769 - accuracy: 0.5893 - val_loss: 1.3346 - val_accuracy: 0.5543 - 3s/epoch - 445ms/step\n",
      "Epoch 101/250\n",
      "6/6 - 4s - loss: 1.1303 - accuracy: 0.6194 - val_loss: 1.3100 - val_accuracy: 0.5388 - 4s/epoch - 584ms/step\n",
      "Epoch 102/250\n",
      "6/6 - 3s - loss: 1.1477 - accuracy: 0.6010 - val_loss: 1.3258 - val_accuracy: 0.5543 - 3s/epoch - 446ms/step\n",
      "Epoch 103/250\n",
      "6/6 - 3s - loss: 1.1299 - accuracy: 0.6136 - val_loss: 1.3356 - val_accuracy: 0.5543 - 3s/epoch - 449ms/step\n",
      "Epoch 104/250\n",
      "6/6 - 3s - loss: 1.1377 - accuracy: 0.6146 - val_loss: 1.3224 - val_accuracy: 0.5155 - 3s/epoch - 450ms/step\n",
      "Epoch 105/250\n",
      "6/6 - 4s - loss: 1.1605 - accuracy: 0.5971 - val_loss: 1.3089 - val_accuracy: 0.5620 - 4s/epoch - 584ms/step\n",
      "Epoch 106/250\n",
      "6/6 - 3s - loss: 1.1278 - accuracy: 0.6136 - val_loss: 1.2966 - val_accuracy: 0.5504 - 3s/epoch - 448ms/step\n",
      "Epoch 107/250\n",
      "6/6 - 3s - loss: 1.1204 - accuracy: 0.6097 - val_loss: 1.3248 - val_accuracy: 0.5504 - 3s/epoch - 447ms/step\n",
      "Epoch 108/250\n",
      "6/6 - 3s - loss: 1.1155 - accuracy: 0.6204 - val_loss: 1.3097 - val_accuracy: 0.5620 - 3s/epoch - 449ms/step\n",
      "Epoch 109/250\n",
      "6/6 - 4s - loss: 1.0999 - accuracy: 0.6262 - val_loss: 1.2985 - val_accuracy: 0.5310 - 4s/epoch - 588ms/step\n",
      "Epoch 110/250\n",
      "6/6 - 3s - loss: 1.1256 - accuracy: 0.5981 - val_loss: 1.2841 - val_accuracy: 0.5659 - 3s/epoch - 452ms/step\n",
      "Epoch 111/250\n",
      "6/6 - 3s - loss: 1.1137 - accuracy: 0.6136 - val_loss: 1.2868 - val_accuracy: 0.5698 - 3s/epoch - 452ms/step\n",
      "Epoch 112/250\n",
      "6/6 - 3s - loss: 1.1303 - accuracy: 0.6097 - val_loss: 1.3215 - val_accuracy: 0.5194 - 3s/epoch - 451ms/step\n",
      "Epoch 113/250\n",
      "6/6 - 4s - loss: 1.1322 - accuracy: 0.5981 - val_loss: 1.2813 - val_accuracy: 0.5659 - 4s/epoch - 600ms/step\n",
      "Epoch 114/250\n",
      "6/6 - 3s - loss: 1.0888 - accuracy: 0.6330 - val_loss: 1.2998 - val_accuracy: 0.5659 - 3s/epoch - 450ms/step\n",
      "Epoch 115/250\n",
      "6/6 - 3s - loss: 1.0836 - accuracy: 0.6282 - val_loss: 1.2762 - val_accuracy: 0.5698 - 3s/epoch - 449ms/step\n",
      "Epoch 116/250\n",
      "6/6 - 3s - loss: 1.0737 - accuracy: 0.6282 - val_loss: 1.2767 - val_accuracy: 0.5426 - 3s/epoch - 456ms/step\n",
      "Epoch 117/250\n",
      "6/6 - 3s - loss: 1.0850 - accuracy: 0.6340 - val_loss: 1.2881 - val_accuracy: 0.5620 - 3s/epoch - 532ms/step\n",
      "Epoch 118/250\n",
      "6/6 - 3s - loss: 1.0962 - accuracy: 0.6311 - val_loss: 1.2520 - val_accuracy: 0.5736 - 3s/epoch - 504ms/step\n",
      "Epoch 119/250\n",
      "6/6 - 3s - loss: 1.0666 - accuracy: 0.6379 - val_loss: 1.3191 - val_accuracy: 0.5388 - 3s/epoch - 452ms/step\n",
      "Epoch 120/250\n",
      "6/6 - 3s - loss: 1.1007 - accuracy: 0.6311 - val_loss: 1.2805 - val_accuracy: 0.5543 - 3s/epoch - 460ms/step\n",
      "Epoch 121/250\n",
      "6/6 - 3s - loss: 1.0821 - accuracy: 0.6282 - val_loss: 1.2710 - val_accuracy: 0.5620 - 3s/epoch - 492ms/step\n",
      "Epoch 122/250\n",
      "6/6 - 3s - loss: 1.0528 - accuracy: 0.6359 - val_loss: 1.2757 - val_accuracy: 0.5465 - 3s/epoch - 550ms/step\n",
      "Epoch 123/250\n",
      "6/6 - 3s - loss: 1.0688 - accuracy: 0.6311 - val_loss: 1.2398 - val_accuracy: 0.5659 - 3s/epoch - 455ms/step\n",
      "Epoch 124/250\n",
      "6/6 - 3s - loss: 1.0699 - accuracy: 0.6388 - val_loss: 1.2226 - val_accuracy: 0.5736 - 3s/epoch - 451ms/step\n",
      "Epoch 125/250\n",
      "6/6 - 3s - loss: 1.0565 - accuracy: 0.6447 - val_loss: 1.2343 - val_accuracy: 0.5698 - 3s/epoch - 476ms/step\n",
      "Epoch 126/250\n",
      "6/6 - 4s - loss: 1.0436 - accuracy: 0.6408 - val_loss: 1.2496 - val_accuracy: 0.5736 - 4s/epoch - 584ms/step\n",
      "Epoch 127/250\n",
      "6/6 - 3s - loss: 1.0445 - accuracy: 0.6379 - val_loss: 1.2222 - val_accuracy: 0.5698 - 3s/epoch - 450ms/step\n",
      "Epoch 128/250\n",
      "6/6 - 3s - loss: 1.0465 - accuracy: 0.6359 - val_loss: 1.2107 - val_accuracy: 0.5698 - 3s/epoch - 448ms/step\n",
      "Epoch 129/250\n",
      "6/6 - 3s - loss: 1.0353 - accuracy: 0.6369 - val_loss: 1.2243 - val_accuracy: 0.5620 - 3s/epoch - 459ms/step\n",
      "Epoch 130/250\n",
      "6/6 - 4s - loss: 1.0180 - accuracy: 0.6553 - val_loss: 1.2352 - val_accuracy: 0.5736 - 4s/epoch - 591ms/step\n",
      "Epoch 131/250\n",
      "6/6 - 3s - loss: 1.0486 - accuracy: 0.6330 - val_loss: 1.2091 - val_accuracy: 0.5736 - 3s/epoch - 451ms/step\n",
      "Epoch 132/250\n",
      "6/6 - 3s - loss: 1.0279 - accuracy: 0.6466 - val_loss: 1.2419 - val_accuracy: 0.5581 - 3s/epoch - 453ms/step\n",
      "Epoch 133/250\n",
      "6/6 - 3s - loss: 1.0135 - accuracy: 0.6427 - val_loss: 1.2066 - val_accuracy: 0.5736 - 3s/epoch - 449ms/step\n",
      "Epoch 134/250\n",
      "6/6 - 4s - loss: 1.0229 - accuracy: 0.6573 - val_loss: 1.2112 - val_accuracy: 0.5620 - 4s/epoch - 587ms/step\n",
      "Epoch 135/250\n",
      "6/6 - 3s - loss: 1.0181 - accuracy: 0.6388 - val_loss: 1.2110 - val_accuracy: 0.5775 - 3s/epoch - 447ms/step\n",
      "Epoch 136/250\n",
      "6/6 - 3s - loss: 0.9991 - accuracy: 0.6495 - val_loss: 1.1910 - val_accuracy: 0.5659 - 3s/epoch - 450ms/step\n",
      "Epoch 137/250\n",
      "6/6 - 3s - loss: 0.9913 - accuracy: 0.6515 - val_loss: 1.1907 - val_accuracy: 0.5891 - 3s/epoch - 448ms/step\n",
      "Epoch 138/250\n",
      "6/6 - 4s - loss: 1.0075 - accuracy: 0.6524 - val_loss: 1.1840 - val_accuracy: 0.5736 - 4s/epoch - 585ms/step\n",
      "Epoch 139/250\n",
      "6/6 - 3s - loss: 1.0041 - accuracy: 0.6417 - val_loss: 1.2090 - val_accuracy: 0.5620 - 3s/epoch - 450ms/step\n",
      "Epoch 140/250\n",
      "6/6 - 3s - loss: 0.9899 - accuracy: 0.6553 - val_loss: 1.2168 - val_accuracy: 0.5698 - 3s/epoch - 451ms/step\n",
      "Epoch 141/250\n",
      "6/6 - 3s - loss: 0.9852 - accuracy: 0.6602 - val_loss: 1.1676 - val_accuracy: 0.5853 - 3s/epoch - 458ms/step\n",
      "Epoch 142/250\n",
      "6/6 - 4s - loss: 0.9720 - accuracy: 0.6641 - val_loss: 1.1602 - val_accuracy: 0.6008 - 4s/epoch - 604ms/step\n",
      "Epoch 143/250\n",
      "6/6 - 3s - loss: 0.9795 - accuracy: 0.6612 - val_loss: 1.1809 - val_accuracy: 0.5814 - 3s/epoch - 446ms/step\n",
      "Epoch 144/250\n",
      "6/6 - 3s - loss: 0.9739 - accuracy: 0.6621 - val_loss: 1.1750 - val_accuracy: 0.5775 - 3s/epoch - 554ms/step\n",
      "Epoch 145/250\n",
      "6/6 - 4s - loss: 0.9716 - accuracy: 0.6621 - val_loss: 1.1779 - val_accuracy: 0.5930 - 4s/epoch - 593ms/step\n",
      "Epoch 146/250\n",
      "6/6 - 4s - loss: 0.9576 - accuracy: 0.6767 - val_loss: 1.1620 - val_accuracy: 0.6008 - 4s/epoch - 699ms/step\n",
      "Epoch 147/250\n",
      "6/6 - 3s - loss: 0.9752 - accuracy: 0.6728 - val_loss: 1.1837 - val_accuracy: 0.5969 - 3s/epoch - 457ms/step\n",
      "Epoch 148/250\n",
      "6/6 - 3s - loss: 0.9670 - accuracy: 0.6602 - val_loss: 1.1608 - val_accuracy: 0.5891 - 3s/epoch - 455ms/step\n",
      "Epoch 149/250\n",
      "6/6 - 3s - loss: 0.9408 - accuracy: 0.6767 - val_loss: 1.1814 - val_accuracy: 0.5969 - 3s/epoch - 454ms/step\n",
      "Epoch 150/250\n",
      "6/6 - 3s - loss: 0.9506 - accuracy: 0.6777 - val_loss: 1.1508 - val_accuracy: 0.6085 - 3s/epoch - 545ms/step\n",
      "Epoch 151/250\n",
      "6/6 - 3s - loss: 0.9540 - accuracy: 0.6660 - val_loss: 1.1219 - val_accuracy: 0.6008 - 3s/epoch - 458ms/step\n",
      "Epoch 152/250\n",
      "6/6 - 3s - loss: 0.9646 - accuracy: 0.6709 - val_loss: 1.1622 - val_accuracy: 0.5853 - 3s/epoch - 447ms/step\n",
      "Epoch 153/250\n",
      "6/6 - 3s - loss: 0.9603 - accuracy: 0.6699 - val_loss: 1.1522 - val_accuracy: 0.5814 - 3s/epoch - 450ms/step\n",
      "Epoch 154/250\n",
      "6/6 - 3s - loss: 0.9438 - accuracy: 0.6689 - val_loss: 1.1278 - val_accuracy: 0.5969 - 3s/epoch - 539ms/step\n",
      "Epoch 155/250\n",
      "6/6 - 3s - loss: 0.9321 - accuracy: 0.6757 - val_loss: 1.1196 - val_accuracy: 0.6163 - 3s/epoch - 451ms/step\n",
      "Epoch 156/250\n",
      "6/6 - 3s - loss: 0.9325 - accuracy: 0.6786 - val_loss: 1.1024 - val_accuracy: 0.6318 - 3s/epoch - 448ms/step\n",
      "Epoch 157/250\n",
      "6/6 - 3s - loss: 0.8964 - accuracy: 0.6990 - val_loss: 1.1360 - val_accuracy: 0.5698 - 3s/epoch - 445ms/step\n",
      "Epoch 158/250\n",
      "6/6 - 3s - loss: 0.9047 - accuracy: 0.6854 - val_loss: 1.1081 - val_accuracy: 0.6163 - 3s/epoch - 543ms/step\n",
      "Epoch 159/250\n",
      "6/6 - 3s - loss: 0.9315 - accuracy: 0.6845 - val_loss: 1.1209 - val_accuracy: 0.6008 - 3s/epoch - 445ms/step\n",
      "Epoch 160/250\n",
      "6/6 - 3s - loss: 0.9227 - accuracy: 0.6913 - val_loss: 1.1131 - val_accuracy: 0.6085 - 3s/epoch - 451ms/step\n",
      "Epoch 161/250\n",
      "6/6 - 3s - loss: 0.8984 - accuracy: 0.6922 - val_loss: 1.1112 - val_accuracy: 0.6085 - 3s/epoch - 447ms/step\n",
      "Epoch 162/250\n",
      "6/6 - 3s - loss: 0.8855 - accuracy: 0.6942 - val_loss: 1.1146 - val_accuracy: 0.6163 - 3s/epoch - 544ms/step\n",
      "Epoch 163/250\n",
      "6/6 - 3s - loss: 0.8894 - accuracy: 0.6971 - val_loss: 1.1030 - val_accuracy: 0.6202 - 3s/epoch - 448ms/step\n",
      "Epoch 164/250\n",
      "6/6 - 3s - loss: 0.8898 - accuracy: 0.6825 - val_loss: 1.1144 - val_accuracy: 0.6279 - 3s/epoch - 459ms/step\n",
      "Epoch 165/250\n",
      "6/6 - 3s - loss: 0.8894 - accuracy: 0.6981 - val_loss: 1.1044 - val_accuracy: 0.6124 - 3s/epoch - 452ms/step\n",
      "Epoch 166/250\n",
      "6/6 - 3s - loss: 0.9067 - accuracy: 0.6922 - val_loss: 1.0776 - val_accuracy: 0.6395 - 3s/epoch - 544ms/step\n",
      "Epoch 167/250\n",
      "6/6 - 3s - loss: 0.9460 - accuracy: 0.6641 - val_loss: 1.0891 - val_accuracy: 0.6318 - 3s/epoch - 449ms/step\n",
      "Epoch 168/250\n",
      "6/6 - 3s - loss: 0.9019 - accuracy: 0.6796 - val_loss: 1.1110 - val_accuracy: 0.6047 - 3s/epoch - 444ms/step\n",
      "Epoch 169/250\n",
      "6/6 - 3s - loss: 0.8748 - accuracy: 0.6971 - val_loss: 1.0801 - val_accuracy: 0.6279 - 3s/epoch - 451ms/step\n",
      "Epoch 170/250\n",
      "6/6 - 3s - loss: 0.8797 - accuracy: 0.6942 - val_loss: 1.1606 - val_accuracy: 0.5775 - 3s/epoch - 540ms/step\n",
      "Epoch 171/250\n",
      "6/6 - 3s - loss: 0.8955 - accuracy: 0.6835 - val_loss: 1.0976 - val_accuracy: 0.6434 - 3s/epoch - 450ms/step\n",
      "Epoch 172/250\n",
      "6/6 - 3s - loss: 0.8575 - accuracy: 0.7097 - val_loss: 1.0838 - val_accuracy: 0.6357 - 3s/epoch - 447ms/step\n",
      "Epoch 173/250\n",
      "6/6 - 3s - loss: 0.8671 - accuracy: 0.7010 - val_loss: 1.0728 - val_accuracy: 0.6628 - 3s/epoch - 449ms/step\n",
      "Epoch 174/250\n",
      "6/6 - 3s - loss: 0.8534 - accuracy: 0.7126 - val_loss: 1.0494 - val_accuracy: 0.6512 - 3s/epoch - 543ms/step\n",
      "Epoch 175/250\n",
      "6/6 - 3s - loss: 0.8542 - accuracy: 0.6971 - val_loss: 1.0765 - val_accuracy: 0.6473 - 3s/epoch - 455ms/step\n",
      "Epoch 176/250\n",
      "6/6 - 3s - loss: 0.8858 - accuracy: 0.6990 - val_loss: 1.0916 - val_accuracy: 0.6357 - 3s/epoch - 453ms/step\n",
      "Epoch 177/250\n",
      "6/6 - 3s - loss: 0.8680 - accuracy: 0.7078 - val_loss: 1.0913 - val_accuracy: 0.6047 - 3s/epoch - 449ms/step\n",
      "Epoch 178/250\n",
      "6/6 - 3s - loss: 0.8586 - accuracy: 0.7049 - val_loss: 1.0948 - val_accuracy: 0.6202 - 3s/epoch - 539ms/step\n",
      "Epoch 179/250\n",
      "6/6 - 3s - loss: 0.8681 - accuracy: 0.6854 - val_loss: 1.0821 - val_accuracy: 0.6163 - 3s/epoch - 451ms/step\n",
      "Epoch 180/250\n",
      "6/6 - 3s - loss: 0.8632 - accuracy: 0.6893 - val_loss: 1.0890 - val_accuracy: 0.6434 - 3s/epoch - 475ms/step\n",
      "Epoch 181/250\n",
      "6/6 - 3s - loss: 0.8352 - accuracy: 0.7097 - val_loss: 1.0707 - val_accuracy: 0.6124 - 3s/epoch - 449ms/step\n",
      "Epoch 182/250\n",
      "6/6 - 3s - loss: 0.8261 - accuracy: 0.7233 - val_loss: 1.0417 - val_accuracy: 0.6705 - 3s/epoch - 543ms/step\n",
      "Epoch 183/250\n",
      "6/6 - 3s - loss: 0.8118 - accuracy: 0.7223 - val_loss: 1.0413 - val_accuracy: 0.6589 - 3s/epoch - 450ms/step\n",
      "Epoch 184/250\n",
      "6/6 - 3s - loss: 0.8247 - accuracy: 0.7243 - val_loss: 1.0557 - val_accuracy: 0.6395 - 3s/epoch - 447ms/step\n",
      "Epoch 185/250\n",
      "6/6 - 3s - loss: 0.8096 - accuracy: 0.7068 - val_loss: 1.0602 - val_accuracy: 0.6395 - 3s/epoch - 453ms/step\n",
      "Epoch 186/250\n",
      "6/6 - 3s - loss: 0.8030 - accuracy: 0.7233 - val_loss: 1.0255 - val_accuracy: 0.6628 - 3s/epoch - 536ms/step\n",
      "Epoch 187/250\n",
      "6/6 - 3s - loss: 0.7881 - accuracy: 0.7379 - val_loss: 1.0433 - val_accuracy: 0.6434 - 3s/epoch - 450ms/step\n",
      "Epoch 188/250\n",
      "6/6 - 3s - loss: 0.7862 - accuracy: 0.7175 - val_loss: 1.0453 - val_accuracy: 0.6357 - 3s/epoch - 447ms/step\n",
      "Epoch 189/250\n",
      "6/6 - 3s - loss: 0.7997 - accuracy: 0.7214 - val_loss: 1.0521 - val_accuracy: 0.6512 - 3s/epoch - 475ms/step\n",
      "Epoch 190/250\n",
      "6/6 - 3s - loss: 0.8223 - accuracy: 0.7204 - val_loss: 1.0712 - val_accuracy: 0.6512 - 3s/epoch - 545ms/step\n",
      "Epoch 191/250\n",
      "6/6 - 3s - loss: 0.8360 - accuracy: 0.7078 - val_loss: 1.0525 - val_accuracy: 0.6395 - 3s/epoch - 451ms/step\n",
      "Epoch 192/250\n",
      "6/6 - 3s - loss: 0.8182 - accuracy: 0.7117 - val_loss: 1.0407 - val_accuracy: 0.6667 - 3s/epoch - 446ms/step\n",
      "Epoch 193/250\n",
      "6/6 - 3s - loss: 0.8162 - accuracy: 0.7078 - val_loss: 1.0428 - val_accuracy: 0.6434 - 3s/epoch - 444ms/step\n",
      "Epoch 194/250\n",
      "6/6 - 3s - loss: 0.7901 - accuracy: 0.7291 - val_loss: 1.0190 - val_accuracy: 0.6667 - 3s/epoch - 541ms/step\n",
      "Epoch 195/250\n",
      "6/6 - 3s - loss: 0.7604 - accuracy: 0.7456 - val_loss: 1.0253 - val_accuracy: 0.6822 - 3s/epoch - 445ms/step\n",
      "Epoch 196/250\n",
      "6/6 - 3s - loss: 0.7660 - accuracy: 0.7359 - val_loss: 1.0087 - val_accuracy: 0.6667 - 3s/epoch - 444ms/step\n",
      "Epoch 197/250\n",
      "6/6 - 3s - loss: 0.7767 - accuracy: 0.7437 - val_loss: 1.0354 - val_accuracy: 0.6473 - 3s/epoch - 469ms/step\n",
      "Epoch 198/250\n",
      "6/6 - 3s - loss: 0.7700 - accuracy: 0.7388 - val_loss: 1.0010 - val_accuracy: 0.6744 - 3s/epoch - 538ms/step\n",
      "Epoch 199/250\n",
      "6/6 - 3s - loss: 0.7803 - accuracy: 0.7437 - val_loss: 1.0053 - val_accuracy: 0.6899 - 3s/epoch - 448ms/step\n",
      "Epoch 200/250\n",
      "6/6 - 3s - loss: 0.7488 - accuracy: 0.7534 - val_loss: 1.0193 - val_accuracy: 0.6938 - 3s/epoch - 444ms/step\n",
      "Epoch 201/250\n",
      "6/6 - 3s - loss: 0.7572 - accuracy: 0.7282 - val_loss: 0.9985 - val_accuracy: 0.6938 - 3s/epoch - 445ms/step\n",
      "Epoch 202/250\n",
      "6/6 - 3s - loss: 0.7480 - accuracy: 0.7524 - val_loss: 1.0072 - val_accuracy: 0.6822 - 3s/epoch - 542ms/step\n",
      "Epoch 203/250\n",
      "6/6 - 3s - loss: 0.7452 - accuracy: 0.7534 - val_loss: 0.9959 - val_accuracy: 0.6822 - 3s/epoch - 449ms/step\n",
      "Epoch 204/250\n",
      "6/6 - 3s - loss: 0.7461 - accuracy: 0.7369 - val_loss: 0.9904 - val_accuracy: 0.6705 - 3s/epoch - 445ms/step\n",
      "Epoch 205/250\n",
      "6/6 - 3s - loss: 0.7536 - accuracy: 0.7369 - val_loss: 1.0039 - val_accuracy: 0.6977 - 3s/epoch - 449ms/step\n",
      "Epoch 206/250\n",
      "6/6 - 3s - loss: 0.7667 - accuracy: 0.7359 - val_loss: 1.0119 - val_accuracy: 0.6705 - 3s/epoch - 540ms/step\n",
      "Epoch 207/250\n",
      "6/6 - 3s - loss: 0.7403 - accuracy: 0.7524 - val_loss: 1.0101 - val_accuracy: 0.6705 - 3s/epoch - 444ms/step\n",
      "Epoch 208/250\n",
      "6/6 - 3s - loss: 0.7404 - accuracy: 0.7447 - val_loss: 0.9962 - val_accuracy: 0.7132 - 3s/epoch - 450ms/step\n",
      "Epoch 209/250\n",
      "6/6 - 3s - loss: 0.7169 - accuracy: 0.7485 - val_loss: 0.9897 - val_accuracy: 0.6938 - 3s/epoch - 445ms/step\n",
      "Epoch 210/250\n",
      "6/6 - 3s - loss: 0.7176 - accuracy: 0.7485 - val_loss: 0.9773 - val_accuracy: 0.7016 - 3s/epoch - 544ms/step\n",
      "Epoch 211/250\n",
      "6/6 - 3s - loss: 0.7273 - accuracy: 0.7485 - val_loss: 0.9713 - val_accuracy: 0.7093 - 3s/epoch - 452ms/step\n",
      "Epoch 212/250\n",
      "6/6 - 3s - loss: 0.7057 - accuracy: 0.7544 - val_loss: 0.9815 - val_accuracy: 0.7016 - 3s/epoch - 453ms/step\n",
      "Epoch 213/250\n",
      "6/6 - 3s - loss: 0.6857 - accuracy: 0.7660 - val_loss: 1.0120 - val_accuracy: 0.6667 - 3s/epoch - 450ms/step\n",
      "Epoch 214/250\n",
      "6/6 - 3s - loss: 0.7252 - accuracy: 0.7456 - val_loss: 0.9890 - val_accuracy: 0.6977 - 3s/epoch - 546ms/step\n",
      "Epoch 215/250\n",
      "6/6 - 3s - loss: 0.7069 - accuracy: 0.7495 - val_loss: 0.9730 - val_accuracy: 0.7016 - 3s/epoch - 447ms/step\n",
      "Epoch 216/250\n",
      "6/6 - 3s - loss: 0.7048 - accuracy: 0.7583 - val_loss: 0.9778 - val_accuracy: 0.7054 - 3s/epoch - 449ms/step\n",
      "Epoch 217/250\n",
      "6/6 - 3s - loss: 0.7024 - accuracy: 0.7544 - val_loss: 0.9826 - val_accuracy: 0.6899 - 3s/epoch - 455ms/step\n",
      "Epoch 218/250\n",
      "6/6 - 3s - loss: 0.6966 - accuracy: 0.7718 - val_loss: 0.9923 - val_accuracy: 0.6822 - 3s/epoch - 546ms/step\n",
      "Epoch 219/250\n",
      "6/6 - 3s - loss: 0.7032 - accuracy: 0.7689 - val_loss: 0.9796 - val_accuracy: 0.6977 - 3s/epoch - 454ms/step\n",
      "Epoch 220/250\n",
      "6/6 - 3s - loss: 0.6981 - accuracy: 0.7621 - val_loss: 0.9914 - val_accuracy: 0.6860 - 3s/epoch - 454ms/step\n",
      "Epoch 221/250\n",
      "6/6 - 3s - loss: 0.6961 - accuracy: 0.7699 - val_loss: 0.9676 - val_accuracy: 0.7054 - 3s/epoch - 450ms/step\n",
      "Epoch 222/250\n",
      "6/6 - 3s - loss: 0.6926 - accuracy: 0.7621 - val_loss: 0.9826 - val_accuracy: 0.7016 - 3s/epoch - 541ms/step\n",
      "Epoch 223/250\n",
      "6/6 - 3s - loss: 0.6735 - accuracy: 0.7757 - val_loss: 0.9624 - val_accuracy: 0.7171 - 3s/epoch - 456ms/step\n",
      "Epoch 224/250\n",
      "6/6 - 3s - loss: 0.6824 - accuracy: 0.7699 - val_loss: 0.9909 - val_accuracy: 0.6860 - 3s/epoch - 455ms/step\n",
      "Epoch 225/250\n",
      "6/6 - 3s - loss: 0.6867 - accuracy: 0.7689 - val_loss: 0.9614 - val_accuracy: 0.7287 - 3s/epoch - 451ms/step\n",
      "Epoch 226/250\n",
      "6/6 - 3s - loss: 0.6846 - accuracy: 0.7689 - val_loss: 0.9751 - val_accuracy: 0.7093 - 3s/epoch - 549ms/step\n",
      "Epoch 227/250\n",
      "6/6 - 3s - loss: 0.6690 - accuracy: 0.7689 - val_loss: 0.9852 - val_accuracy: 0.7054 - 3s/epoch - 451ms/step\n",
      "Epoch 228/250\n",
      "6/6 - 3s - loss: 0.6396 - accuracy: 0.7913 - val_loss: 0.9738 - val_accuracy: 0.7093 - 3s/epoch - 448ms/step\n",
      "Epoch 229/250\n",
      "6/6 - 3s - loss: 0.6516 - accuracy: 0.7689 - val_loss: 0.9696 - val_accuracy: 0.7132 - 3s/epoch - 452ms/step\n",
      "Epoch 230/250\n",
      "6/6 - 3s - loss: 0.6600 - accuracy: 0.7816 - val_loss: 0.9782 - val_accuracy: 0.6860 - 3s/epoch - 550ms/step\n",
      "Epoch 231/250\n",
      "6/6 - 3s - loss: 0.6513 - accuracy: 0.7767 - val_loss: 0.9476 - val_accuracy: 0.7248 - 3s/epoch - 458ms/step\n",
      "Epoch 232/250\n",
      "6/6 - 3s - loss: 0.6629 - accuracy: 0.7748 - val_loss: 0.9533 - val_accuracy: 0.7093 - 3s/epoch - 451ms/step\n",
      "Epoch 233/250\n",
      "6/6 - 3s - loss: 0.6499 - accuracy: 0.7777 - val_loss: 0.9794 - val_accuracy: 0.7016 - 3s/epoch - 449ms/step\n",
      "Epoch 234/250\n",
      "6/6 - 3s - loss: 0.6652 - accuracy: 0.7612 - val_loss: 0.9362 - val_accuracy: 0.7364 - 3s/epoch - 551ms/step\n",
      "Epoch 235/250\n",
      "6/6 - 3s - loss: 0.6572 - accuracy: 0.7796 - val_loss: 0.9595 - val_accuracy: 0.7132 - 3s/epoch - 448ms/step\n",
      "Epoch 236/250\n",
      "6/6 - 3s - loss: 0.6565 - accuracy: 0.7757 - val_loss: 0.9582 - val_accuracy: 0.7248 - 3s/epoch - 452ms/step\n",
      "Epoch 237/250\n",
      "6/6 - 3s - loss: 0.6493 - accuracy: 0.7932 - val_loss: 0.9975 - val_accuracy: 0.6977 - 3s/epoch - 478ms/step\n",
      "Epoch 238/250\n",
      "6/6 - 3s - loss: 0.6392 - accuracy: 0.7786 - val_loss: 0.9572 - val_accuracy: 0.7171 - 3s/epoch - 545ms/step\n",
      "Epoch 239/250\n",
      "6/6 - 3s - loss: 0.6459 - accuracy: 0.7806 - val_loss: 0.9712 - val_accuracy: 0.7093 - 3s/epoch - 449ms/step\n",
      "Epoch 240/250\n",
      "6/6 - 3s - loss: 0.6395 - accuracy: 0.7709 - val_loss: 0.9537 - val_accuracy: 0.7209 - 3s/epoch - 449ms/step\n",
      "Epoch 241/250\n",
      "6/6 - 3s - loss: 0.6353 - accuracy: 0.7796 - val_loss: 0.9771 - val_accuracy: 0.7132 - 3s/epoch - 492ms/step\n",
      "Epoch 242/250\n",
      "6/6 - 3s - loss: 0.6215 - accuracy: 0.7874 - val_loss: 0.9636 - val_accuracy: 0.7093 - 3s/epoch - 540ms/step\n",
      "Epoch 243/250\n",
      "6/6 - 3s - loss: 0.6398 - accuracy: 0.7932 - val_loss: 0.9530 - val_accuracy: 0.7248 - 3s/epoch - 450ms/step\n",
      "Epoch 244/250\n",
      "6/6 - 3s - loss: 0.6416 - accuracy: 0.7757 - val_loss: 0.9599 - val_accuracy: 0.7054 - 3s/epoch - 449ms/step\n",
      "Epoch 245/250\n",
      "6/6 - 3s - loss: 0.6373 - accuracy: 0.7922 - val_loss: 0.9520 - val_accuracy: 0.7171 - 3s/epoch - 456ms/step\n",
      "Epoch 246/250\n",
      "6/6 - 3s - loss: 0.6266 - accuracy: 0.7903 - val_loss: 0.9756 - val_accuracy: 0.6899 - 3s/epoch - 543ms/step\n",
      "Epoch 247/250\n",
      "6/6 - 3s - loss: 0.6127 - accuracy: 0.7825 - val_loss: 0.9392 - val_accuracy: 0.7016 - 3s/epoch - 449ms/step\n",
      "Epoch 248/250\n",
      "6/6 - 3s - loss: 0.6283 - accuracy: 0.7816 - val_loss: 0.9476 - val_accuracy: 0.7209 - 3s/epoch - 448ms/step\n",
      "Epoch 249/250\n",
      "6/6 - 3s - loss: 0.6304 - accuracy: 0.7883 - val_loss: 0.9556 - val_accuracy: 0.7093 - 3s/epoch - 451ms/step\n",
      "Epoch 250/250\n",
      "6/6 - 3s - loss: 0.6150 - accuracy: 0.7942 - val_loss: 0.9704 - val_accuracy: 0.7248 - 3s/epoch - 545ms/step\n",
      "9/9 [==============================] - 0s 22ms/step\n",
      "Epoch 1/250\n",
      "6/6 - 3s - loss: 1.8841 - accuracy: 0.3602 - val_loss: 1.7792 - val_accuracy: 0.3876 - 3s/epoch - 422ms/step\n",
      "Epoch 2/250\n",
      "6/6 - 2s - loss: 1.7202 - accuracy: 0.4175 - val_loss: 1.7395 - val_accuracy: 0.3876 - 2s/epoch - 279ms/step\n",
      "Epoch 3/250\n",
      "6/6 - 2s - loss: 1.6814 - accuracy: 0.4175 - val_loss: 1.7368 - val_accuracy: 0.3876 - 2s/epoch - 287ms/step\n",
      "Epoch 4/250\n",
      "6/6 - 2s - loss: 1.6797 - accuracy: 0.4175 - val_loss: 1.7634 - val_accuracy: 0.3876 - 2s/epoch - 288ms/step\n",
      "Epoch 5/250\n",
      "6/6 - 2s - loss: 1.6737 - accuracy: 0.4175 - val_loss: 1.7390 - val_accuracy: 0.3876 - 2s/epoch - 381ms/step\n",
      "Epoch 6/250\n",
      "6/6 - 2s - loss: 1.6727 - accuracy: 0.4175 - val_loss: 1.7552 - val_accuracy: 0.3876 - 2s/epoch - 295ms/step\n",
      "Epoch 7/250\n",
      "6/6 - 2s - loss: 1.6772 - accuracy: 0.4175 - val_loss: 1.7356 - val_accuracy: 0.3876 - 2s/epoch - 297ms/step\n",
      "Epoch 8/250\n",
      "6/6 - 2s - loss: 1.6782 - accuracy: 0.4175 - val_loss: 1.7374 - val_accuracy: 0.3876 - 2s/epoch - 288ms/step\n",
      "Epoch 9/250\n",
      "6/6 - 2s - loss: 1.6707 - accuracy: 0.4175 - val_loss: 1.7592 - val_accuracy: 0.3876 - 2s/epoch - 283ms/step\n",
      "Epoch 10/250\n",
      "6/6 - 2s - loss: 1.6745 - accuracy: 0.4175 - val_loss: 1.7355 - val_accuracy: 0.3876 - 2s/epoch - 281ms/step\n",
      "Epoch 11/250\n",
      "6/6 - 2s - loss: 1.6706 - accuracy: 0.4175 - val_loss: 1.7432 - val_accuracy: 0.3876 - 2s/epoch - 375ms/step\n",
      "Epoch 12/250\n",
      "6/6 - 2s - loss: 1.6700 - accuracy: 0.4175 - val_loss: 1.7359 - val_accuracy: 0.3876 - 2s/epoch - 285ms/step\n",
      "Epoch 13/250\n",
      "6/6 - 2s - loss: 1.6714 - accuracy: 0.4175 - val_loss: 1.7321 - val_accuracy: 0.3876 - 2s/epoch - 288ms/step\n",
      "Epoch 14/250\n",
      "6/6 - 2s - loss: 1.6795 - accuracy: 0.4175 - val_loss: 1.7327 - val_accuracy: 0.3876 - 2s/epoch - 295ms/step\n",
      "Epoch 15/250\n",
      "6/6 - 2s - loss: 1.6724 - accuracy: 0.4175 - val_loss: 1.7429 - val_accuracy: 0.3876 - 2s/epoch - 283ms/step\n",
      "Epoch 16/250\n",
      "6/6 - 2s - loss: 1.6699 - accuracy: 0.4175 - val_loss: 1.7284 - val_accuracy: 0.3876 - 2s/epoch - 285ms/step\n",
      "Epoch 17/250\n",
      "6/6 - 2s - loss: 1.6756 - accuracy: 0.4175 - val_loss: 1.7335 - val_accuracy: 0.3876 - 2s/epoch - 314ms/step\n",
      "Epoch 18/250\n",
      "6/6 - 2s - loss: 1.6728 - accuracy: 0.4175 - val_loss: 1.7469 - val_accuracy: 0.3876 - 2s/epoch - 349ms/step\n",
      "Epoch 19/250\n",
      "6/6 - 2s - loss: 1.6693 - accuracy: 0.4175 - val_loss: 1.7378 - val_accuracy: 0.3876 - 2s/epoch - 293ms/step\n",
      "Epoch 20/250\n",
      "6/6 - 2s - loss: 1.6772 - accuracy: 0.4175 - val_loss: 1.7411 - val_accuracy: 0.3876 - 2s/epoch - 286ms/step\n",
      "Epoch 21/250\n",
      "6/6 - 2s - loss: 1.6784 - accuracy: 0.4175 - val_loss: 1.7505 - val_accuracy: 0.3876 - 2s/epoch - 292ms/step\n",
      "Epoch 22/250\n",
      "6/6 - 2s - loss: 1.6712 - accuracy: 0.4175 - val_loss: 1.7339 - val_accuracy: 0.3876 - 2s/epoch - 277ms/step\n",
      "Epoch 23/250\n",
      "6/6 - 2s - loss: 1.6866 - accuracy: 0.4175 - val_loss: 1.7323 - val_accuracy: 0.3876 - 2s/epoch - 295ms/step\n",
      "Epoch 24/250\n",
      "6/6 - 2s - loss: 1.6832 - accuracy: 0.4175 - val_loss: 1.7473 - val_accuracy: 0.3876 - 2s/epoch - 390ms/step\n",
      "Epoch 25/250\n",
      "6/6 - 2s - loss: 1.6738 - accuracy: 0.4175 - val_loss: 1.7337 - val_accuracy: 0.3876 - 2s/epoch - 293ms/step\n",
      "Epoch 26/250\n",
      "6/6 - 2s - loss: 1.6727 - accuracy: 0.4175 - val_loss: 1.7367 - val_accuracy: 0.3876 - 2s/epoch - 288ms/step\n",
      "Epoch 27/250\n",
      "6/6 - 2s - loss: 1.6712 - accuracy: 0.4175 - val_loss: 1.7343 - val_accuracy: 0.3876 - 2s/epoch - 289ms/step\n",
      "Epoch 28/250\n",
      "6/6 - 2s - loss: 1.6726 - accuracy: 0.4175 - val_loss: 1.7478 - val_accuracy: 0.3876 - 2s/epoch - 287ms/step\n",
      "Epoch 29/250\n",
      "6/6 - 2s - loss: 1.6761 - accuracy: 0.4175 - val_loss: 1.7392 - val_accuracy: 0.3876 - 2s/epoch - 287ms/step\n",
      "Epoch 30/250\n",
      "6/6 - 2s - loss: 1.6789 - accuracy: 0.4175 - val_loss: 1.7336 - val_accuracy: 0.3876 - 2s/epoch - 374ms/step\n",
      "Epoch 31/250\n",
      "6/6 - 2s - loss: 1.6737 - accuracy: 0.4175 - val_loss: 1.7418 - val_accuracy: 0.3876 - 2s/epoch - 286ms/step\n",
      "Epoch 32/250\n",
      "6/6 - 2s - loss: 1.6724 - accuracy: 0.4175 - val_loss: 1.7398 - val_accuracy: 0.3876 - 2s/epoch - 286ms/step\n",
      "Epoch 33/250\n",
      "6/6 - 2s - loss: 1.6698 - accuracy: 0.4175 - val_loss: 1.7307 - val_accuracy: 0.3876 - 2s/epoch - 286ms/step\n",
      "Epoch 34/250\n",
      "6/6 - 2s - loss: 1.6703 - accuracy: 0.4175 - val_loss: 1.7359 - val_accuracy: 0.3876 - 2s/epoch - 294ms/step\n",
      "Epoch 35/250\n",
      "6/6 - 2s - loss: 1.6691 - accuracy: 0.4175 - val_loss: 1.7415 - val_accuracy: 0.3876 - 2s/epoch - 289ms/step\n",
      "Epoch 36/250\n",
      "6/6 - 2s - loss: 1.6689 - accuracy: 0.4175 - val_loss: 1.7339 - val_accuracy: 0.3876 - 2s/epoch - 384ms/step\n",
      "Epoch 37/250\n",
      "6/6 - 2s - loss: 1.6687 - accuracy: 0.4175 - val_loss: 1.7303 - val_accuracy: 0.3876 - 2s/epoch - 295ms/step\n",
      "Epoch 38/250\n",
      "6/6 - 2s - loss: 1.6693 - accuracy: 0.4175 - val_loss: 1.7335 - val_accuracy: 0.3876 - 2s/epoch - 287ms/step\n",
      "Epoch 39/250\n",
      "6/6 - 2s - loss: 1.6712 - accuracy: 0.4175 - val_loss: 1.7366 - val_accuracy: 0.3876 - 2s/epoch - 284ms/step\n",
      "Epoch 40/250\n",
      "6/6 - 2s - loss: 1.6705 - accuracy: 0.4175 - val_loss: 1.7339 - val_accuracy: 0.3876 - 2s/epoch - 297ms/step\n",
      "Epoch 41/250\n",
      "6/6 - 2s - loss: 1.6718 - accuracy: 0.4175 - val_loss: 1.7406 - val_accuracy: 0.3876 - 2s/epoch - 282ms/step\n",
      "Epoch 42/250\n",
      "6/6 - 2s - loss: 1.6700 - accuracy: 0.4175 - val_loss: 1.7547 - val_accuracy: 0.3876 - 2s/epoch - 356ms/step\n",
      "Epoch 43/250\n",
      "6/6 - 2s - loss: 1.6752 - accuracy: 0.4175 - val_loss: 1.7371 - val_accuracy: 0.3876 - 2s/epoch - 310ms/step\n",
      "Epoch 44/250\n",
      "6/6 - 2s - loss: 1.6763 - accuracy: 0.4175 - val_loss: 1.7343 - val_accuracy: 0.3876 - 2s/epoch - 277ms/step\n",
      "Epoch 45/250\n",
      "6/6 - 2s - loss: 1.6712 - accuracy: 0.4175 - val_loss: 1.7602 - val_accuracy: 0.3876 - 2s/epoch - 288ms/step\n",
      "Epoch 46/250\n",
      "6/6 - 2s - loss: 1.6729 - accuracy: 0.4175 - val_loss: 1.7402 - val_accuracy: 0.3876 - 2s/epoch - 297ms/step\n",
      "Epoch 47/250\n",
      "6/6 - 2s - loss: 1.6756 - accuracy: 0.4175 - val_loss: 1.7476 - val_accuracy: 0.3876 - 2s/epoch - 287ms/step\n",
      "Epoch 48/250\n",
      "6/6 - 2s - loss: 1.6765 - accuracy: 0.4175 - val_loss: 1.7488 - val_accuracy: 0.3876 - 2s/epoch - 293ms/step\n",
      "Epoch 49/250\n",
      "6/6 - 2s - loss: 1.6680 - accuracy: 0.4175 - val_loss: 1.7277 - val_accuracy: 0.3876 - 2s/epoch - 375ms/step\n",
      "Epoch 50/250\n",
      "6/6 - 2s - loss: 1.6793 - accuracy: 0.4175 - val_loss: 1.7271 - val_accuracy: 0.3876 - 2s/epoch - 291ms/step\n",
      "Epoch 51/250\n",
      "6/6 - 2s - loss: 1.6736 - accuracy: 0.4175 - val_loss: 1.7489 - val_accuracy: 0.3876 - 2s/epoch - 294ms/step\n",
      "Epoch 52/250\n",
      "6/6 - 2s - loss: 1.6700 - accuracy: 0.4175 - val_loss: 1.7277 - val_accuracy: 0.3876 - 2s/epoch - 293ms/step\n",
      "Epoch 53/250\n",
      "6/6 - 2s - loss: 1.6743 - accuracy: 0.4175 - val_loss: 1.7261 - val_accuracy: 0.3876 - 2s/epoch - 285ms/step\n",
      "Epoch 54/250\n",
      "6/6 - 2s - loss: 1.6693 - accuracy: 0.4175 - val_loss: 1.7389 - val_accuracy: 0.3876 - 2s/epoch - 292ms/step\n",
      "Epoch 55/250\n",
      "6/6 - 2s - loss: 1.6702 - accuracy: 0.4175 - val_loss: 1.7315 - val_accuracy: 0.3876 - 2s/epoch - 389ms/step\n",
      "Epoch 56/250\n",
      "6/6 - 2s - loss: 1.6752 - accuracy: 0.4175 - val_loss: 1.7290 - val_accuracy: 0.3876 - 2s/epoch - 282ms/step\n",
      "Epoch 57/250\n",
      "6/6 - 2s - loss: 1.6725 - accuracy: 0.4175 - val_loss: 1.7304 - val_accuracy: 0.3876 - 2s/epoch - 293ms/step\n",
      "Epoch 58/250\n",
      "6/6 - 2s - loss: 1.6669 - accuracy: 0.4175 - val_loss: 1.7369 - val_accuracy: 0.3876 - 2s/epoch - 284ms/step\n",
      "Epoch 59/250\n",
      "6/6 - 2s - loss: 1.6676 - accuracy: 0.4175 - val_loss: 1.7403 - val_accuracy: 0.3876 - 2s/epoch - 279ms/step\n",
      "Epoch 60/250\n",
      "6/6 - 2s - loss: 1.6687 - accuracy: 0.4175 - val_loss: 1.7313 - val_accuracy: 0.3876 - 2s/epoch - 296ms/step\n",
      "Epoch 61/250\n",
      "6/6 - 2s - loss: 1.6664 - accuracy: 0.4175 - val_loss: 1.7307 - val_accuracy: 0.3876 - 2s/epoch - 391ms/step\n",
      "Epoch 62/250\n",
      "6/6 - 2s - loss: 1.6667 - accuracy: 0.4175 - val_loss: 1.7229 - val_accuracy: 0.3876 - 2s/epoch - 287ms/step\n",
      "Epoch 63/250\n",
      "6/6 - 2s - loss: 1.6645 - accuracy: 0.4175 - val_loss: 1.7335 - val_accuracy: 0.3876 - 2s/epoch - 282ms/step\n",
      "Epoch 64/250\n",
      "6/6 - 2s - loss: 1.6645 - accuracy: 0.4175 - val_loss: 1.7262 - val_accuracy: 0.3876 - 2s/epoch - 282ms/step\n",
      "Epoch 65/250\n",
      "6/6 - 2s - loss: 1.6662 - accuracy: 0.4175 - val_loss: 1.7238 - val_accuracy: 0.3876 - 2s/epoch - 285ms/step\n",
      "Epoch 66/250\n",
      "6/6 - 2s - loss: 1.6567 - accuracy: 0.4175 - val_loss: 1.7315 - val_accuracy: 0.3876 - 2s/epoch - 286ms/step\n",
      "Epoch 67/250\n",
      "6/6 - 2s - loss: 1.6581 - accuracy: 0.4175 - val_loss: 1.7237 - val_accuracy: 0.3876 - 2s/epoch - 363ms/step\n",
      "Epoch 68/250\n",
      "6/6 - 2s - loss: 1.6551 - accuracy: 0.4175 - val_loss: 1.7169 - val_accuracy: 0.3876 - 2s/epoch - 307ms/step\n",
      "Epoch 69/250\n",
      "6/6 - 2s - loss: 1.6506 - accuracy: 0.4175 - val_loss: 1.7152 - val_accuracy: 0.3876 - 2s/epoch - 285ms/step\n",
      "Epoch 70/250\n",
      "6/6 - 2s - loss: 1.6464 - accuracy: 0.4175 - val_loss: 1.7345 - val_accuracy: 0.3876 - 2s/epoch - 287ms/step\n",
      "Epoch 71/250\n",
      "6/6 - 2s - loss: 1.6411 - accuracy: 0.4175 - val_loss: 1.7172 - val_accuracy: 0.3876 - 2s/epoch - 277ms/step\n",
      "Epoch 72/250\n",
      "6/6 - 2s - loss: 1.6276 - accuracy: 0.4175 - val_loss: 1.6953 - val_accuracy: 0.3876 - 2s/epoch - 287ms/step\n",
      "Epoch 73/250\n",
      "6/6 - 2s - loss: 1.6150 - accuracy: 0.4175 - val_loss: 1.6999 - val_accuracy: 0.3876 - 2s/epoch - 294ms/step\n",
      "Epoch 74/250\n",
      "6/6 - 2s - loss: 1.6097 - accuracy: 0.4175 - val_loss: 1.6868 - val_accuracy: 0.3876 - 2s/epoch - 376ms/step\n",
      "Epoch 75/250\n",
      "6/6 - 2s - loss: 1.5912 - accuracy: 0.4214 - val_loss: 1.6567 - val_accuracy: 0.3953 - 2s/epoch - 284ms/step\n",
      "Epoch 76/250\n",
      "6/6 - 2s - loss: 1.5641 - accuracy: 0.4330 - val_loss: 1.6412 - val_accuracy: 0.4031 - 2s/epoch - 285ms/step\n",
      "Epoch 77/250\n",
      "6/6 - 2s - loss: 1.5476 - accuracy: 0.4476 - val_loss: 1.6140 - val_accuracy: 0.3953 - 2s/epoch - 284ms/step\n",
      "Epoch 78/250\n",
      "6/6 - 2s - loss: 1.5307 - accuracy: 0.4350 - val_loss: 1.6023 - val_accuracy: 0.4302 - 2s/epoch - 284ms/step\n",
      "Epoch 79/250\n",
      "6/6 - 2s - loss: 1.5035 - accuracy: 0.4728 - val_loss: 1.5907 - val_accuracy: 0.4341 - 2s/epoch - 280ms/step\n",
      "Epoch 80/250\n",
      "6/6 - 2s - loss: 1.4676 - accuracy: 0.4602 - val_loss: 1.6702 - val_accuracy: 0.4457 - 2s/epoch - 375ms/step\n",
      "Epoch 81/250\n",
      "6/6 - 2s - loss: 1.4684 - accuracy: 0.4738 - val_loss: 1.5705 - val_accuracy: 0.4496 - 2s/epoch - 280ms/step\n",
      "Epoch 82/250\n",
      "6/6 - 2s - loss: 1.4588 - accuracy: 0.4728 - val_loss: 1.5351 - val_accuracy: 0.4419 - 2s/epoch - 284ms/step\n",
      "Epoch 83/250\n",
      "6/6 - 2s - loss: 1.4128 - accuracy: 0.4777 - val_loss: 1.5029 - val_accuracy: 0.4535 - 2s/epoch - 282ms/step\n",
      "Epoch 84/250\n",
      "6/6 - 2s - loss: 1.3717 - accuracy: 0.4961 - val_loss: 1.4861 - val_accuracy: 0.4535 - 2s/epoch - 281ms/step\n",
      "Epoch 85/250\n",
      "6/6 - 2s - loss: 1.3496 - accuracy: 0.5233 - val_loss: 1.4407 - val_accuracy: 0.4767 - 2s/epoch - 285ms/step\n",
      "Epoch 86/250\n",
      "6/6 - 2s - loss: 1.3314 - accuracy: 0.5126 - val_loss: 1.4397 - val_accuracy: 0.4806 - 2s/epoch - 370ms/step\n",
      "Epoch 87/250\n",
      "6/6 - 2s - loss: 1.3001 - accuracy: 0.5262 - val_loss: 1.4010 - val_accuracy: 0.4845 - 2s/epoch - 303ms/step\n",
      "Epoch 88/250\n",
      "6/6 - 2s - loss: 1.2790 - accuracy: 0.5320 - val_loss: 1.3852 - val_accuracy: 0.5116 - 2s/epoch - 294ms/step\n",
      "Epoch 89/250\n",
      "6/6 - 2s - loss: 1.2567 - accuracy: 0.5398 - val_loss: 1.3706 - val_accuracy: 0.5271 - 2s/epoch - 284ms/step\n",
      "Epoch 90/250\n",
      "6/6 - 2s - loss: 1.2375 - accuracy: 0.5553 - val_loss: 1.3409 - val_accuracy: 0.5116 - 2s/epoch - 291ms/step\n",
      "Epoch 91/250\n",
      "6/6 - 2s - loss: 1.1998 - accuracy: 0.5777 - val_loss: 1.3398 - val_accuracy: 0.5194 - 2s/epoch - 291ms/step\n",
      "Epoch 92/250\n",
      "6/6 - 2s - loss: 1.1710 - accuracy: 0.5825 - val_loss: 1.2857 - val_accuracy: 0.5581 - 2s/epoch - 344ms/step\n",
      "Epoch 93/250\n",
      "6/6 - 2s - loss: 1.1445 - accuracy: 0.5864 - val_loss: 1.2871 - val_accuracy: 0.5504 - 2s/epoch - 332ms/step\n",
      "Epoch 94/250\n",
      "6/6 - 2s - loss: 1.1343 - accuracy: 0.6136 - val_loss: 1.2784 - val_accuracy: 0.5271 - 2s/epoch - 287ms/step\n",
      "Epoch 95/250\n",
      "6/6 - 2s - loss: 1.1102 - accuracy: 0.6029 - val_loss: 1.2366 - val_accuracy: 0.5775 - 2s/epoch - 297ms/step\n",
      "Epoch 96/250\n",
      "6/6 - 2s - loss: 1.0759 - accuracy: 0.6320 - val_loss: 1.2250 - val_accuracy: 0.5581 - 2s/epoch - 280ms/step\n",
      "Epoch 97/250\n",
      "6/6 - 2s - loss: 1.0628 - accuracy: 0.6252 - val_loss: 1.1845 - val_accuracy: 0.6163 - 2s/epoch - 288ms/step\n",
      "Epoch 98/250\n",
      "6/6 - 2s - loss: 1.0546 - accuracy: 0.6408 - val_loss: 1.1646 - val_accuracy: 0.5969 - 2s/epoch - 297ms/step\n",
      "Epoch 99/250\n",
      "6/6 - 2s - loss: 1.0347 - accuracy: 0.6359 - val_loss: 1.1321 - val_accuracy: 0.6163 - 2s/epoch - 380ms/step\n",
      "Epoch 100/250\n",
      "6/6 - 2s - loss: 0.9933 - accuracy: 0.6573 - val_loss: 1.1190 - val_accuracy: 0.5891 - 2s/epoch - 285ms/step\n",
      "Epoch 101/250\n",
      "6/6 - 2s - loss: 0.9806 - accuracy: 0.6748 - val_loss: 1.1077 - val_accuracy: 0.6550 - 2s/epoch - 283ms/step\n",
      "Epoch 102/250\n",
      "6/6 - 2s - loss: 0.9861 - accuracy: 0.6553 - val_loss: 1.0563 - val_accuracy: 0.6279 - 2s/epoch - 290ms/step\n",
      "Epoch 103/250\n",
      "6/6 - 2s - loss: 0.9542 - accuracy: 0.6660 - val_loss: 1.0872 - val_accuracy: 0.6163 - 2s/epoch - 288ms/step\n",
      "Epoch 104/250\n",
      "6/6 - 2s - loss: 0.9223 - accuracy: 0.6699 - val_loss: 1.0444 - val_accuracy: 0.6550 - 2s/epoch - 289ms/step\n",
      "Epoch 105/250\n",
      "6/6 - 2s - loss: 0.9137 - accuracy: 0.6922 - val_loss: 1.0325 - val_accuracy: 0.6240 - 2s/epoch - 378ms/step\n",
      "Epoch 106/250\n",
      "6/6 - 2s - loss: 0.8887 - accuracy: 0.6728 - val_loss: 1.0308 - val_accuracy: 0.6860 - 2s/epoch - 283ms/step\n",
      "Epoch 107/250\n",
      "6/6 - 2s - loss: 0.8705 - accuracy: 0.7078 - val_loss: 1.0429 - val_accuracy: 0.6279 - 2s/epoch - 282ms/step\n",
      "Epoch 108/250\n",
      "6/6 - 2s - loss: 0.8811 - accuracy: 0.6951 - val_loss: 1.0264 - val_accuracy: 0.6473 - 2s/epoch - 291ms/step\n",
      "Epoch 109/250\n",
      "6/6 - 2s - loss: 0.8434 - accuracy: 0.7039 - val_loss: 0.9914 - val_accuracy: 0.6822 - 2s/epoch - 287ms/step\n",
      "Epoch 110/250\n",
      "6/6 - 2s - loss: 0.8456 - accuracy: 0.7078 - val_loss: 0.9918 - val_accuracy: 0.6667 - 2s/epoch - 275ms/step\n",
      "Epoch 111/250\n",
      "6/6 - 2s - loss: 0.8258 - accuracy: 0.7214 - val_loss: 0.9766 - val_accuracy: 0.6860 - 2s/epoch - 372ms/step\n",
      "Epoch 112/250\n",
      "6/6 - 2s - loss: 0.8174 - accuracy: 0.7155 - val_loss: 0.9590 - val_accuracy: 0.6938 - 2s/epoch - 294ms/step\n",
      "Epoch 113/250\n",
      "6/6 - 2s - loss: 0.7915 - accuracy: 0.7272 - val_loss: 0.9595 - val_accuracy: 0.6938 - 2s/epoch - 290ms/step\n",
      "Epoch 114/250\n",
      "6/6 - 2s - loss: 0.7914 - accuracy: 0.7204 - val_loss: 0.9606 - val_accuracy: 0.6899 - 2s/epoch - 290ms/step\n",
      "Epoch 115/250\n",
      "6/6 - 2s - loss: 0.7899 - accuracy: 0.7311 - val_loss: 0.9603 - val_accuracy: 0.6860 - 2s/epoch - 295ms/step\n",
      "Epoch 116/250\n",
      "6/6 - 2s - loss: 0.7995 - accuracy: 0.7107 - val_loss: 0.9370 - val_accuracy: 0.6938 - 2s/epoch - 290ms/step\n",
      "Epoch 117/250\n",
      "6/6 - 2s - loss: 0.7675 - accuracy: 0.7340 - val_loss: 0.9291 - val_accuracy: 0.7287 - 2s/epoch - 346ms/step\n",
      "Epoch 118/250\n",
      "6/6 - 2s - loss: 0.7516 - accuracy: 0.7417 - val_loss: 0.9196 - val_accuracy: 0.7054 - 2s/epoch - 322ms/step\n",
      "Epoch 119/250\n",
      "6/6 - 2s - loss: 0.7355 - accuracy: 0.7553 - val_loss: 0.9324 - val_accuracy: 0.7248 - 2s/epoch - 290ms/step\n",
      "Epoch 120/250\n",
      "6/6 - 2s - loss: 0.7256 - accuracy: 0.7408 - val_loss: 0.9073 - val_accuracy: 0.7171 - 2s/epoch - 287ms/step\n",
      "Epoch 121/250\n",
      "6/6 - 2s - loss: 0.7122 - accuracy: 0.7466 - val_loss: 0.9125 - val_accuracy: 0.7209 - 2s/epoch - 289ms/step\n",
      "Epoch 122/250\n",
      "6/6 - 2s - loss: 0.7166 - accuracy: 0.7592 - val_loss: 0.9117 - val_accuracy: 0.7016 - 2s/epoch - 285ms/step\n",
      "Epoch 123/250\n",
      "6/6 - 2s - loss: 0.7178 - accuracy: 0.7534 - val_loss: 0.9279 - val_accuracy: 0.6938 - 2s/epoch - 287ms/step\n",
      "Epoch 124/250\n",
      "6/6 - 2s - loss: 0.7390 - accuracy: 0.7476 - val_loss: 0.8742 - val_accuracy: 0.7132 - 2s/epoch - 380ms/step\n",
      "Epoch 125/250\n",
      "6/6 - 2s - loss: 0.7106 - accuracy: 0.7466 - val_loss: 0.8974 - val_accuracy: 0.7093 - 2s/epoch - 285ms/step\n",
      "Epoch 126/250\n",
      "6/6 - 2s - loss: 0.6987 - accuracy: 0.7612 - val_loss: 0.8717 - val_accuracy: 0.7403 - 2s/epoch - 286ms/step\n",
      "Epoch 127/250\n",
      "6/6 - 2s - loss: 0.6906 - accuracy: 0.7544 - val_loss: 0.8685 - val_accuracy: 0.7326 - 2s/epoch - 284ms/step\n",
      "Epoch 128/250\n",
      "6/6 - 2s - loss: 0.6670 - accuracy: 0.7689 - val_loss: 0.8670 - val_accuracy: 0.7481 - 2s/epoch - 288ms/step\n",
      "Epoch 129/250\n",
      "6/6 - 2s - loss: 0.6848 - accuracy: 0.7553 - val_loss: 0.8616 - val_accuracy: 0.7442 - 2s/epoch - 282ms/step\n",
      "Epoch 130/250\n",
      "6/6 - 2s - loss: 0.6519 - accuracy: 0.7903 - val_loss: 0.8446 - val_accuracy: 0.7481 - 2s/epoch - 383ms/step\n",
      "Epoch 131/250\n",
      "6/6 - 2s - loss: 0.6460 - accuracy: 0.7631 - val_loss: 0.8862 - val_accuracy: 0.7132 - 2s/epoch - 280ms/step\n",
      "Epoch 132/250\n",
      "6/6 - 2s - loss: 0.6740 - accuracy: 0.7709 - val_loss: 0.8572 - val_accuracy: 0.7481 - 2s/epoch - 288ms/step\n",
      "Epoch 133/250\n",
      "6/6 - 2s - loss: 0.6371 - accuracy: 0.7786 - val_loss: 0.8626 - val_accuracy: 0.7403 - 2s/epoch - 286ms/step\n",
      "Epoch 134/250\n",
      "6/6 - 2s - loss: 0.6224 - accuracy: 0.7883 - val_loss: 0.8844 - val_accuracy: 0.7326 - 2s/epoch - 292ms/step\n",
      "Epoch 135/250\n",
      "6/6 - 2s - loss: 0.6325 - accuracy: 0.7845 - val_loss: 0.8365 - val_accuracy: 0.7481 - 2s/epoch - 291ms/step\n",
      "Epoch 136/250\n",
      "6/6 - 2s - loss: 0.6351 - accuracy: 0.7806 - val_loss: 0.8395 - val_accuracy: 0.7558 - 2s/epoch - 400ms/step\n",
      "Epoch 137/250\n",
      "6/6 - 2s - loss: 0.6288 - accuracy: 0.7961 - val_loss: 0.8283 - val_accuracy: 0.7558 - 2s/epoch - 284ms/step\n",
      "Epoch 138/250\n",
      "6/6 - 2s - loss: 0.6345 - accuracy: 0.7728 - val_loss: 0.8216 - val_accuracy: 0.7481 - 2s/epoch - 285ms/step\n",
      "Epoch 139/250\n",
      "6/6 - 2s - loss: 0.6114 - accuracy: 0.7835 - val_loss: 0.8248 - val_accuracy: 0.7558 - 2s/epoch - 296ms/step\n",
      "Epoch 140/250\n",
      "6/6 - 2s - loss: 0.6142 - accuracy: 0.7777 - val_loss: 0.8359 - val_accuracy: 0.7558 - 2s/epoch - 291ms/step\n",
      "Epoch 141/250\n",
      "6/6 - 2s - loss: 0.6086 - accuracy: 0.7864 - val_loss: 0.8182 - val_accuracy: 0.7558 - 2s/epoch - 299ms/step\n",
      "Epoch 142/250\n",
      "6/6 - 2s - loss: 0.5847 - accuracy: 0.8010 - val_loss: 0.8519 - val_accuracy: 0.7481 - 2s/epoch - 378ms/step\n",
      "Epoch 143/250\n",
      "6/6 - 2s - loss: 0.5996 - accuracy: 0.7990 - val_loss: 0.8030 - val_accuracy: 0.7829 - 2s/epoch - 297ms/step\n",
      "Epoch 144/250\n",
      "6/6 - 2s - loss: 0.5893 - accuracy: 0.8058 - val_loss: 0.8172 - val_accuracy: 0.7558 - 2s/epoch - 292ms/step\n",
      "Epoch 145/250\n",
      "6/6 - 2s - loss: 0.5895 - accuracy: 0.7971 - val_loss: 0.7993 - val_accuracy: 0.7674 - 2s/epoch - 289ms/step\n",
      "Epoch 146/250\n",
      "6/6 - 2s - loss: 0.5832 - accuracy: 0.8058 - val_loss: 0.8005 - val_accuracy: 0.7713 - 2s/epoch - 293ms/step\n",
      "Epoch 147/250\n",
      "6/6 - 2s - loss: 0.5476 - accuracy: 0.8175 - val_loss: 0.8303 - val_accuracy: 0.7403 - 2s/epoch - 286ms/step\n",
      "Epoch 148/250\n",
      "6/6 - 2s - loss: 0.5692 - accuracy: 0.8117 - val_loss: 0.7900 - val_accuracy: 0.7752 - 2s/epoch - 330ms/step\n",
      "Epoch 149/250\n",
      "6/6 - 2s - loss: 0.5670 - accuracy: 0.7981 - val_loss: 0.8541 - val_accuracy: 0.7248 - 2s/epoch - 340ms/step\n",
      "Epoch 150/250\n",
      "6/6 - 2s - loss: 0.5705 - accuracy: 0.7990 - val_loss: 0.8163 - val_accuracy: 0.7713 - 2s/epoch - 289ms/step\n",
      "Epoch 151/250\n",
      "6/6 - 2s - loss: 0.5495 - accuracy: 0.8146 - val_loss: 0.8240 - val_accuracy: 0.7636 - 2s/epoch - 287ms/step\n",
      "Epoch 152/250\n",
      "6/6 - 2s - loss: 0.5427 - accuracy: 0.8087 - val_loss: 0.8098 - val_accuracy: 0.7636 - 2s/epoch - 291ms/step\n",
      "Epoch 153/250\n",
      "6/6 - 2s - loss: 0.5427 - accuracy: 0.8049 - val_loss: 0.8132 - val_accuracy: 0.7481 - 2s/epoch - 289ms/step\n",
      "Epoch 154/250\n",
      "6/6 - 2s - loss: 0.5342 - accuracy: 0.8311 - val_loss: 0.8019 - val_accuracy: 0.7519 - 2s/epoch - 289ms/step\n",
      "Epoch 155/250\n",
      "6/6 - 2s - loss: 0.5179 - accuracy: 0.8233 - val_loss: 0.8029 - val_accuracy: 0.7558 - 2s/epoch - 388ms/step\n",
      "Epoch 156/250\n",
      "6/6 - 2s - loss: 0.5100 - accuracy: 0.8223 - val_loss: 0.8038 - val_accuracy: 0.7791 - 2s/epoch - 295ms/step\n",
      "Epoch 157/250\n",
      "6/6 - 2s - loss: 0.5369 - accuracy: 0.8039 - val_loss: 0.8577 - val_accuracy: 0.7442 - 2s/epoch - 300ms/step\n",
      "Epoch 158/250\n",
      "6/6 - 2s - loss: 0.5317 - accuracy: 0.8184 - val_loss: 0.8145 - val_accuracy: 0.7752 - 2s/epoch - 300ms/step\n",
      "Epoch 159/250\n",
      "6/6 - 2s - loss: 0.5138 - accuracy: 0.8155 - val_loss: 0.7999 - val_accuracy: 0.7636 - 2s/epoch - 298ms/step\n",
      "Epoch 160/250\n",
      "6/6 - 2s - loss: 0.5115 - accuracy: 0.8204 - val_loss: 0.7849 - val_accuracy: 0.7829 - 2s/epoch - 302ms/step\n",
      "Epoch 161/250\n",
      "6/6 - 2s - loss: 0.5141 - accuracy: 0.8301 - val_loss: 0.7782 - val_accuracy: 0.7752 - 2s/epoch - 392ms/step\n",
      "Epoch 162/250\n",
      "6/6 - 2s - loss: 0.5083 - accuracy: 0.8194 - val_loss: 0.7726 - val_accuracy: 0.7752 - 2s/epoch - 293ms/step\n",
      "Epoch 163/250\n",
      "6/6 - 2s - loss: 0.4724 - accuracy: 0.8417 - val_loss: 0.8115 - val_accuracy: 0.7752 - 2s/epoch - 300ms/step\n",
      "Epoch 164/250\n",
      "6/6 - 2s - loss: 0.4897 - accuracy: 0.8184 - val_loss: 0.7970 - val_accuracy: 0.7752 - 2s/epoch - 296ms/step\n",
      "Epoch 165/250\n",
      "6/6 - 2s - loss: 0.4899 - accuracy: 0.8291 - val_loss: 0.7719 - val_accuracy: 0.7868 - 2s/epoch - 290ms/step\n",
      "Epoch 166/250\n",
      "6/6 - 2s - loss: 0.4814 - accuracy: 0.8262 - val_loss: 0.7908 - val_accuracy: 0.7597 - 2s/epoch - 300ms/step\n",
      "Epoch 167/250\n",
      "6/6 - 2s - loss: 0.4551 - accuracy: 0.8379 - val_loss: 0.7756 - val_accuracy: 0.7752 - 2s/epoch - 387ms/step\n",
      "Epoch 168/250\n",
      "6/6 - 2s - loss: 0.4653 - accuracy: 0.8408 - val_loss: 0.7668 - val_accuracy: 0.7907 - 2s/epoch - 292ms/step\n",
      "Epoch 169/250\n",
      "6/6 - 2s - loss: 0.4486 - accuracy: 0.8495 - val_loss: 0.7814 - val_accuracy: 0.7829 - 2s/epoch - 305ms/step\n",
      "Epoch 170/250\n",
      "6/6 - 2s - loss: 0.4902 - accuracy: 0.8291 - val_loss: 0.7697 - val_accuracy: 0.7946 - 2s/epoch - 296ms/step\n",
      "Epoch 171/250\n",
      "6/6 - 2s - loss: 0.4415 - accuracy: 0.8466 - val_loss: 0.7877 - val_accuracy: 0.7829 - 2s/epoch - 291ms/step\n",
      "Epoch 172/250\n",
      "6/6 - 2s - loss: 0.4654 - accuracy: 0.8320 - val_loss: 0.8004 - val_accuracy: 0.7868 - 2s/epoch - 297ms/step\n",
      "Epoch 173/250\n",
      "6/6 - 2s - loss: 0.4746 - accuracy: 0.8301 - val_loss: 0.8223 - val_accuracy: 0.7597 - 2s/epoch - 391ms/step\n",
      "Epoch 174/250\n",
      "6/6 - 2s - loss: 0.4373 - accuracy: 0.8573 - val_loss: 0.7671 - val_accuracy: 0.7868 - 2s/epoch - 287ms/step\n",
      "Epoch 175/250\n",
      "6/6 - 2s - loss: 0.4425 - accuracy: 0.8583 - val_loss: 0.7588 - val_accuracy: 0.7829 - 2s/epoch - 287ms/step\n",
      "Epoch 176/250\n",
      "6/6 - 2s - loss: 0.4338 - accuracy: 0.8602 - val_loss: 0.7789 - val_accuracy: 0.7791 - 2s/epoch - 289ms/step\n",
      "Epoch 177/250\n",
      "6/6 - 2s - loss: 0.4444 - accuracy: 0.8466 - val_loss: 0.7556 - val_accuracy: 0.7829 - 2s/epoch - 291ms/step\n",
      "Epoch 178/250\n",
      "6/6 - 2s - loss: 0.4241 - accuracy: 0.8699 - val_loss: 0.7440 - val_accuracy: 0.7984 - 2s/epoch - 288ms/step\n",
      "Epoch 179/250\n",
      "6/6 - 2s - loss: 0.4130 - accuracy: 0.8631 - val_loss: 0.7842 - val_accuracy: 0.7752 - 2s/epoch - 360ms/step\n",
      "Epoch 180/250\n",
      "6/6 - 2s - loss: 0.4215 - accuracy: 0.8631 - val_loss: 0.7715 - val_accuracy: 0.7752 - 2s/epoch - 308ms/step\n",
      "Epoch 181/250\n",
      "6/6 - 2s - loss: 0.4197 - accuracy: 0.8612 - val_loss: 0.7627 - val_accuracy: 0.7674 - 2s/epoch - 286ms/step\n",
      "Epoch 182/250\n",
      "6/6 - 2s - loss: 0.4178 - accuracy: 0.8515 - val_loss: 0.7516 - val_accuracy: 0.7791 - 2s/epoch - 286ms/step\n",
      "Epoch 183/250\n",
      "6/6 - 2s - loss: 0.4115 - accuracy: 0.8612 - val_loss: 0.7725 - val_accuracy: 0.7946 - 2s/epoch - 295ms/step\n",
      "Epoch 184/250\n",
      "6/6 - 2s - loss: 0.4107 - accuracy: 0.8699 - val_loss: 0.7719 - val_accuracy: 0.7829 - 2s/epoch - 297ms/step\n",
      "Epoch 185/250\n",
      "6/6 - 2s - loss: 0.3803 - accuracy: 0.8738 - val_loss: 0.7768 - val_accuracy: 0.7868 - 2s/epoch - 314ms/step\n",
      "Epoch 186/250\n",
      "6/6 - 2s - loss: 0.4038 - accuracy: 0.8631 - val_loss: 0.7531 - val_accuracy: 0.8062 - 2s/epoch - 358ms/step\n",
      "Epoch 187/250\n",
      "6/6 - 2s - loss: 0.3876 - accuracy: 0.8718 - val_loss: 0.7804 - val_accuracy: 0.7868 - 2s/epoch - 288ms/step\n",
      "Epoch 188/250\n",
      "6/6 - 2s - loss: 0.3907 - accuracy: 0.8689 - val_loss: 0.7925 - val_accuracy: 0.7946 - 2s/epoch - 292ms/step\n",
      "Epoch 189/250\n",
      "6/6 - 2s - loss: 0.3809 - accuracy: 0.8757 - val_loss: 0.7741 - val_accuracy: 0.7868 - 2s/epoch - 286ms/step\n",
      "Epoch 190/250\n",
      "6/6 - 2s - loss: 0.3672 - accuracy: 0.8612 - val_loss: 0.7761 - val_accuracy: 0.7907 - 2s/epoch - 288ms/step\n",
      "Epoch 191/250\n",
      "6/6 - 2s - loss: 0.3876 - accuracy: 0.8641 - val_loss: 0.7749 - val_accuracy: 0.7907 - 2s/epoch - 297ms/step\n",
      "Epoch 192/250\n",
      "6/6 - 2s - loss: 0.4043 - accuracy: 0.8680 - val_loss: 0.7853 - val_accuracy: 0.8178 - 2s/epoch - 388ms/step\n",
      "Epoch 193/250\n",
      "6/6 - 2s - loss: 0.3594 - accuracy: 0.8728 - val_loss: 0.7526 - val_accuracy: 0.7829 - 2s/epoch - 287ms/step\n",
      "Epoch 194/250\n",
      "6/6 - 2s - loss: 0.3647 - accuracy: 0.8806 - val_loss: 0.7639 - val_accuracy: 0.7946 - 2s/epoch - 290ms/step\n",
      "Epoch 195/250\n",
      "6/6 - 2s - loss: 0.3327 - accuracy: 0.8932 - val_loss: 0.8090 - val_accuracy: 0.7946 - 2s/epoch - 288ms/step\n",
      "Epoch 196/250\n",
      "6/6 - 2s - loss: 0.3673 - accuracy: 0.8835 - val_loss: 0.7850 - val_accuracy: 0.7791 - 2s/epoch - 292ms/step\n",
      "Epoch 197/250\n",
      "6/6 - 2s - loss: 0.3619 - accuracy: 0.8845 - val_loss: 0.7871 - val_accuracy: 0.7674 - 2s/epoch - 298ms/step\n",
      "Epoch 198/250\n",
      "6/6 - 2s - loss: 0.3523 - accuracy: 0.8854 - val_loss: 0.7708 - val_accuracy: 0.7829 - 2s/epoch - 383ms/step\n",
      "Epoch 199/250\n",
      "6/6 - 2s - loss: 0.3627 - accuracy: 0.8718 - val_loss: 0.7612 - val_accuracy: 0.7984 - 2s/epoch - 288ms/step\n",
      "Epoch 200/250\n",
      "6/6 - 2s - loss: 0.3438 - accuracy: 0.8864 - val_loss: 0.7736 - val_accuracy: 0.7984 - 2s/epoch - 294ms/step\n",
      "Epoch 201/250\n",
      "6/6 - 2s - loss: 0.3327 - accuracy: 0.8806 - val_loss: 0.7539 - val_accuracy: 0.7946 - 2s/epoch - 290ms/step\n",
      "Epoch 202/250\n",
      "6/6 - 2s - loss: 0.3309 - accuracy: 0.8874 - val_loss: 0.7400 - val_accuracy: 0.7984 - 2s/epoch - 295ms/step\n",
      "Epoch 203/250\n",
      "6/6 - 2s - loss: 0.3142 - accuracy: 0.8981 - val_loss: 0.7480 - val_accuracy: 0.8101 - 2s/epoch - 288ms/step\n",
      "Epoch 204/250\n",
      "6/6 - 2s - loss: 0.3286 - accuracy: 0.8864 - val_loss: 0.7530 - val_accuracy: 0.8101 - 2s/epoch - 383ms/step\n",
      "Epoch 205/250\n",
      "6/6 - 2s - loss: 0.3256 - accuracy: 0.8845 - val_loss: 0.7558 - val_accuracy: 0.7868 - 2s/epoch - 294ms/step\n",
      "Epoch 206/250\n",
      "6/6 - 2s - loss: 0.3406 - accuracy: 0.8816 - val_loss: 0.7710 - val_accuracy: 0.7907 - 2s/epoch - 297ms/step\n",
      "Epoch 207/250\n",
      "6/6 - 2s - loss: 0.3065 - accuracy: 0.9039 - val_loss: 0.7761 - val_accuracy: 0.7868 - 2s/epoch - 294ms/step\n",
      "Epoch 208/250\n",
      "6/6 - 2s - loss: 0.3039 - accuracy: 0.8913 - val_loss: 0.7760 - val_accuracy: 0.7829 - 2s/epoch - 287ms/step\n",
      "Epoch 209/250\n",
      "6/6 - 2s - loss: 0.3174 - accuracy: 0.8971 - val_loss: 0.7699 - val_accuracy: 0.7984 - 2s/epoch - 289ms/step\n",
      "Epoch 210/250\n",
      "6/6 - 2s - loss: 0.3085 - accuracy: 0.8951 - val_loss: 0.7890 - val_accuracy: 0.7752 - 2s/epoch - 374ms/step\n",
      "Epoch 211/250\n",
      "6/6 - 2s - loss: 0.3122 - accuracy: 0.9068 - val_loss: 0.7606 - val_accuracy: 0.7907 - 2s/epoch - 306ms/step\n",
      "Epoch 212/250\n",
      "6/6 - 2s - loss: 0.3097 - accuracy: 0.8981 - val_loss: 0.7767 - val_accuracy: 0.8062 - 2s/epoch - 290ms/step\n",
      "Epoch 213/250\n",
      "6/6 - 2s - loss: 0.3200 - accuracy: 0.8961 - val_loss: 0.7730 - val_accuracy: 0.8023 - 2s/epoch - 297ms/step\n",
      "Epoch 214/250\n",
      "6/6 - 2s - loss: 0.3197 - accuracy: 0.8903 - val_loss: 0.7517 - val_accuracy: 0.8178 - 2s/epoch - 288ms/step\n",
      "Epoch 215/250\n",
      "6/6 - 2s - loss: 0.2868 - accuracy: 0.9126 - val_loss: 0.7905 - val_accuracy: 0.7907 - 2s/epoch - 287ms/step\n",
      "Epoch 216/250\n",
      "6/6 - 2s - loss: 0.3029 - accuracy: 0.8971 - val_loss: 0.7558 - val_accuracy: 0.8062 - 2s/epoch - 358ms/step\n",
      "Epoch 217/250\n",
      "6/6 - 2s - loss: 0.3005 - accuracy: 0.9049 - val_loss: 0.7688 - val_accuracy: 0.7946 - 2s/epoch - 322ms/step\n",
      "Epoch 218/250\n",
      "6/6 - 2s - loss: 0.2847 - accuracy: 0.9078 - val_loss: 0.8007 - val_accuracy: 0.7984 - 2s/epoch - 296ms/step\n",
      "Epoch 219/250\n",
      "6/6 - 2s - loss: 0.2828 - accuracy: 0.9068 - val_loss: 0.7502 - val_accuracy: 0.7984 - 2s/epoch - 289ms/step\n",
      "Epoch 220/250\n",
      "6/6 - 2s - loss: 0.2793 - accuracy: 0.9078 - val_loss: 0.7499 - val_accuracy: 0.8062 - 2s/epoch - 286ms/step\n",
      "Epoch 221/250\n",
      "6/6 - 2s - loss: 0.2904 - accuracy: 0.8971 - val_loss: 0.7839 - val_accuracy: 0.7868 - 2s/epoch - 291ms/step\n",
      "Epoch 222/250\n",
      "6/6 - 2s - loss: 0.2727 - accuracy: 0.9136 - val_loss: 0.7578 - val_accuracy: 0.7984 - 2s/epoch - 301ms/step\n",
      "Epoch 223/250\n",
      "6/6 - 2s - loss: 0.2801 - accuracy: 0.9000 - val_loss: 0.7694 - val_accuracy: 0.7907 - 2s/epoch - 365ms/step\n",
      "Epoch 224/250\n",
      "6/6 - 2s - loss: 0.2696 - accuracy: 0.9146 - val_loss: 0.7799 - val_accuracy: 0.8178 - 2s/epoch - 287ms/step\n",
      "Epoch 225/250\n",
      "6/6 - 2s - loss: 0.2638 - accuracy: 0.9155 - val_loss: 0.7732 - val_accuracy: 0.8101 - 2s/epoch - 286ms/step\n",
      "Epoch 226/250\n",
      "6/6 - 2s - loss: 0.2647 - accuracy: 0.9136 - val_loss: 0.7990 - val_accuracy: 0.7984 - 2s/epoch - 289ms/step\n",
      "Epoch 227/250\n",
      "6/6 - 2s - loss: 0.2645 - accuracy: 0.9019 - val_loss: 0.7706 - val_accuracy: 0.7946 - 2s/epoch - 287ms/step\n",
      "Epoch 228/250\n",
      "6/6 - 2s - loss: 0.2747 - accuracy: 0.9155 - val_loss: 0.7534 - val_accuracy: 0.8062 - 2s/epoch - 287ms/step\n",
      "Epoch 229/250\n",
      "6/6 - 2s - loss: 0.2683 - accuracy: 0.8942 - val_loss: 0.7925 - val_accuracy: 0.8178 - 2s/epoch - 387ms/step\n",
      "Epoch 230/250\n",
      "6/6 - 2s - loss: 0.2636 - accuracy: 0.9204 - val_loss: 0.7781 - val_accuracy: 0.8023 - 2s/epoch - 289ms/step\n",
      "Epoch 231/250\n",
      "6/6 - 2s - loss: 0.2549 - accuracy: 0.9175 - val_loss: 0.7768 - val_accuracy: 0.7946 - 2s/epoch - 295ms/step\n",
      "Epoch 232/250\n",
      "6/6 - 2s - loss: 0.2696 - accuracy: 0.9058 - val_loss: 0.7618 - val_accuracy: 0.8101 - 2s/epoch - 293ms/step\n",
      "Epoch 233/250\n",
      "6/6 - 2s - loss: 0.2453 - accuracy: 0.9252 - val_loss: 0.7637 - val_accuracy: 0.8023 - 2s/epoch - 286ms/step\n",
      "Epoch 234/250\n",
      "6/6 - 2s - loss: 0.2262 - accuracy: 0.9282 - val_loss: 0.7658 - val_accuracy: 0.8023 - 2s/epoch - 286ms/step\n",
      "Epoch 235/250\n",
      "6/6 - 2s - loss: 0.2583 - accuracy: 0.9087 - val_loss: 0.7698 - val_accuracy: 0.8217 - 2s/epoch - 384ms/step\n",
      "Epoch 236/250\n",
      "6/6 - 2s - loss: 0.2451 - accuracy: 0.9233 - val_loss: 0.8050 - val_accuracy: 0.8023 - 2s/epoch - 286ms/step\n",
      "Epoch 237/250\n",
      "6/6 - 2s - loss: 0.2371 - accuracy: 0.9233 - val_loss: 0.7817 - val_accuracy: 0.8178 - 2s/epoch - 292ms/step\n",
      "Epoch 238/250\n",
      "6/6 - 2s - loss: 0.2312 - accuracy: 0.9282 - val_loss: 0.7959 - val_accuracy: 0.8062 - 2s/epoch - 296ms/step\n",
      "Epoch 239/250\n",
      "6/6 - 2s - loss: 0.2442 - accuracy: 0.9155 - val_loss: 0.8078 - val_accuracy: 0.8101 - 2s/epoch - 283ms/step\n",
      "Epoch 240/250\n",
      "6/6 - 2s - loss: 0.2435 - accuracy: 0.9194 - val_loss: 0.7903 - val_accuracy: 0.7984 - 2s/epoch - 290ms/step\n",
      "Epoch 241/250\n",
      "6/6 - 2s - loss: 0.2349 - accuracy: 0.9272 - val_loss: 0.8130 - val_accuracy: 0.7946 - 2s/epoch - 381ms/step\n",
      "Epoch 242/250\n",
      "6/6 - 2s - loss: 0.2350 - accuracy: 0.9204 - val_loss: 0.7985 - val_accuracy: 0.7984 - 2s/epoch - 293ms/step\n",
      "Epoch 243/250\n",
      "6/6 - 2s - loss: 0.2176 - accuracy: 0.9301 - val_loss: 0.7833 - val_accuracy: 0.7907 - 2s/epoch - 287ms/step\n",
      "Epoch 244/250\n",
      "6/6 - 2s - loss: 0.2067 - accuracy: 0.9301 - val_loss: 0.7958 - val_accuracy: 0.8140 - 2s/epoch - 294ms/step\n",
      "Epoch 245/250\n",
      "6/6 - 2s - loss: 0.2194 - accuracy: 0.9214 - val_loss: 0.7928 - val_accuracy: 0.8140 - 2s/epoch - 296ms/step\n",
      "Epoch 246/250\n",
      "6/6 - 2s - loss: 0.2303 - accuracy: 0.9272 - val_loss: 0.7936 - val_accuracy: 0.8140 - 2s/epoch - 288ms/step\n",
      "Epoch 247/250\n",
      "6/6 - 2s - loss: 0.2114 - accuracy: 0.9252 - val_loss: 0.8291 - val_accuracy: 0.7984 - 2s/epoch - 354ms/step\n",
      "Epoch 248/250\n",
      "6/6 - 2s - loss: 0.2116 - accuracy: 0.9301 - val_loss: 0.7815 - val_accuracy: 0.8023 - 2s/epoch - 321ms/step\n",
      "Epoch 249/250\n",
      "6/6 - 2s - loss: 0.2195 - accuracy: 0.9252 - val_loss: 0.7909 - val_accuracy: 0.8178 - 2s/epoch - 292ms/step\n",
      "Epoch 250/250\n",
      "6/6 - 2s - loss: 0.2081 - accuracy: 0.9320 - val_loss: 0.7797 - val_accuracy: 0.7984 - 2s/epoch - 286ms/step\n",
      "9/9 [==============================] - 0s 16ms/step\n",
      "Epoch 1/250\n",
      "6/6 - 4s - loss: 1.9029 - accuracy: 0.3515 - val_loss: 1.7584 - val_accuracy: 0.3876 - 4s/epoch - 627ms/step\n",
      "Epoch 2/250\n",
      "6/6 - 3s - loss: 1.7032 - accuracy: 0.4175 - val_loss: 1.7405 - val_accuracy: 0.3876 - 3s/epoch - 529ms/step\n",
      "Epoch 3/250\n",
      "6/6 - 3s - loss: 1.6700 - accuracy: 0.4175 - val_loss: 1.7563 - val_accuracy: 0.3876 - 3s/epoch - 457ms/step\n",
      "Epoch 4/250\n",
      "6/6 - 3s - loss: 1.6853 - accuracy: 0.4175 - val_loss: 1.7288 - val_accuracy: 0.3876 - 3s/epoch - 461ms/step\n",
      "Epoch 5/250\n",
      "6/6 - 3s - loss: 1.6744 - accuracy: 0.4175 - val_loss: 1.7373 - val_accuracy: 0.3876 - 3s/epoch - 536ms/step\n",
      "Epoch 6/250\n",
      "6/6 - 3s - loss: 1.6710 - accuracy: 0.4175 - val_loss: 1.7448 - val_accuracy: 0.3876 - 3s/epoch - 467ms/step\n",
      "Epoch 7/250\n",
      "6/6 - 3s - loss: 1.6720 - accuracy: 0.4175 - val_loss: 1.7517 - val_accuracy: 0.3876 - 3s/epoch - 462ms/step\n",
      "Epoch 8/250\n",
      "6/6 - 3s - loss: 1.6731 - accuracy: 0.4175 - val_loss: 1.7319 - val_accuracy: 0.3876 - 3s/epoch - 464ms/step\n",
      "Epoch 9/250\n",
      "6/6 - 3s - loss: 1.6706 - accuracy: 0.4175 - val_loss: 1.7297 - val_accuracy: 0.3876 - 3s/epoch - 553ms/step\n",
      "Epoch 10/250\n",
      "6/6 - 3s - loss: 1.6704 - accuracy: 0.4175 - val_loss: 1.7290 - val_accuracy: 0.3876 - 3s/epoch - 461ms/step\n",
      "Epoch 11/250\n",
      "6/6 - 3s - loss: 1.6714 - accuracy: 0.4175 - val_loss: 1.7269 - val_accuracy: 0.3876 - 3s/epoch - 456ms/step\n",
      "Epoch 12/250\n",
      "6/6 - 3s - loss: 1.6719 - accuracy: 0.4175 - val_loss: 1.7324 - val_accuracy: 0.3876 - 3s/epoch - 484ms/step\n",
      "Epoch 13/250\n",
      "6/6 - 3s - loss: 1.6683 - accuracy: 0.4175 - val_loss: 1.7347 - val_accuracy: 0.3876 - 3s/epoch - 551ms/step\n",
      "Epoch 14/250\n",
      "6/6 - 3s - loss: 1.6695 - accuracy: 0.4175 - val_loss: 1.7302 - val_accuracy: 0.3876 - 3s/epoch - 454ms/step\n",
      "Epoch 15/250\n",
      "6/6 - 3s - loss: 1.6706 - accuracy: 0.4175 - val_loss: 1.7398 - val_accuracy: 0.3876 - 3s/epoch - 458ms/step\n",
      "Epoch 16/250\n",
      "6/6 - 3s - loss: 1.6660 - accuracy: 0.4175 - val_loss: 1.7362 - val_accuracy: 0.3876 - 3s/epoch - 460ms/step\n",
      "Epoch 17/250\n",
      "6/6 - 3s - loss: 1.6719 - accuracy: 0.4175 - val_loss: 1.7489 - val_accuracy: 0.3876 - 3s/epoch - 554ms/step\n",
      "Epoch 18/250\n",
      "6/6 - 3s - loss: 1.6659 - accuracy: 0.4175 - val_loss: 1.7431 - val_accuracy: 0.3876 - 3s/epoch - 468ms/step\n",
      "Epoch 19/250\n",
      "6/6 - 3s - loss: 1.6674 - accuracy: 0.4175 - val_loss: 1.7379 - val_accuracy: 0.3876 - 3s/epoch - 457ms/step\n",
      "Epoch 20/250\n",
      "6/6 - 3s - loss: 1.6657 - accuracy: 0.4175 - val_loss: 1.7426 - val_accuracy: 0.3876 - 3s/epoch - 462ms/step\n",
      "Epoch 21/250\n",
      "6/6 - 3s - loss: 1.6725 - accuracy: 0.4175 - val_loss: 1.7354 - val_accuracy: 0.3876 - 3s/epoch - 558ms/step\n",
      "Epoch 22/250\n",
      "6/6 - 3s - loss: 1.6701 - accuracy: 0.4175 - val_loss: 1.7355 - val_accuracy: 0.3876 - 3s/epoch - 457ms/step\n",
      "Epoch 23/250\n",
      "6/6 - 3s - loss: 1.6810 - accuracy: 0.4175 - val_loss: 1.7474 - val_accuracy: 0.3876 - 3s/epoch - 458ms/step\n",
      "Epoch 24/250\n",
      "6/6 - 3s - loss: 1.6699 - accuracy: 0.4175 - val_loss: 1.7369 - val_accuracy: 0.3876 - 3s/epoch - 464ms/step\n",
      "Epoch 25/250\n",
      "6/6 - 3s - loss: 1.6752 - accuracy: 0.4175 - val_loss: 1.7449 - val_accuracy: 0.3876 - 3s/epoch - 550ms/step\n",
      "Epoch 26/250\n",
      "6/6 - 3s - loss: 1.6813 - accuracy: 0.4175 - val_loss: 1.7350 - val_accuracy: 0.3876 - 3s/epoch - 453ms/step\n",
      "Epoch 27/250\n",
      "6/6 - 3s - loss: 1.7098 - accuracy: 0.4175 - val_loss: 1.7288 - val_accuracy: 0.3876 - 3s/epoch - 453ms/step\n",
      "Epoch 28/250\n",
      "6/6 - 3s - loss: 1.6798 - accuracy: 0.4175 - val_loss: 1.7477 - val_accuracy: 0.3876 - 3s/epoch - 457ms/step\n",
      "Epoch 29/250\n",
      "6/6 - 3s - loss: 1.6720 - accuracy: 0.4175 - val_loss: 1.7259 - val_accuracy: 0.3876 - 3s/epoch - 555ms/step\n",
      "Epoch 30/250\n",
      "6/6 - 3s - loss: 1.6702 - accuracy: 0.4175 - val_loss: 1.7455 - val_accuracy: 0.3876 - 3s/epoch - 461ms/step\n",
      "Epoch 31/250\n",
      "6/6 - 3s - loss: 1.6684 - accuracy: 0.4175 - val_loss: 1.7246 - val_accuracy: 0.3876 - 3s/epoch - 460ms/step\n",
      "Epoch 32/250\n",
      "6/6 - 3s - loss: 1.6698 - accuracy: 0.4175 - val_loss: 1.7248 - val_accuracy: 0.3876 - 3s/epoch - 482ms/step\n",
      "Epoch 33/250\n",
      "6/6 - 3s - loss: 1.6672 - accuracy: 0.4175 - val_loss: 1.7287 - val_accuracy: 0.3876 - 3s/epoch - 554ms/step\n",
      "Epoch 34/250\n",
      "6/6 - 3s - loss: 1.6645 - accuracy: 0.4175 - val_loss: 1.7261 - val_accuracy: 0.3876 - 3s/epoch - 455ms/step\n",
      "Epoch 35/250\n",
      "6/6 - 3s - loss: 1.6596 - accuracy: 0.4175 - val_loss: 1.7470 - val_accuracy: 0.3876 - 3s/epoch - 459ms/step\n",
      "Epoch 36/250\n",
      "6/6 - 3s - loss: 1.6589 - accuracy: 0.4175 - val_loss: 1.7363 - val_accuracy: 0.3876 - 3s/epoch - 486ms/step\n",
      "Epoch 37/250\n",
      "6/6 - 3s - loss: 1.6603 - accuracy: 0.4175 - val_loss: 1.7338 - val_accuracy: 0.3876 - 3s/epoch - 554ms/step\n",
      "Epoch 38/250\n",
      "6/6 - 3s - loss: 1.6599 - accuracy: 0.4175 - val_loss: 1.7308 - val_accuracy: 0.3876 - 3s/epoch - 467ms/step\n",
      "Epoch 39/250\n",
      "6/6 - 3s - loss: 1.6671 - accuracy: 0.4175 - val_loss: 1.7336 - val_accuracy: 0.3876 - 3s/epoch - 463ms/step\n",
      "Epoch 40/250\n",
      "6/6 - 3s - loss: 1.6516 - accuracy: 0.4175 - val_loss: 1.7630 - val_accuracy: 0.3876 - 3s/epoch - 455ms/step\n",
      "Epoch 41/250\n",
      "6/6 - 3s - loss: 1.6566 - accuracy: 0.4175 - val_loss: 1.7344 - val_accuracy: 0.3876 - 3s/epoch - 553ms/step\n",
      "Epoch 42/250\n",
      "6/6 - 3s - loss: 1.6830 - accuracy: 0.4175 - val_loss: 1.7246 - val_accuracy: 0.3876 - 3s/epoch - 461ms/step\n",
      "Epoch 43/250\n",
      "6/6 - 3s - loss: 1.6710 - accuracy: 0.4175 - val_loss: 1.7287 - val_accuracy: 0.3876 - 3s/epoch - 462ms/step\n",
      "Epoch 44/250\n",
      "6/6 - 3s - loss: 1.6588 - accuracy: 0.4175 - val_loss: 1.7238 - val_accuracy: 0.3876 - 3s/epoch - 488ms/step\n",
      "Epoch 45/250\n",
      "6/6 - 3s - loss: 1.6541 - accuracy: 0.4175 - val_loss: 1.7333 - val_accuracy: 0.3876 - 3s/epoch - 525ms/step\n",
      "Epoch 46/250\n",
      "6/6 - 3s - loss: 1.6467 - accuracy: 0.4175 - val_loss: 1.7298 - val_accuracy: 0.3876 - 3s/epoch - 463ms/step\n",
      "Epoch 47/250\n",
      "6/6 - 3s - loss: 1.6421 - accuracy: 0.4175 - val_loss: 1.7382 - val_accuracy: 0.3876 - 3s/epoch - 455ms/step\n",
      "Epoch 48/250\n",
      "6/6 - 3s - loss: 1.6424 - accuracy: 0.4175 - val_loss: 1.7212 - val_accuracy: 0.3876 - 3s/epoch - 488ms/step\n",
      "Epoch 49/250\n",
      "6/6 - 3s - loss: 1.6354 - accuracy: 0.4175 - val_loss: 1.7183 - val_accuracy: 0.3876 - 3s/epoch - 519ms/step\n",
      "Epoch 50/250\n",
      "6/6 - 3s - loss: 1.6248 - accuracy: 0.4175 - val_loss: 1.7124 - val_accuracy: 0.3876 - 3s/epoch - 455ms/step\n",
      "Epoch 51/250\n",
      "6/6 - 3s - loss: 1.6187 - accuracy: 0.4175 - val_loss: 1.7102 - val_accuracy: 0.3876 - 3s/epoch - 455ms/step\n",
      "Epoch 52/250\n",
      "6/6 - 3s - loss: 1.6120 - accuracy: 0.4175 - val_loss: 1.7008 - val_accuracy: 0.3876 - 3s/epoch - 493ms/step\n",
      "Epoch 53/250\n",
      "6/6 - 3s - loss: 1.6063 - accuracy: 0.4175 - val_loss: 1.7003 - val_accuracy: 0.3876 - 3s/epoch - 513ms/step\n",
      "Epoch 54/250\n",
      "6/6 - 3s - loss: 1.5919 - accuracy: 0.4175 - val_loss: 1.6951 - val_accuracy: 0.3876 - 3s/epoch - 450ms/step\n",
      "Epoch 55/250\n",
      "6/6 - 3s - loss: 1.5898 - accuracy: 0.4175 - val_loss: 1.6880 - val_accuracy: 0.3876 - 3s/epoch - 457ms/step\n",
      "Epoch 56/250\n",
      "6/6 - 3s - loss: 1.5777 - accuracy: 0.4184 - val_loss: 1.6742 - val_accuracy: 0.3876 - 3s/epoch - 499ms/step\n",
      "Epoch 57/250\n",
      "6/6 - 3s - loss: 1.5679 - accuracy: 0.4175 - val_loss: 1.6799 - val_accuracy: 0.3876 - 3s/epoch - 506ms/step\n",
      "Epoch 58/250\n",
      "6/6 - 3s - loss: 1.5598 - accuracy: 0.4233 - val_loss: 1.6551 - val_accuracy: 0.3876 - 3s/epoch - 460ms/step\n",
      "Epoch 59/250\n",
      "6/6 - 3s - loss: 1.5379 - accuracy: 0.4204 - val_loss: 1.6701 - val_accuracy: 0.3876 - 3s/epoch - 452ms/step\n",
      "Epoch 60/250\n",
      "6/6 - 3s - loss: 1.5222 - accuracy: 0.4282 - val_loss: 1.6393 - val_accuracy: 0.4031 - 3s/epoch - 495ms/step\n",
      "Epoch 61/250\n",
      "6/6 - 3s - loss: 1.5055 - accuracy: 0.4340 - val_loss: 1.6476 - val_accuracy: 0.4147 - 3s/epoch - 503ms/step\n",
      "Epoch 62/250\n",
      "6/6 - 3s - loss: 1.4929 - accuracy: 0.4631 - val_loss: 1.6210 - val_accuracy: 0.4147 - 3s/epoch - 449ms/step\n",
      "Epoch 63/250\n",
      "6/6 - 3s - loss: 1.4735 - accuracy: 0.4524 - val_loss: 1.6009 - val_accuracy: 0.4302 - 3s/epoch - 448ms/step\n",
      "Epoch 64/250\n",
      "6/6 - 3s - loss: 1.4613 - accuracy: 0.4728 - val_loss: 1.6081 - val_accuracy: 0.4264 - 3s/epoch - 498ms/step\n",
      "Epoch 65/250\n",
      "6/6 - 3s - loss: 1.4485 - accuracy: 0.4689 - val_loss: 1.5698 - val_accuracy: 0.4612 - 3s/epoch - 499ms/step\n",
      "Epoch 66/250\n",
      "6/6 - 3s - loss: 1.4336 - accuracy: 0.4854 - val_loss: 1.6557 - val_accuracy: 0.4186 - 3s/epoch - 452ms/step\n",
      "Epoch 67/250\n",
      "6/6 - 3s - loss: 1.4494 - accuracy: 0.4757 - val_loss: 1.5886 - val_accuracy: 0.4651 - 3s/epoch - 453ms/step\n",
      "Epoch 68/250\n",
      "6/6 - 3s - loss: 1.4193 - accuracy: 0.5010 - val_loss: 1.5830 - val_accuracy: 0.4380 - 3s/epoch - 497ms/step\n",
      "Epoch 69/250\n",
      "6/6 - 3s - loss: 1.4118 - accuracy: 0.4903 - val_loss: 1.5825 - val_accuracy: 0.4690 - 3s/epoch - 505ms/step\n",
      "Epoch 70/250\n",
      "6/6 - 3s - loss: 1.3995 - accuracy: 0.5029 - val_loss: 1.5607 - val_accuracy: 0.4612 - 3s/epoch - 453ms/step\n",
      "Epoch 71/250\n",
      "6/6 - 3s - loss: 1.3990 - accuracy: 0.4825 - val_loss: 1.5676 - val_accuracy: 0.4767 - 3s/epoch - 456ms/step\n",
      "Epoch 72/250\n",
      "6/6 - 3s - loss: 1.3793 - accuracy: 0.5029 - val_loss: 1.5094 - val_accuracy: 0.4651 - 3s/epoch - 491ms/step\n",
      "Epoch 73/250\n",
      "6/6 - 3s - loss: 1.3786 - accuracy: 0.5078 - val_loss: 1.5240 - val_accuracy: 0.4922 - 3s/epoch - 507ms/step\n",
      "Epoch 74/250\n",
      "6/6 - 3s - loss: 1.3848 - accuracy: 0.5126 - val_loss: 1.5229 - val_accuracy: 0.4690 - 3s/epoch - 455ms/step\n",
      "Epoch 75/250\n",
      "6/6 - 3s - loss: 1.3534 - accuracy: 0.5019 - val_loss: 1.4913 - val_accuracy: 0.4806 - 3s/epoch - 451ms/step\n",
      "Epoch 76/250\n",
      "6/6 - 3s - loss: 1.3475 - accuracy: 0.5078 - val_loss: 1.5084 - val_accuracy: 0.4767 - 3s/epoch - 479ms/step\n",
      "Epoch 77/250\n",
      "6/6 - 3s - loss: 1.3402 - accuracy: 0.5165 - val_loss: 1.5205 - val_accuracy: 0.5078 - 3s/epoch - 514ms/step\n",
      "Epoch 78/250\n",
      "6/6 - 3s - loss: 1.3408 - accuracy: 0.5311 - val_loss: 1.5100 - val_accuracy: 0.4806 - 3s/epoch - 456ms/step\n",
      "Epoch 79/250\n",
      "6/6 - 3s - loss: 1.3038 - accuracy: 0.5437 - val_loss: 1.4701 - val_accuracy: 0.5116 - 3s/epoch - 452ms/step\n",
      "Epoch 80/250\n",
      "6/6 - 3s - loss: 1.3015 - accuracy: 0.5417 - val_loss: 1.4670 - val_accuracy: 0.4922 - 3s/epoch - 493ms/step\n",
      "Epoch 81/250\n",
      "6/6 - 3s - loss: 1.2972 - accuracy: 0.5515 - val_loss: 1.4804 - val_accuracy: 0.5116 - 3s/epoch - 509ms/step\n",
      "Epoch 82/250\n",
      "6/6 - 3s - loss: 1.3031 - accuracy: 0.5592 - val_loss: 1.4633 - val_accuracy: 0.5000 - 3s/epoch - 453ms/step\n",
      "Epoch 83/250\n",
      "6/6 - 3s - loss: 1.3008 - accuracy: 0.5340 - val_loss: 1.4512 - val_accuracy: 0.5349 - 3s/epoch - 460ms/step\n",
      "Epoch 84/250\n",
      "6/6 - 3s - loss: 1.2898 - accuracy: 0.5427 - val_loss: 1.4501 - val_accuracy: 0.5078 - 3s/epoch - 512ms/step\n",
      "Epoch 85/250\n",
      "6/6 - 3s - loss: 1.2759 - accuracy: 0.5573 - val_loss: 1.4607 - val_accuracy: 0.4922 - 3s/epoch - 494ms/step\n",
      "Epoch 86/250\n",
      "6/6 - 3s - loss: 1.2679 - accuracy: 0.5573 - val_loss: 1.4339 - val_accuracy: 0.5310 - 3s/epoch - 449ms/step\n",
      "Epoch 87/250\n",
      "6/6 - 3s - loss: 1.2598 - accuracy: 0.5553 - val_loss: 1.4793 - val_accuracy: 0.5078 - 3s/epoch - 453ms/step\n",
      "Epoch 88/250\n",
      "6/6 - 3s - loss: 1.2760 - accuracy: 0.5553 - val_loss: 1.4431 - val_accuracy: 0.5310 - 3s/epoch - 505ms/step\n",
      "Epoch 89/250\n",
      "6/6 - 3s - loss: 1.2586 - accuracy: 0.5650 - val_loss: 1.4153 - val_accuracy: 0.5271 - 3s/epoch - 494ms/step\n",
      "Epoch 90/250\n",
      "6/6 - 3s - loss: 1.2344 - accuracy: 0.5796 - val_loss: 1.4168 - val_accuracy: 0.5271 - 3s/epoch - 455ms/step\n",
      "Epoch 91/250\n",
      "6/6 - 3s - loss: 1.2412 - accuracy: 0.5932 - val_loss: 1.4100 - val_accuracy: 0.5388 - 3s/epoch - 456ms/step\n",
      "Epoch 92/250\n",
      "6/6 - 3s - loss: 1.2373 - accuracy: 0.5845 - val_loss: 1.4230 - val_accuracy: 0.4961 - 3s/epoch - 525ms/step\n",
      "Epoch 93/250\n",
      "6/6 - 3s - loss: 1.2374 - accuracy: 0.5612 - val_loss: 1.4246 - val_accuracy: 0.5426 - 3s/epoch - 488ms/step\n",
      "Epoch 94/250\n",
      "6/6 - 3s - loss: 1.2150 - accuracy: 0.5806 - val_loss: 1.3915 - val_accuracy: 0.5465 - 3s/epoch - 451ms/step\n",
      "Epoch 95/250\n",
      "6/6 - 3s - loss: 1.2164 - accuracy: 0.5835 - val_loss: 1.3926 - val_accuracy: 0.5388 - 3s/epoch - 457ms/step\n",
      "Epoch 96/250\n",
      "6/6 - 3s - loss: 1.2118 - accuracy: 0.5825 - val_loss: 1.3631 - val_accuracy: 0.5465 - 3s/epoch - 523ms/step\n",
      "Epoch 97/250\n",
      "6/6 - 3s - loss: 1.2328 - accuracy: 0.5728 - val_loss: 1.3666 - val_accuracy: 0.5465 - 3s/epoch - 488ms/step\n",
      "Epoch 98/250\n",
      "6/6 - 3s - loss: 1.2006 - accuracy: 0.5922 - val_loss: 1.3780 - val_accuracy: 0.5310 - 3s/epoch - 458ms/step\n",
      "Epoch 99/250\n",
      "6/6 - 3s - loss: 1.1925 - accuracy: 0.5942 - val_loss: 1.4041 - val_accuracy: 0.5194 - 3s/epoch - 463ms/step\n",
      "Epoch 100/250\n",
      "6/6 - 3s - loss: 1.2124 - accuracy: 0.5913 - val_loss: 1.3711 - val_accuracy: 0.5581 - 3s/epoch - 550ms/step\n",
      "Epoch 101/250\n",
      "6/6 - 3s - loss: 1.1827 - accuracy: 0.5971 - val_loss: 1.3524 - val_accuracy: 0.5620 - 3s/epoch - 476ms/step\n",
      "Epoch 102/250\n",
      "6/6 - 3s - loss: 1.1874 - accuracy: 0.5942 - val_loss: 1.3441 - val_accuracy: 0.5426 - 3s/epoch - 450ms/step\n",
      "Epoch 103/250\n",
      "6/6 - 3s - loss: 1.1879 - accuracy: 0.5961 - val_loss: 1.3869 - val_accuracy: 0.5310 - 3s/epoch - 456ms/step\n",
      "Epoch 104/250\n",
      "6/6 - 3s - loss: 1.1839 - accuracy: 0.5748 - val_loss: 1.3550 - val_accuracy: 0.5659 - 3s/epoch - 544ms/step\n",
      "Epoch 105/250\n",
      "6/6 - 3s - loss: 1.1782 - accuracy: 0.5961 - val_loss: 1.3636 - val_accuracy: 0.5465 - 3s/epoch - 454ms/step\n",
      "Epoch 106/250\n",
      "6/6 - 3s - loss: 1.1727 - accuracy: 0.5903 - val_loss: 1.3594 - val_accuracy: 0.5698 - 3s/epoch - 457ms/step\n",
      "Epoch 107/250\n",
      "6/6 - 3s - loss: 1.1812 - accuracy: 0.5913 - val_loss: 1.3678 - val_accuracy: 0.5349 - 3s/epoch - 452ms/step\n",
      "Epoch 108/250\n",
      "6/6 - 3s - loss: 1.1776 - accuracy: 0.5971 - val_loss: 1.3338 - val_accuracy: 0.5543 - 3s/epoch - 547ms/step\n",
      "Epoch 109/250\n",
      "6/6 - 3s - loss: 1.1529 - accuracy: 0.6068 - val_loss: 1.3310 - val_accuracy: 0.5465 - 3s/epoch - 450ms/step\n",
      "Epoch 110/250\n",
      "6/6 - 3s - loss: 1.1599 - accuracy: 0.5903 - val_loss: 1.3235 - val_accuracy: 0.5465 - 3s/epoch - 451ms/step\n",
      "Epoch 111/250\n",
      "6/6 - 3s - loss: 1.1511 - accuracy: 0.6039 - val_loss: 1.3071 - val_accuracy: 0.5543 - 3s/epoch - 452ms/step\n",
      "Epoch 112/250\n",
      "6/6 - 3s - loss: 1.1331 - accuracy: 0.6194 - val_loss: 1.3542 - val_accuracy: 0.5426 - 3s/epoch - 554ms/step\n",
      "Epoch 113/250\n",
      "6/6 - 3s - loss: 1.1628 - accuracy: 0.5971 - val_loss: 1.3228 - val_accuracy: 0.5349 - 3s/epoch - 458ms/step\n",
      "Epoch 114/250\n",
      "6/6 - 3s - loss: 1.1264 - accuracy: 0.6262 - val_loss: 1.3236 - val_accuracy: 0.5659 - 3s/epoch - 456ms/step\n",
      "Epoch 115/250\n",
      "6/6 - 3s - loss: 1.1344 - accuracy: 0.6155 - val_loss: 1.2930 - val_accuracy: 0.5543 - 3s/epoch - 457ms/step\n",
      "Epoch 116/250\n",
      "6/6 - 3s - loss: 1.1335 - accuracy: 0.6117 - val_loss: 1.2948 - val_accuracy: 0.5543 - 3s/epoch - 553ms/step\n",
      "Epoch 117/250\n",
      "6/6 - 3s - loss: 1.1289 - accuracy: 0.6155 - val_loss: 1.3049 - val_accuracy: 0.5543 - 3s/epoch - 455ms/step\n",
      "Epoch 118/250\n",
      "6/6 - 3s - loss: 1.1310 - accuracy: 0.6029 - val_loss: 1.3368 - val_accuracy: 0.5310 - 3s/epoch - 453ms/step\n",
      "Epoch 119/250\n",
      "6/6 - 3s - loss: 1.1149 - accuracy: 0.6175 - val_loss: 1.2870 - val_accuracy: 0.5504 - 3s/epoch - 458ms/step\n",
      "Epoch 120/250\n",
      "6/6 - 3s - loss: 1.1307 - accuracy: 0.6136 - val_loss: 1.2959 - val_accuracy: 0.5504 - 3s/epoch - 552ms/step\n",
      "Epoch 121/250\n",
      "6/6 - 3s - loss: 1.1246 - accuracy: 0.6204 - val_loss: 1.2986 - val_accuracy: 0.5504 - 3s/epoch - 460ms/step\n",
      "Epoch 122/250\n",
      "6/6 - 3s - loss: 1.1294 - accuracy: 0.6146 - val_loss: 1.2682 - val_accuracy: 0.5620 - 3s/epoch - 460ms/step\n",
      "Epoch 123/250\n",
      "6/6 - 3s - loss: 1.1098 - accuracy: 0.6282 - val_loss: 1.2753 - val_accuracy: 0.5504 - 3s/epoch - 457ms/step\n",
      "Epoch 124/250\n",
      "6/6 - 3s - loss: 1.1117 - accuracy: 0.6252 - val_loss: 1.2676 - val_accuracy: 0.5543 - 3s/epoch - 554ms/step\n",
      "Epoch 125/250\n",
      "6/6 - 3s - loss: 1.1025 - accuracy: 0.6262 - val_loss: 1.2803 - val_accuracy: 0.5736 - 3s/epoch - 456ms/step\n",
      "Epoch 126/250\n",
      "6/6 - 3s - loss: 1.0797 - accuracy: 0.6282 - val_loss: 1.2708 - val_accuracy: 0.5543 - 3s/epoch - 482ms/step\n",
      "Epoch 127/250\n",
      "6/6 - 3s - loss: 1.0747 - accuracy: 0.6388 - val_loss: 1.2399 - val_accuracy: 0.5853 - 3s/epoch - 458ms/step\n",
      "Epoch 128/250\n",
      "6/6 - 3s - loss: 1.0893 - accuracy: 0.6155 - val_loss: 1.2503 - val_accuracy: 0.5736 - 3s/epoch - 546ms/step\n",
      "Epoch 129/250\n",
      "6/6 - 3s - loss: 1.0752 - accuracy: 0.6379 - val_loss: 1.2448 - val_accuracy: 0.5698 - 3s/epoch - 449ms/step\n",
      "Epoch 130/250\n",
      "6/6 - 3s - loss: 1.0678 - accuracy: 0.6466 - val_loss: 1.2464 - val_accuracy: 0.5659 - 3s/epoch - 449ms/step\n",
      "Epoch 131/250\n",
      "6/6 - 3s - loss: 1.0782 - accuracy: 0.6320 - val_loss: 1.2552 - val_accuracy: 0.5698 - 3s/epoch - 456ms/step\n",
      "Epoch 132/250\n",
      "6/6 - 3s - loss: 1.0547 - accuracy: 0.6544 - val_loss: 1.2624 - val_accuracy: 0.5504 - 3s/epoch - 574ms/step\n",
      "Epoch 133/250\n",
      "6/6 - 3s - loss: 1.0931 - accuracy: 0.6243 - val_loss: 1.2281 - val_accuracy: 0.5620 - 3s/epoch - 480ms/step\n",
      "Epoch 134/250\n",
      "6/6 - 3s - loss: 1.0581 - accuracy: 0.6398 - val_loss: 1.2161 - val_accuracy: 0.5581 - 3s/epoch - 452ms/step\n",
      "Epoch 135/250\n",
      "6/6 - 3s - loss: 1.0467 - accuracy: 0.6388 - val_loss: 1.2302 - val_accuracy: 0.5775 - 3s/epoch - 479ms/step\n",
      "Epoch 136/250\n",
      "6/6 - 3s - loss: 1.0707 - accuracy: 0.6408 - val_loss: 1.2593 - val_accuracy: 0.5543 - 3s/epoch - 547ms/step\n",
      "Epoch 137/250\n",
      "6/6 - 3s - loss: 1.0562 - accuracy: 0.6485 - val_loss: 1.2150 - val_accuracy: 0.5659 - 3s/epoch - 456ms/step\n",
      "Epoch 138/250\n",
      "6/6 - 3s - loss: 1.0575 - accuracy: 0.6408 - val_loss: 1.2019 - val_accuracy: 0.5891 - 3s/epoch - 452ms/step\n",
      "Epoch 139/250\n",
      "6/6 - 3s - loss: 1.0406 - accuracy: 0.6583 - val_loss: 1.1917 - val_accuracy: 0.5775 - 3s/epoch - 447ms/step\n",
      "Epoch 140/250\n",
      "6/6 - 3s - loss: 1.0334 - accuracy: 0.6563 - val_loss: 1.1943 - val_accuracy: 0.5814 - 3s/epoch - 543ms/step\n",
      "Epoch 141/250\n",
      "6/6 - 3s - loss: 1.0530 - accuracy: 0.6417 - val_loss: 1.2383 - val_accuracy: 0.5698 - 3s/epoch - 482ms/step\n",
      "Epoch 142/250\n",
      "6/6 - 3s - loss: 1.0224 - accuracy: 0.6505 - val_loss: 1.1789 - val_accuracy: 0.6008 - 3s/epoch - 446ms/step\n",
      "Epoch 143/250\n",
      "6/6 - 3s - loss: 1.0274 - accuracy: 0.6534 - val_loss: 1.1743 - val_accuracy: 0.5930 - 3s/epoch - 451ms/step\n",
      "Epoch 144/250\n",
      "6/6 - 3s - loss: 1.0232 - accuracy: 0.6544 - val_loss: 1.1775 - val_accuracy: 0.5969 - 3s/epoch - 543ms/step\n",
      "Epoch 145/250\n",
      "6/6 - 3s - loss: 1.0289 - accuracy: 0.6427 - val_loss: 1.1700 - val_accuracy: 0.5930 - 3s/epoch - 476ms/step\n",
      "Epoch 146/250\n",
      "6/6 - 3s - loss: 1.0152 - accuracy: 0.6602 - val_loss: 1.1537 - val_accuracy: 0.6163 - 3s/epoch - 454ms/step\n",
      "Epoch 147/250\n",
      "6/6 - 3s - loss: 1.0068 - accuracy: 0.6544 - val_loss: 1.1712 - val_accuracy: 0.5969 - 3s/epoch - 457ms/step\n",
      "Epoch 148/250\n",
      "6/6 - 3s - loss: 1.0054 - accuracy: 0.6612 - val_loss: 1.1400 - val_accuracy: 0.6047 - 3s/epoch - 546ms/step\n",
      "Epoch 149/250\n",
      "6/6 - 3s - loss: 1.0199 - accuracy: 0.6650 - val_loss: 1.1451 - val_accuracy: 0.6008 - 3s/epoch - 451ms/step\n",
      "Epoch 150/250\n",
      "6/6 - 3s - loss: 0.9996 - accuracy: 0.6495 - val_loss: 1.1566 - val_accuracy: 0.5969 - 3s/epoch - 452ms/step\n",
      "Epoch 151/250\n",
      "6/6 - 3s - loss: 1.0047 - accuracy: 0.6641 - val_loss: 1.1289 - val_accuracy: 0.6318 - 3s/epoch - 448ms/step\n",
      "Epoch 152/250\n",
      "6/6 - 3s - loss: 0.9844 - accuracy: 0.6641 - val_loss: 1.1275 - val_accuracy: 0.5969 - 3s/epoch - 546ms/step\n",
      "Epoch 153/250\n",
      "6/6 - 3s - loss: 0.9791 - accuracy: 0.6583 - val_loss: 1.1226 - val_accuracy: 0.6085 - 3s/epoch - 456ms/step\n",
      "Epoch 154/250\n",
      "6/6 - 3s - loss: 0.9735 - accuracy: 0.6670 - val_loss: 1.1321 - val_accuracy: 0.6163 - 3s/epoch - 452ms/step\n",
      "Epoch 155/250\n",
      "6/6 - 3s - loss: 0.9726 - accuracy: 0.6806 - val_loss: 1.1123 - val_accuracy: 0.6124 - 3s/epoch - 480ms/step\n",
      "Epoch 156/250\n",
      "6/6 - 3s - loss: 0.9626 - accuracy: 0.6689 - val_loss: 1.1120 - val_accuracy: 0.6357 - 3s/epoch - 548ms/step\n",
      "Epoch 157/250\n",
      "6/6 - 3s - loss: 0.9543 - accuracy: 0.6767 - val_loss: 1.1166 - val_accuracy: 0.6124 - 3s/epoch - 452ms/step\n",
      "Epoch 158/250\n",
      "6/6 - 3s - loss: 0.9643 - accuracy: 0.6913 - val_loss: 1.1202 - val_accuracy: 0.6163 - 3s/epoch - 477ms/step\n",
      "Epoch 159/250\n",
      "6/6 - 3s - loss: 0.9697 - accuracy: 0.6563 - val_loss: 1.1387 - val_accuracy: 0.6395 - 3s/epoch - 486ms/step\n",
      "Epoch 160/250\n",
      "6/6 - 3s - loss: 0.9841 - accuracy: 0.6495 - val_loss: 1.1312 - val_accuracy: 0.5930 - 3s/epoch - 527ms/step\n",
      "Epoch 161/250\n",
      "6/6 - 3s - loss: 0.9770 - accuracy: 0.6738 - val_loss: 1.1049 - val_accuracy: 0.6434 - 3s/epoch - 484ms/step\n",
      "Epoch 162/250\n",
      "6/6 - 3s - loss: 0.9638 - accuracy: 0.6612 - val_loss: 1.0975 - val_accuracy: 0.6473 - 3s/epoch - 452ms/step\n",
      "Epoch 163/250\n",
      "6/6 - 3s - loss: 0.9433 - accuracy: 0.6922 - val_loss: 1.0914 - val_accuracy: 0.6705 - 3s/epoch - 506ms/step\n",
      "Epoch 164/250\n",
      "6/6 - 3s - loss: 0.9420 - accuracy: 0.6777 - val_loss: 1.1184 - val_accuracy: 0.5969 - 3s/epoch - 495ms/step\n",
      "Epoch 165/250\n",
      "6/6 - 3s - loss: 0.9353 - accuracy: 0.6932 - val_loss: 1.0643 - val_accuracy: 0.6744 - 3s/epoch - 450ms/step\n",
      "Epoch 166/250\n",
      "6/6 - 3s - loss: 0.9507 - accuracy: 0.6874 - val_loss: 1.1022 - val_accuracy: 0.6357 - 3s/epoch - 456ms/step\n",
      "Epoch 167/250\n",
      "6/6 - 3s - loss: 0.9231 - accuracy: 0.6874 - val_loss: 1.1363 - val_accuracy: 0.6085 - 3s/epoch - 507ms/step\n",
      "Epoch 168/250\n",
      "6/6 - 3s - loss: 0.9651 - accuracy: 0.6718 - val_loss: 1.1348 - val_accuracy: 0.6085 - 3s/epoch - 496ms/step\n",
      "Epoch 169/250\n",
      "6/6 - 3s - loss: 0.9515 - accuracy: 0.6621 - val_loss: 1.1378 - val_accuracy: 0.5853 - 3s/epoch - 454ms/step\n",
      "Epoch 170/250\n",
      "6/6 - 3s - loss: 0.9262 - accuracy: 0.6825 - val_loss: 1.0759 - val_accuracy: 0.6667 - 3s/epoch - 459ms/step\n",
      "Epoch 171/250\n",
      "6/6 - 3s - loss: 0.9253 - accuracy: 0.7010 - val_loss: 1.0729 - val_accuracy: 0.6550 - 3s/epoch - 517ms/step\n",
      "Epoch 172/250\n",
      "6/6 - 3s - loss: 0.9179 - accuracy: 0.6961 - val_loss: 1.1004 - val_accuracy: 0.6279 - 3s/epoch - 491ms/step\n",
      "Epoch 173/250\n",
      "6/6 - 3s - loss: 0.9311 - accuracy: 0.6883 - val_loss: 1.1109 - val_accuracy: 0.6279 - 3s/epoch - 454ms/step\n",
      "Epoch 174/250\n",
      "6/6 - 3s - loss: 0.9135 - accuracy: 0.6767 - val_loss: 1.0664 - val_accuracy: 0.6512 - 3s/epoch - 461ms/step\n",
      "Epoch 175/250\n",
      "6/6 - 3s - loss: 0.9003 - accuracy: 0.6903 - val_loss: 1.0659 - val_accuracy: 0.6628 - 3s/epoch - 524ms/step\n",
      "Epoch 176/250\n",
      "6/6 - 3s - loss: 0.8830 - accuracy: 0.6913 - val_loss: 1.0633 - val_accuracy: 0.6434 - 3s/epoch - 479ms/step\n",
      "Epoch 177/250\n",
      "6/6 - 3s - loss: 0.8810 - accuracy: 0.7078 - val_loss: 1.0572 - val_accuracy: 0.6628 - 3s/epoch - 454ms/step\n",
      "Epoch 178/250\n",
      "6/6 - 3s - loss: 0.8857 - accuracy: 0.7000 - val_loss: 1.0419 - val_accuracy: 0.6744 - 3s/epoch - 453ms/step\n",
      "Epoch 179/250\n",
      "6/6 - 3s - loss: 0.8929 - accuracy: 0.6951 - val_loss: 1.0311 - val_accuracy: 0.6589 - 3s/epoch - 517ms/step\n",
      "Epoch 180/250\n",
      "6/6 - 3s - loss: 0.8726 - accuracy: 0.6922 - val_loss: 1.0465 - val_accuracy: 0.6473 - 3s/epoch - 482ms/step\n",
      "Epoch 181/250\n",
      "6/6 - 3s - loss: 0.8774 - accuracy: 0.7010 - val_loss: 1.0399 - val_accuracy: 0.6705 - 3s/epoch - 455ms/step\n",
      "Epoch 182/250\n",
      "6/6 - 3s - loss: 0.8756 - accuracy: 0.7049 - val_loss: 1.0736 - val_accuracy: 0.6279 - 3s/epoch - 450ms/step\n",
      "Epoch 183/250\n",
      "6/6 - 3s - loss: 0.8815 - accuracy: 0.6971 - val_loss: 1.0827 - val_accuracy: 0.6357 - 3s/epoch - 522ms/step\n",
      "Epoch 184/250\n",
      "6/6 - 3s - loss: 0.8794 - accuracy: 0.6942 - val_loss: 1.0548 - val_accuracy: 0.6395 - 3s/epoch - 489ms/step\n",
      "Epoch 185/250\n",
      "6/6 - 3s - loss: 0.8564 - accuracy: 0.7252 - val_loss: 1.0067 - val_accuracy: 0.6899 - 3s/epoch - 458ms/step\n",
      "Epoch 186/250\n",
      "6/6 - 3s - loss: 0.8672 - accuracy: 0.7155 - val_loss: 1.0108 - val_accuracy: 0.6783 - 3s/epoch - 457ms/step\n",
      "Epoch 187/250\n",
      "6/6 - 3s - loss: 0.8504 - accuracy: 0.7117 - val_loss: 1.0014 - val_accuracy: 0.7054 - 3s/epoch - 540ms/step\n",
      "Epoch 188/250\n",
      "6/6 - 3s - loss: 0.8312 - accuracy: 0.7223 - val_loss: 0.9979 - val_accuracy: 0.7016 - 3s/epoch - 471ms/step\n",
      "Epoch 189/250\n",
      "6/6 - 3s - loss: 0.8277 - accuracy: 0.7146 - val_loss: 1.0192 - val_accuracy: 0.6783 - 3s/epoch - 458ms/step\n",
      "Epoch 190/250\n",
      "6/6 - 3s - loss: 0.8376 - accuracy: 0.7223 - val_loss: 0.9941 - val_accuracy: 0.7016 - 3s/epoch - 483ms/step\n",
      "Epoch 191/250\n",
      "6/6 - 3s - loss: 0.8267 - accuracy: 0.7223 - val_loss: 0.9937 - val_accuracy: 0.7132 - 3s/epoch - 553ms/step\n",
      "Epoch 192/250\n",
      "6/6 - 3s - loss: 0.8141 - accuracy: 0.7301 - val_loss: 0.9963 - val_accuracy: 0.6938 - 3s/epoch - 452ms/step\n",
      "Epoch 193/250\n",
      "6/6 - 3s - loss: 0.8235 - accuracy: 0.7272 - val_loss: 0.9838 - val_accuracy: 0.7093 - 3s/epoch - 456ms/step\n",
      "Epoch 194/250\n",
      "6/6 - 3s - loss: 0.8167 - accuracy: 0.7039 - val_loss: 1.0550 - val_accuracy: 0.6357 - 3s/epoch - 454ms/step\n",
      "Epoch 195/250\n",
      "6/6 - 3s - loss: 0.8243 - accuracy: 0.7184 - val_loss: 0.9947 - val_accuracy: 0.6899 - 3s/epoch - 552ms/step\n",
      "Epoch 196/250\n",
      "6/6 - 3s - loss: 0.8152 - accuracy: 0.7146 - val_loss: 0.9918 - val_accuracy: 0.6860 - 3s/epoch - 457ms/step\n",
      "Epoch 197/250\n",
      "6/6 - 3s - loss: 0.7937 - accuracy: 0.7252 - val_loss: 0.9816 - val_accuracy: 0.7132 - 3s/epoch - 456ms/step\n",
      "Epoch 198/250\n",
      "6/6 - 3s - loss: 0.8252 - accuracy: 0.7194 - val_loss: 0.9968 - val_accuracy: 0.6899 - 3s/epoch - 459ms/step\n",
      "Epoch 199/250\n",
      "6/6 - 3s - loss: 0.8218 - accuracy: 0.7155 - val_loss: 0.9770 - val_accuracy: 0.7093 - 3s/epoch - 543ms/step\n",
      "Epoch 200/250\n",
      "6/6 - 3s - loss: 0.8209 - accuracy: 0.6990 - val_loss: 1.0235 - val_accuracy: 0.6589 - 3s/epoch - 453ms/step\n",
      "Epoch 201/250\n",
      "6/6 - 3s - loss: 0.8430 - accuracy: 0.7126 - val_loss: 0.9814 - val_accuracy: 0.6705 - 3s/epoch - 453ms/step\n",
      "Epoch 202/250\n",
      "6/6 - 3s - loss: 0.7953 - accuracy: 0.7214 - val_loss: 1.0073 - val_accuracy: 0.6899 - 3s/epoch - 457ms/step\n",
      "Epoch 203/250\n",
      "6/6 - 3s - loss: 0.7848 - accuracy: 0.7388 - val_loss: 0.9985 - val_accuracy: 0.6705 - 3s/epoch - 550ms/step\n",
      "Epoch 204/250\n",
      "6/6 - 3s - loss: 0.8191 - accuracy: 0.7311 - val_loss: 0.9702 - val_accuracy: 0.7093 - 3s/epoch - 454ms/step\n",
      "Epoch 205/250\n",
      "6/6 - 3s - loss: 0.8096 - accuracy: 0.7223 - val_loss: 1.0340 - val_accuracy: 0.6783 - 3s/epoch - 467ms/step\n",
      "Epoch 206/250\n",
      "6/6 - 3s - loss: 0.8152 - accuracy: 0.7194 - val_loss: 0.9803 - val_accuracy: 0.6899 - 3s/epoch - 454ms/step\n",
      "Epoch 207/250\n",
      "6/6 - 3s - loss: 0.8026 - accuracy: 0.7223 - val_loss: 0.9892 - val_accuracy: 0.6667 - 3s/epoch - 580ms/step\n",
      "Epoch 208/250\n",
      "6/6 - 3s - loss: 0.7772 - accuracy: 0.7447 - val_loss: 0.9828 - val_accuracy: 0.7054 - 3s/epoch - 457ms/step\n",
      "Epoch 209/250\n",
      "6/6 - 3s - loss: 0.7772 - accuracy: 0.7398 - val_loss: 0.9508 - val_accuracy: 0.7093 - 3s/epoch - 460ms/step\n",
      "Epoch 210/250\n",
      "6/6 - 3s - loss: 0.7905 - accuracy: 0.7272 - val_loss: 0.9658 - val_accuracy: 0.7209 - 3s/epoch - 456ms/step\n",
      "Epoch 211/250\n",
      "6/6 - 3s - loss: 0.7587 - accuracy: 0.7534 - val_loss: 0.9923 - val_accuracy: 0.7171 - 3s/epoch - 548ms/step\n",
      "Epoch 212/250\n",
      "6/6 - 3s - loss: 0.7635 - accuracy: 0.7437 - val_loss: 0.9561 - val_accuracy: 0.7171 - 3s/epoch - 456ms/step\n",
      "Epoch 213/250\n",
      "6/6 - 3s - loss: 0.7684 - accuracy: 0.7388 - val_loss: 0.9628 - val_accuracy: 0.7132 - 3s/epoch - 452ms/step\n",
      "Epoch 214/250\n",
      "6/6 - 3s - loss: 0.7378 - accuracy: 0.7427 - val_loss: 0.9566 - val_accuracy: 0.7248 - 3s/epoch - 455ms/step\n",
      "Epoch 215/250\n",
      "6/6 - 3s - loss: 0.7694 - accuracy: 0.7340 - val_loss: 0.9513 - val_accuracy: 0.7016 - 3s/epoch - 546ms/step\n",
      "Epoch 216/250\n",
      "6/6 - 3s - loss: 0.7513 - accuracy: 0.7515 - val_loss: 0.9781 - val_accuracy: 0.6938 - 3s/epoch - 457ms/step\n",
      "Epoch 217/250\n",
      "6/6 - 3s - loss: 0.7550 - accuracy: 0.7408 - val_loss: 0.9968 - val_accuracy: 0.6899 - 3s/epoch - 456ms/step\n",
      "Epoch 218/250\n",
      "6/6 - 3s - loss: 0.7622 - accuracy: 0.7495 - val_loss: 0.9522 - val_accuracy: 0.7171 - 3s/epoch - 455ms/step\n",
      "Epoch 219/250\n",
      "6/6 - 3s - loss: 0.7413 - accuracy: 0.7466 - val_loss: 0.9594 - val_accuracy: 0.7209 - 3s/epoch - 544ms/step\n",
      "Epoch 220/250\n",
      "6/6 - 3s - loss: 0.7418 - accuracy: 0.7427 - val_loss: 0.9772 - val_accuracy: 0.6860 - 3s/epoch - 451ms/step\n",
      "Epoch 221/250\n",
      "6/6 - 3s - loss: 0.7227 - accuracy: 0.7680 - val_loss: 0.9532 - val_accuracy: 0.7209 - 3s/epoch - 455ms/step\n",
      "Epoch 222/250\n",
      "6/6 - 3s - loss: 0.7254 - accuracy: 0.7602 - val_loss: 0.9479 - val_accuracy: 0.7248 - 3s/epoch - 455ms/step\n",
      "Epoch 223/250\n",
      "6/6 - 3s - loss: 0.7461 - accuracy: 0.7447 - val_loss: 0.9597 - val_accuracy: 0.7171 - 3s/epoch - 545ms/step\n",
      "Epoch 224/250\n",
      "6/6 - 3s - loss: 0.7351 - accuracy: 0.7573 - val_loss: 0.9512 - val_accuracy: 0.7364 - 3s/epoch - 455ms/step\n",
      "Epoch 225/250\n",
      "6/6 - 3s - loss: 0.7098 - accuracy: 0.7534 - val_loss: 0.9622 - val_accuracy: 0.7132 - 3s/epoch - 454ms/step\n",
      "Epoch 226/250\n",
      "6/6 - 3s - loss: 0.7449 - accuracy: 0.7350 - val_loss: 0.9484 - val_accuracy: 0.7209 - 3s/epoch - 481ms/step\n",
      "Epoch 227/250\n",
      "6/6 - 3s - loss: 0.7175 - accuracy: 0.7670 - val_loss: 0.9502 - val_accuracy: 0.7093 - 3s/epoch - 549ms/step\n",
      "Epoch 228/250\n",
      "6/6 - 3s - loss: 0.7116 - accuracy: 0.7612 - val_loss: 0.9620 - val_accuracy: 0.7016 - 3s/epoch - 456ms/step\n",
      "Epoch 229/250\n",
      "6/6 - 3s - loss: 0.7194 - accuracy: 0.7583 - val_loss: 0.9453 - val_accuracy: 0.7171 - 3s/epoch - 453ms/step\n",
      "Epoch 230/250\n",
      "6/6 - 3s - loss: 0.6852 - accuracy: 0.7689 - val_loss: 0.9289 - val_accuracy: 0.7326 - 3s/epoch - 457ms/step\n",
      "Epoch 231/250\n",
      "6/6 - 3s - loss: 0.6966 - accuracy: 0.7689 - val_loss: 0.9633 - val_accuracy: 0.7054 - 3s/epoch - 545ms/step\n",
      "Epoch 232/250\n",
      "6/6 - 3s - loss: 0.6947 - accuracy: 0.7592 - val_loss: 0.9217 - val_accuracy: 0.7287 - 3s/epoch - 452ms/step\n",
      "Epoch 233/250\n",
      "6/6 - 3s - loss: 0.6878 - accuracy: 0.7786 - val_loss: 0.9680 - val_accuracy: 0.6938 - 3s/epoch - 450ms/step\n",
      "Epoch 234/250\n",
      "6/6 - 3s - loss: 0.7206 - accuracy: 0.7544 - val_loss: 0.9475 - val_accuracy: 0.7209 - 3s/epoch - 454ms/step\n",
      "Epoch 235/250\n",
      "6/6 - 3s - loss: 0.7039 - accuracy: 0.7592 - val_loss: 0.9599 - val_accuracy: 0.7171 - 3s/epoch - 547ms/step\n",
      "Epoch 236/250\n",
      "6/6 - 3s - loss: 0.6744 - accuracy: 0.7699 - val_loss: 0.9447 - val_accuracy: 0.7248 - 3s/epoch - 478ms/step\n",
      "Epoch 237/250\n",
      "6/6 - 3s - loss: 0.6923 - accuracy: 0.7612 - val_loss: 0.9760 - val_accuracy: 0.7132 - 3s/epoch - 456ms/step\n",
      "Epoch 238/250\n",
      "6/6 - 3s - loss: 0.7113 - accuracy: 0.7767 - val_loss: 0.9630 - val_accuracy: 0.7054 - 3s/epoch - 452ms/step\n",
      "Epoch 239/250\n",
      "6/6 - 3s - loss: 0.6825 - accuracy: 0.7709 - val_loss: 0.9744 - val_accuracy: 0.6938 - 3s/epoch - 544ms/step\n",
      "Epoch 240/250\n",
      "6/6 - 3s - loss: 0.6860 - accuracy: 0.7670 - val_loss: 0.9159 - val_accuracy: 0.7364 - 3s/epoch - 454ms/step\n",
      "Epoch 241/250\n",
      "6/6 - 3s - loss: 0.6765 - accuracy: 0.7631 - val_loss: 0.9345 - val_accuracy: 0.7209 - 3s/epoch - 456ms/step\n",
      "Epoch 242/250\n",
      "6/6 - 3s - loss: 0.6625 - accuracy: 0.7699 - val_loss: 0.9267 - val_accuracy: 0.7364 - 3s/epoch - 451ms/step\n",
      "Epoch 243/250\n",
      "6/6 - 3s - loss: 0.6609 - accuracy: 0.7796 - val_loss: 0.9147 - val_accuracy: 0.7287 - 3s/epoch - 539ms/step\n",
      "Epoch 244/250\n",
      "6/6 - 3s - loss: 0.6641 - accuracy: 0.7757 - val_loss: 0.9426 - val_accuracy: 0.7171 - 3s/epoch - 459ms/step\n",
      "Epoch 245/250\n",
      "6/6 - 3s - loss: 0.6716 - accuracy: 0.7709 - val_loss: 0.9415 - val_accuracy: 0.7209 - 3s/epoch - 455ms/step\n",
      "Epoch 246/250\n",
      "6/6 - 3s - loss: 0.6529 - accuracy: 0.7738 - val_loss: 0.9289 - val_accuracy: 0.7287 - 3s/epoch - 456ms/step\n",
      "Epoch 247/250\n",
      "6/6 - 3s - loss: 0.6459 - accuracy: 0.7796 - val_loss: 0.9244 - val_accuracy: 0.7209 - 3s/epoch - 549ms/step\n",
      "Epoch 248/250\n",
      "6/6 - 3s - loss: 0.6513 - accuracy: 0.7854 - val_loss: 0.9153 - val_accuracy: 0.7209 - 3s/epoch - 457ms/step\n",
      "Epoch 249/250\n",
      "6/6 - 3s - loss: 0.6442 - accuracy: 0.7796 - val_loss: 0.9271 - val_accuracy: 0.7132 - 3s/epoch - 452ms/step\n",
      "Epoch 250/250\n",
      "6/6 - 3s - loss: 0.6318 - accuracy: 0.7796 - val_loss: 0.9181 - val_accuracy: 0.7442 - 3s/epoch - 478ms/step\n",
      "9/9 [==============================] - 0s 25ms/step\n"
     ]
    }
   ],
   "source": [
    "results=[]\n",
    "for a in Drops:\n",
    "    for b in Convolution_windows:\n",
    "        np.random.seed(52)\n",
    "        model = Sequential()\n",
    "        model.add(Conv2D(32, b, input_shape=(50, 37, 1), activation='relu'))\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "        model.add(Conv2D(64, b, input_shape=(50, 37, 1), activation='relu'))\n",
    "        model.add(Dropout(a))\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(64, activation='relu'))\n",
    "        model.add(Dense(num_classes, activation='softmax'))\n",
    "        # Compile, fit, and generate scores and predicted probabilities.\n",
    "        model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "        model.fit(X_train_pp, y_train_pp, validation_data=(X_test_pp, y_test_pp), epochs=250, batch_size=200, verbose=2)\n",
    "        scores = model.evaluate(X_test_pp, y_test_pp, verbose=0)\n",
    "        prob = model.predict(X_test_pp)\n",
    "        Results.append((a,b,accuracy_score(y_test,np.argmax(prob,axis=1))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "v1DoMoalbm2u",
    "outputId": "efac0983-61d8-40de-ad3f-7900bf74125c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.2, (3, 3), 0.7790697674418605),\n",
       " (0.2, (10, 10), 0.7209302325581395),\n",
       " (0.3, (3, 3), 0.7674418604651163),\n",
       " (0.3, (10, 10), 0.7248062015503876),\n",
       " (0.4, (3, 3), 0.7984496124031008),\n",
       " (0.4, (10, 10), 0.7441860465116279)]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nFHnEDqUc690"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
